   #alternate OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires
   OCTO Talks ! Â» Lâ€™optimisation bayÃ©sienne par lâ€™exemple : Ã  quoi Ã§a sert
   et comment Ã§a marche ? Flux des commentaires Le chemin vers lâ€™omnicanal
   Le demi-cercle (Ã©pisode 49 â€” Cocktail) alternate alternate

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

Lâ€™optimisation bayÃ©sienne par lâ€™exemple : Ã  quoi Ã§a sert et comment Ã§a marche
?

   PostÃ© le 02/08/2018 par Louis Boutin, Paul De Nonancourt
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   â€œSi jâ€™ai une valeur y qui est fonction de x, comment faire pour
   dÃ©terminer la valeur de x minimisant ou maximisant la valeur de y ?â€
   tel est le problÃ¨me de base du domaine de lâ€™optimisation, qui se
   dÃ©cline Ã  de trÃ¨s nombreux cas dâ€™usage allant de â€œcomment fixer le prix
   pour maximiser un profitâ€ Ã  â€œquelle stratÃ©gie mon robot doit-il adopter
   pour rester en Ã©quilibreâ€.

   Nous vous proposons dans cet article une introduction aux stratÃ©gies
   dâ€™optimisation bayÃ©sienne, un sous-domaine regroupant des techniques
   trÃ¨s puissantes pour converger efficacement vers des valeurs optimales
   lorsquâ€™on fait face Ã  une situation oÃ¹ le nombre dâ€™observations est
   limitÃ© par des contraintes de temps ou de matÃ©riel.

   Vous souhaitez voir un cas dâ€™usage de ces algorithmes ? Comprendre
   comment ces derniers fonctionnent et comment les implÃ©menter ? Alors
   vous Ãªtes au bon endroit. Cet article prend pour exemple la
   problÃ©matique de la configuration automatique des paramÃ¨tres dâ€™une base
   de donnÃ©es pour illustrer lâ€™optimisation bayÃ©sienne. Nous prÃ©senterons
   un exemple dâ€™implÃ©mentation en Python ainsi que quelques autres cas
   dâ€™usage pour cette approche.

1 â€“ Lâ€™optimisation bayÃ©sienne au service de la performance dâ€™une base de
donnÃ©es

1.1 â€“ Un exemple concret

   Chez OCTO Technology, nous avons rÃ©cemment dÃ©cidÃ© dâ€™explorer des
   questions de configuration automatique du fonctionnement de bases de
   donnÃ©es, un domaine particuliÃ¨rement large mais avec plusieurs
   problÃ©matiques que lâ€™on peut distinguer. Lâ€™une dâ€™elles en particulier
   va nous intÃ©resser ici car elle constitue un bon exemple de situation
   oÃ¹ lâ€™optimisation bayÃ©sienne se rÃ©vÃ¨le pertinente.

   Imaginons une base de donnÃ©es, pas nÃ©cessairement complexe, avec un
   ensemble de paramÃ¨tres Ã  rÃ©gler : cache, mÃ©moires partagÃ©es, nombre de
   connexions simultanÃ©es maximum, etc. Ã‰tant donnÃ© une charge de travail,
   tel quâ€™un ensemble de requÃªtes exÃ©cutÃ©es sur cette base de donnÃ©es, on
   souhaite dÃ©terminer automatiquement les valeurs de paramÃ¨tres qui nous
   permettront dâ€™obtenir les meilleurs rÃ©sultats (par exemple, nous
   voudrions complÃ©ter lâ€™exÃ©cution de notre charge le plus rapidement
   possible). Il existe des rÃ¨gles mÃ©tier fournissant des pistes pour
   fixer ces paramÃ¨tres : le site PgTune propose par exemple des
   configurations pour Postgres en fonction du hardware (RAM, CPU). Mais
   ces rÃ¨gles ne sont pas forcÃ©ment adaptÃ©es Ã  notre charge de travail,
   sont rarement optimales et ne sâ€™appuient pas nÃ©cessairement sur des
   thÃ©ories. Pour rÃ©sumer, on souhaiterait rendre le choix dâ€™une bonne
   configuration le plus automatisÃ© et le plus efficace possible mais il
   est en rÃ©alitÃ© trÃ¨s difficile de dÃ©terminer des rÃ¨gles prÃ©cises
   rÃ©gissant ces paramÃ¨tres.

   Heureusement pour nous, il sâ€™agit finalement dâ€™un problÃ¨me classique
   dâ€™optimisation pour lequel de nombreuses solutions existent : nous
   voulons trouver rapidement une configuration (câ€™est-Ã -dire un ensemble
   de paramÃ¨tres) maximisant ou minimisant une mÃ©trique de performance.
   Pour cela, nous devons tout de mÃªme prendre en compte un certain nombre
   de contraintes :
     * Tester une configuration prend du temps car nous devons tester une
       charge dans son intÃ©gralitÃ© sur notre base de donnÃ©es, nous ne
       pouvons donc pas tester un nombre illimitÃ© de configurations pour
       dÃ©terminer la meilleure.
     * Le comportement de la performance de la base de donnÃ©es en fonction
       de la configuration est une boÃ®te noire, nous ne pouvons que donner
       une configuration en entrÃ©e et observer une performance en sortie.

   on optimise la configuration d'une une base de donnÃ©es en fonction
   d'une charge et une mÃ©trique de performance

   Le problÃ¨me de dÃ©part : comment trouver rapidement la configuration
   optimisant la performance, câ€™est-Ã -dire ici minimisant le temps
   dâ€™exÃ©cution ?

2.2 â€“ Les avantages de lâ€™optimisation bayÃ©sienne

   Compte tenu de nos contraintes, il est nÃ©cessaire de trouver une
   stratÃ©gie dâ€™optimisation pas Ã  pas efficace : nous souhaitons, en un
   minimum dâ€™observations, dÃ©terminer la meilleure configuration. En
   consultant la littÃ©rature acadÃ©mique, nous avons ainsi identifiÃ© deux
   articles explorant Ã©galement le problÃ¨me de la configuration
   automatique dâ€™une base de donnÃ©es : iTuned (2009) et Ottertune (2017).
   Les auteurs de ces deux publications proposent des solutions similaires
   basÃ©es sur lâ€™optimisation bayÃ©sienne afin de rechercher une
   configuration optimale.

   Cette approche sÃ©quentielle se trouve Ãªtre particuliÃ¨rement adaptÃ©e Ã 
   notre problÃ¨me de par son principe. Lâ€™objectif est dâ€™utiliser un petit
   nombre dâ€™observations pour estimer un comportement plus global. En
   exploitant efficacement la connaissance accumulÃ©e sur notre fonction
   boÃ®te noire, on espÃ¨re minimiser le nombre dâ€™observations et converger
   rapidement vers la configuration optimale.

   Ã‰tudions maintenant plus en dÃ©tail le fonctionnement dâ€™un algorithme
   dâ€™optimisation bayÃ©sienne avant de passer Ã  une implÃ©mentation concrÃ¨te
   pour rÃ©pondre Ã  notre problÃ¨me.

2 â€“ Sous le capot de lâ€™optimisation bayÃ©sienne

2.1 â€“ Extraire de lâ€™information Ã  partir dâ€™un nombre limitÃ© dâ€™observations

   Lâ€™optimisation bayÃ©sienne est une approche probabiliste basÃ©e sur
   lâ€™infÃ©rence bayÃ©sienne. En somme, cela veut dire quâ€™on va chercher Ã 
   exploiter ce quâ€™on connaÃ®t dÃ©jÃ , donc lâ€™ensemble des Ã©vÃ©nements
   prÃ©cÃ©demment observÃ©s, pour infÃ©rer la probabilitÃ© des Ã©vÃ©nements que
   nous nâ€™avons pas encore observÃ©s. Dans le cadre de lâ€™optimisation
   bayÃ©sienne, nous partons dâ€™un ensemble dâ€™observations dont nous
   connaissons le rÃ©sultat et nous dÃ©terminons pour chaque valeur ???? en
   dehors de cet ensemble la distribution de probabilitÃ© de lâ€™Ã©valuation
   de ???? en ce point ????.


   Dans cet exemple, on cherche Ã  minimiser une fonction quâ€™on ne connaÃ®t
   pas. Comment utiliser ces premiÃ¨res observations pour infÃ©rer les
   valeurs lorsque x varie entre -2 et 2 ?


   Mais comment calculer cette distribution de probabilitÃ© ? Parmi toutes
   les mÃ©thodes existantes, nous retiendrons ici lâ€™une des mÃ©thodes
   classiques qui consiste Ã  utiliser les processus gaussiens qui
   gÃ©nÃ©ralisent le concept de loi normale aux fonctions. Nous ne
   dÃ©velopperons pas cette mÃ©thode un peu complexe. Lâ€™important est de
   comprendre que cette approche nous permet de gÃ©nÃ©rer pour chaque point
   une distribution de probabilitÃ© caractÃ©risÃ©e par une moyenne Âµ (la
   valeur la plus probable) et un Ã©cart-type Ïƒ (la mesure de la dispersion
   probable de la valeur autour de la moyenne).

   Pour le lecteur souhaitant aller plus loin, cet excellent article de
   blog dÃ©veloppe davantage les processus gaussiens sans aller trop loin
   dans les dÃ©tails mathÃ©matiques. La publication originale est ensuite la
   source la plus exhaustive sur le sujet.

   Les processus gaussiens permettent dâ€™infÃ©rer la distribution de
   probabilitÃ© pour chaque point avec la valeur moyenne estimÃ©e Âµ en
   pointillÃ©, et lâ€™Ã©cart-type Ïƒ reprÃ©sentÃ© par la zone vert pÃ¢le.

   Il est Ã  noter quâ€™on ne pourra pas reprÃ©senter cette distribution pour
   tous les points. Nous ne considÃ©rons cette distribution que sur un
   ensemble fini de points : câ€™est notre espace de recherche. Ainsi nous
   aurons, pour chaque point de cet espace de recherche, une valeur
   centrale, la moyenne Î¼, et une certaine dispersion autour de cette
   moyenne, lâ€™Ã©cart-type Ïƒ. Ce dernier sera dâ€™autant plus faible que lâ€™on
   sera proche dâ€™un point dÃ©jÃ  observÃ©.

   Nous sommes Ã  prÃ©sent capable dâ€™infÃ©rer le comportement de notre
   fonction Ã  partir de nos Ã©valuations. Mais comment choisir quel point
   Ã©valuer : quel point a les meilleures chances dâ€™Ãªtre un minimum ?

2.2 â€“ DÃ©terminer les points Ã  plus fort potentiel avec la fonction
dâ€™acquisition

   Rappelons-nous notre objectif : minimiser ou maximiser la fonction
   observÃ©e, câ€™est-Ã -dire trouver le point pour lequel lâ€™Ã©valuation est
   minimisÃ©e ou maximisÃ©e. Le choix du point utilisÃ© pour lâ€™Ã©valuation
   suivante est donc soumis Ã  un double critÃ¨re. Nous voulons dâ€™une part
   gagner en connaissance sur le comportement de la fonction et donc
   choisir une zone de lâ€™espace de recherche oÃ¹ lâ€™inconnu est grand :
   câ€™est lâ€™exploration. Dâ€™autre part, nous souhaitons trouver le point qui
   minimise/maximise notre fonction : câ€™est lâ€™exploitation. Ces deux
   notions sont matÃ©rialisÃ©es par les indicateurs statistiques citÃ©s
   prÃ©cÃ©demment que sont lâ€™Ã©cart-type et la moyenne. Quand lâ€™Ã©cart-type
   est grand, câ€™est que la zone est mal connue et donc intÃ©ressante Ã 
   explorer. Quand la moyenne est petite/grande, câ€™est que la zone
   observÃ©e est intÃ©ressante pour trouver un minimum/maximum.

   Ce compromis entre exploration et exploitation est exprimÃ© par une
   fonction dâ€™acquisition. Cette fonction associe Ã  chaque point de
   lâ€™espace de recherche un potentiel pour Ãªtre lâ€™optimal. Il existe
   plusieurs fonctions dâ€™acquisitions, avec des variations subtiles mais
   gardant le mÃªme principe directeur : exprimer le potentiel dâ€™un point.
   fonction d'acquisition Upper Confidence Bound

   Upper Confidence Bound est un exemple de fonction dâ€™acquisition, le
   coefficient k exprime le poids donnÃ© Ã  lâ€™exploration dans le compromis
   Ã©voquÃ© prÃ©cÃ©demment Âµ : moyenne â€“ Ïƒ : Ã©cart-type


   Ã€ chaque Ã©tape de notre optimisation, le point choisi pour lâ€™Ã©valuation
   donc est celui qui maximise notre fonction dâ€™exploitation.


   En bleu, notre fonction dâ€™acquisition nous indique les points Ã  plus
   fort potentiel Ã  tester : ils reprÃ©sent le compromis entre exploitation
   (prÃ¨s du minimum) et exploration (dans des zones inconnues)

   Trouver le nouveau point Ã  Ã©valuer implique donc dâ€™Ã©valuer notre
   fonction dâ€™acquisition pour tout notre espace de recherche. Cependant
   ces Ã©valuations seront beaucoup moins coÃ»teuses en comparaison Ã 
   lâ€™Ã©valuation de la fonction observÃ©e. La fonction dâ€™acquisition Ã©tant
   simple et connue, on peut facilement lâ€™Ã©valuer en un grand nombre de
   points pour trouver le maximum. Le maximum trouvÃ© correspond au
   prochain point Ã  tester et une fois lâ€™observation rÃ©alisÃ©e, on peut
   actualiser notre optimisation avec cette nouvelle information et
   repartir depuis le dÃ©but, en rÃ©pÃ©tant jusquâ€™Ã  converger.

   Pour bien comprendre cela, reprenons notre exemple en voyant aprÃ¨s
   plusieurs itÃ©rations comment chaque boucle apporte de lâ€™information
   supplÃ©mentaire jusquâ€™Ã  atteindre un minimum. On peut comparer enfin
   lâ€™approximation obtenue Ã  la fonction originale (inconnue Ã  la base) Ã 
   minimiser et vÃ©rifier lâ€™efficacitÃ© de lâ€™algorithme.

   Le cycle dâ€™optimisation bayÃ©sienne Ã  la recherche la valeur donnant le
   rÃ©sultat minimal sur dix itÃ©rations

   Le rÃ©sultat final aprÃ¨s dix itÃ©rations avec lâ€™approximation Âµ(x) faite
   par lâ€™optimisation bayÃ©sienne comparÃ© Ã  la â€œvraieâ€ fonction Ã 
   minimiser, inconnue au dÃ©part

   Pour voir cela en pratique, passons Ã  un exemple plus concret !

3 â€“ Et en pratique, comment Ã§a se passe ?

   Maintenant que nous en savons un peu plus sur lâ€™optimisation
   bayÃ©sienne, reprenons notre problÃ¨me initial et voyons comment
   implÃ©menter en Python un algorithme rÃ©pondant Ã  ce mÃªme problÃ¨me.

   Supposons une situation oÃ¹ nous souhaitons configurer notre base de
   donnÃ©es sur laquelle nous pouvons faire varier deux paramÃ¨tres param_1
   et param_2. Le but est de dÃ©terminer quelles sont les valeurs de ces
   deux paramÃ¨tres permettant de minimiser le temps pour complÃ©ter une
   charge de travail (par exemple un ensemble de requÃªtes). Les rÃ¨gles
   mÃ©tier dont nous disposons ne nous permettent pas de dÃ©terminer les
   valeurs optimales pour ces paramÃ¨tres et nous fournissent au mieux des
   bornes dans lesquelles rechercher lâ€™optimum.

3.1 â€“ Une implÃ©mentation en Python avec scikit-optimize

   Nous allons ainsi utiliser le package Python scikit-optimize (basÃ© sur
   scikit-learn) pour mettre en place un workflow prenant en entrÃ©e un
   intervalle pour nos valeurs de paramÃ¨tres et cherchant lâ€™ensemble
   donnant les meilleurs rÃ©sultats. Tout le code du workflow et des
   visualisations est disponible sous forme de notebook Jupyter.

   CommenÃ§ons par dÃ©finir notre espace de recherche sous forme de
   dictionnaire :
search_space = {
  'param_1': (0.0, 10.0),
  'param_2': (0.0, 0.0)
}

   Il faut dÃ©sormais instancier un objet Optimizer, tirÃ© du package
   scikit-optimize, qui va se charger de la majeure partie du travail.
   Nous devons prÃ©ciser Ã  lâ€™Optimizer lâ€™espace sur lequel il va effectuer
   sa recherche. Comme expliquÃ© prÃ©cÃ©demment, nous allons utiliser un
   estimateur basÃ© sur les processus gaussiens (ou Gaussian Process,
   â€œGPâ€).

   Pour Ã©viter des effets de bord des processus gaussiens survenant
   lorsque lâ€™espace des observations est vide (ou quasi-vide), il est
   aussi prÃ©fÃ©rable de tester les premiers points de maniÃ¨re alÃ©atoire, ce
   que lâ€™on prÃ©cise par le paramÃ¨tre n_initial_points.
opt = Optimizer([search_space['param_1'], search_space['param_2']],
                "GP",
                n_initial_points=3)

   Il nâ€™y a maintenant plus quâ€™Ã  faire tourner la boucle dâ€™optimisation.
   La force de scikit-optimize se situe dans la possibilitÃ© de faire
   tourner des workflows relativement asynchrones grÃ¢ce aux fonctions ask
   et tell. Ã€ chaque Ã©tape, nous allons demander (ask) quelle est la
   configuration qui prÃ©sente le meilleur potentiel pour pouvoir la
   tester, câ€™est-Ã -dire exÃ©cuter notre charge de travail, avant dâ€™obtenir
   un rÃ©sultat que nous allons ajouter Ã  nos observations (tell). On
   boucle ensuite autant de fois que lâ€™on souhaite ou jusquâ€™Ã  ce quâ€™un
   critÃ¨re de satisfaction soit atteint.
for _ in range(20):
    # Quelle est la prochaine configuration Ã  tester ?
    next_config = opt.ask()  # Renvoie une liste

    # Ici, nous avons une dÃ©pendance extÃ©rieure puisque nous devons mettre Ã 
    # jour la configuration de la base de donnÃ©es puis tester notre charge.
    # Faisons l'hypothÃ¨se que ces interfaces ont Ã©tÃ© dÃ©finies ailleurs dans le c
ode.
    database.update_configuration(next_config)
    runtime = database.benchmark(workload)

    opt.tell(next_config, runtime)

   Si tout se passe bien, lâ€™optimiseur convergera ensuite naturellement
   vers un couple de paramÃ¨tres prÃ©sentant la meilleure performance.

   Pour se reprÃ©senter cela, supposons que le temps nÃ©cessaire pour
   complÃ©ter la charge se comporte de la maniÃ¨re suivante en fonction des
   paramÃ¨tres param_1 et param_2 :

   Ce comportement est ici hypothÃ©tique et lâ€™optimiseur ne le connaÃ®t pas.
   Voici comment Ã©volue lâ€™optimisation pour dÃ©terminer le minimum Ã  chaque
   itÃ©ration (pour rappel, le dÃ©tail est disponible dans ce notebook) :

   Lâ€™optimisation bayÃ©sienne dÃ©montre lÃ  tout son intÃ©rÃªt : en un nombre
   dâ€™observations trÃ¨s restreint (de lâ€™ordre de la dizaine), nous sommes
   en mesure de dÃ©terminer les valeurs des paramÃ¨tres pour lesquelles
   notre base de donnÃ©es a les meilleurs rÃ©sultats. Rapidement,
   lâ€™algorithme converge vers des valeurs autour de (6, 13) en gardant
   tout de mÃªme un caractÃ¨re exploratoire pour sâ€™assurer de ne pas Ãªtre
   coincÃ© sur un minimum local si le comportement de la base de donnÃ©es
   avait Ã©tÃ© plus complexe.

3.2 â€“ Gestion du bruit et de la variabilitÃ© de lâ€™environnement

   Sur un cas rÃ©el, il faut cependant se poser la question du bruit :
   lâ€™optimisation bayÃ©sienne est-elle rÃ©siliente lorsque les observations
   sont bruitÃ©es (dans notre cas, on peut par exemple avoir un temps qui
   varie Ã  cause de perturbations rÃ©seaux) ? La rÃ©ponse est oui, dans une
   certaine mesure. Sur un cas plus compliquÃ©, disponible sur ce notebook,
   on voit quâ€™un niveau de bruit infÃ©rieur Ã  5% peut perturber
   lâ€™algorithme sans que cela ne soit gÃªnant pour dÃ©terminer un minimum
   rapidement. Un autre exemple sur un espace Ã  une dimension dÃ©montre
   Ã©galement cela sur le repository du package scikit-optimize.

   Lorsque le bruit est plus Ã©levÃ©, il est possible de jouer sur des
   paramÃ¨tres qui peuvent prendre en compte lâ€™incertitude (câ€™est le cas du
   paramÃ¨tre alpha de lâ€™estimateur scikit-learn GaussianProcessRegressor).
   Mais lorsque cette variabilitÃ© est trop Ã©levÃ©e, lâ€™algorithme ne peut
   simplement pas fonctionner correctement. Pour cette raison, il est
   conseillÃ© avant dâ€™utiliser une stratÃ©gie dâ€™optimisation bayÃ©sienne de
   vÃ©rifier que lâ€™environnement est suffisamment stable et que les
   observations sont reproductibles. AprÃ¨s tout, on ne peut pas optimiser
   ce qui varie.

   Des observations trop bruitÃ©es ne permettent pas de converger vers un
   minimum : ici, les rÃ©sultats varient trop pour pouvoir dÃ©cider quel
   point tester ensuite

3.3 â€“ Application au tuning de modÃ¨les de machine learning

   Lâ€™exemple prÃ©cÃ©dent dâ€™application de lâ€™optimisation bayÃ©sienne est
   relativement prÃ©cis, mais la stratÃ©gie peut facilement se gÃ©nÃ©raliser Ã 
   dâ€™autres applications oÃ¹ lâ€™on cherche un ensemble de paramÃ¨tres
   maximisant la performance mais que chaque observation est coÃ»teuse.

   Câ€™est notamment le cas de la gestion des hyper-paramÃ¨tres dâ€™un modÃ¨le
   de machine learning, la librairie scikit-optimize est dâ€™ailleurs
   taillÃ©e pour ce type dâ€™utilisation. En effet, lorsquâ€™on utilise un
   modÃ¨le de machine learning, il est difficile dâ€™Ã©valuer directement la
   valeur optimale de certains paramÃ¨tres (par exemple le nombre dâ€™arbres
   et leur profondeur pour un RandomForestClassifier). Utiliser
   lâ€™optimisation bayÃ©sienne pour rÃ©soudre le problÃ¨me Ã  notre place est
   tout Ã  fait possible : lâ€™entrÃ©e de notre problÃ¨me correspond aux
   valeurs des hyper-paramÃ¨tres et la performance Ã  optimiser est une
   mÃ©trique au choix de lâ€™utilisateur (prÃ©cision, AUC, etc.).

   Comment dÃ©terminer rapidement les valeurs des hyper-paramÃ¨tres
   maximisant la mÃ©trique de performance ?


   Cette approche permet notamment de gagner en temps dâ€™optimisation en
   rÃ©duisant le nombre dâ€™observations par rapport Ã  des algorithmes type
   RandomSearch ou GridSearch qui demandent plus de tests pour arriver Ã 
   des rÃ©sultats. Câ€™est dâ€™ailleurs lâ€™approche plÃ©biscitÃ©e en 2017 par
   Google pour le tuning dâ€™hyper-paramÃ¨tres qui met mÃªme en place un
   systÃ¨me de â€œhyperparameter tuning as a serviceâ€ sur Cloud ML.

   Convaincu par lâ€™optimisation bayÃ©sienne ? Vous souhaitez optimiser
   rapidement vos modÃ¨les de machine learning ? Jetez donc un oeil aux
   solutions prÃªtes Ã  lâ€™emploi de librairies Python comme scikit-optimize
   ou bayesian-optimization qui prÃ©sentent toutes les deux des exemples
   dâ€™implÃ©mentation appliquÃ©e au tuning de modÃ¨les ici et ici.

Conclusion

   Lâ€™approche bayÃ©sienne est donc efficace pour rÃ©pondre au problÃ¨me du
   choix de paramÃ¨tres optimaux lorsque le comportement de la fonction est
   mal connue, que les observations sont coÃ»teuses et quâ€™une approche
   alÃ©atoire ou brute force nâ€™est pas envisageable. Les algorithmes
   dâ€™optimisation bayÃ©sienne se prÃªtent donc bien Ã  la configuration de
   systÃ¨mes dâ€™informations comme une base de donnÃ©es, Ã  condition de bien
   connaÃ®tre son environnement et sa variabilitÃ© !

   Enfin, on a pu rÃ©cemment voir de grandes entreprises communiquer sur
   des initiatives exploitant ces approches. Des ingÃ©nieurs de Twitter par
   exemple, dÃ©veloppent un systÃ¨me utilisant lâ€™optimisation bayÃ©sienne
   pour configurer automatiquement et en continu les paramÃ¨tres JVM de
   leurs services. En juin 2018, Facebook a prÃ©sentÃ© Spiral, une librairie
   destinÃ©e Ã  la configuration automatique et temps rÃ©el des services
   avec, en prÃ©paration, lâ€™utilisation de lâ€™optimisation bayÃ©sienne pour
   la configuration de paramÃ¨tres. Autant dâ€™approches illustrant la force
   de lâ€™optimisation bayÃ©sienne lorsquâ€™on lâ€™applique Ã  la configuration de
   systÃ¨mes informatiques.
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Cet article a Ã©tÃ© postÃ© dans Data Science.

Articles rÃ©cents

     * Comment conserver les mots de passe de ses utilisateurs en 2019 ?
     * AmÃ©lioration continue : Comment rester dynamique Ã  mesure que
       lâ€™Ã©quipe sâ€™agrandit ?
     * Culture Innovâ€™ : Quel ROI attendu ?
     * Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes
     * Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos
       valeurs et le garant de la vision technique dâ€™OCTO.â€

Laisser un commentaire Annuler la rÃ©ponse

   Votre adresse de messagerie ne sera pas publiÃ©e. Les champs
   obligatoires sont indiquÃ©s avec *

   Commentaire
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   [ ] Me notifier par mail en cas de nouveaux commentaires

   Nom * ______________________________

   Adresse de messagerie * ______________________________

   Site web ______________________________
   (BUTTON) Laisser un commentaire
   Ce formulaire est protÃ©gÃ© par Google Recaptcha
   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

   SÃ©curitÃ©

Comment conserver les mots de passe de ses utilisateurs en 2019 ?

   PostÃ© le 02/10/2019 par Fabien Leite
   Mot de passe

   Lorsque vous concevez une application, vous vous posez forcÃ©ment la
   question de lâ€™authentification et du contrÃ´le dâ€™accÃ¨s. Pour Ã§a,
   plusieurs mÃ©thodes sont disponibles et la premiÃ¨re qui vient
   gÃ©nÃ©ralement Ã  lâ€™esprit est lâ€™utilisation dâ€™un couple identifiant / mot
   de passe. Dans la mesure du possible, on prÃ©fÃ¨rera utiliser une
   solution dÃ©diÃ©e Ã  lâ€™authentification et au contrÃ´le dâ€™accÃ¨s : en bref,
   utiliser une solution dâ€™IAM pour gÃ©rer ces aspects Ã  votre place. Câ€™est
   gÃ©nÃ©ralement plus simple Ã  maintenir et câ€™est surtout souvent meilleur
   pour lâ€™expÃ©rience utilisateur. â€¦
   Lire la suite

   MÃ©thode

AmÃ©lioration continue : Comment rester dynamique Ã  mesure que lâ€™Ã©quipe
sâ€™agrandit ?

   PostÃ© le 01/10/2019 par Etienne Girot

   DiffÃ©rentes Ã©tudes1 soutiennent quâ€™une Ã©quipe performante est une
   Ã©quipe qui est capable de remettre frÃ©quemment en question ses modes de
   fonctionnement afin dâ€™apprendre et sâ€™amÃ©liorer en continu. Pour y
   arriver, elle : favorise l'Ã©mergence de nouvelles idÃ©es a moyen de
   valider ou dâ€™invalider efficacement la pertinence de ces nouvelles
   idÃ©es est en mesure dâ€™aligner ses membres derriÃ¨re les idÃ©es retenues
   comme Ã©tant pertinentes Or, plus une Ã©quipe grandit (aussi bien en
   nombre de membres quâ€™en temps passÃ© Ã  travailler ensemble) plus elle
   est sujette Ã â€¦
   Lire la suite

   MÃ©thode innovation

Culture Innovâ€™ : Quel ROI attendu ?

   PostÃ© le 01/10/2019 par Sylvain Fagnent, Matthieu VETTER
   [school.png]

   AprÃ¨s des annÃ©es et des millions investis sous la menace de la
   disruption, les Directions reviennent Ã  une logique plus ROIste. Ce
   mouvement est sain pour optimiser les ressources rares et donner du
   sens au travail des innovateurs. Le risque est cependant de tuer dans
   lâ€™oeuf des pÃ©pites potentielles en pilotant lâ€™innovation comme un
   business opÃ©rationnel. En fonction des objectifs, les retours sur
   investissement (ROI) dâ€™une dÃ©marche dâ€™innovation seront diffÃ©rents. Et
   dans un monde de plus en plus focalisÃ© sur la rentabilitÃ© Ã  court
   terme,â€¦
   Lire la suite

   Data Science

Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes

   PostÃ© le 30/09/2019 par Annabelle Blangero
   [school.png]

   Lâ€™usage des algorithmes de traitement de donnÃ©es â€“ de la simple requÃªte
   SQL aux puissants algorithmes de recommandation et de personnalisation
   des gÃ©ants de la Tech â€“ sâ€™est popularisÃ© ces derniÃ¨res annÃ©es,
   notamment pour des utilisateurs traditionnellement hors du domaine IT.
   Cet usage se retrouve dans tous les secteurs (industrie, Ã©ducation,
   santÃ©, sÃ©curitÃ©, etc.) et tend Ã  dÃ©lÃ©guer de plus en plus de dÃ©cisions
   Ã  des systÃ¨mes automatisÃ©s. Cette appropriation par le plus grand
   nombre rend les naufrages encore plus probables, et lâ€™exemple de
   Cambridgeâ€¦
   Lire la suite

   Archi & techno

Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos valeurs et le
garant de la vision technique dâ€™OCTO.â€

   PostÃ© le 27/09/2019 par Joy Boswell
   [archi.png]

   Chez OCTO depuis plus de 10 ans , Meriem fait partie des personnes
   fondatrices de lâ€™entreprise. Ancienne leadeuse de la tribu Nouvelles
   Architectures de DonnÃ©es, elle est dÃ©sormais CTO et participe Ã  la
   dÃ©finition de la vision stratÃ©gique et technique dâ€™OCTO. Qui de mieux
   pour nous parler du â€œtech leading Ã  la OCTOâ€ ?
   Lire la suite

   Data Science

Mise en application de DVC sur un projet de Machine Learning

   PostÃ© le 27/09/2019 par Nicolas TOUSSAINT, JÃ©rÃ©my Bouhi
   [school.png]

   Introduction DVC (Data Version Control) est un package Python qui
   permet de gÃ©rer plus facilement ses projets de Data science. Cet outil
   est une extension de Git pour le Machine Learning, comme lâ€™Ã©nonce son
   principal contributeur Dmitry Petrov dans cette prÃ©sentation. DVC est Ã 
   la fois comparable et complÃ©mentaire Ã  Git. Il va sâ€™occuper de
   synchroniser vos donnÃ©es et votre code. Il est donc particuliÃ¨rement
   intÃ©ressant dans le cadre dâ€™un projet de Machine Learning oÃ¹ le modÃ¨le
   et les donnÃ©es Ã©voluent au fil du dÃ©veloppement.â€¦
   Lire la suite

   Archi & techno

BD â€“ Le DÃ©ploiement Continu (CD)

   PostÃ© le 26/09/2019 par Aryana Peze
   [archi.png]

   Hello ! Lors de la BD prÃ©cÃ©dente, nous avons abordÃ© le sujet de la CI
   (IntÃ©gration Continue). Et impossible de parler de CI sans parler de CD
   (DÃ©ploiement Continu)! En thoÃ©rie, la CD implique un dÃ©ploiement
   automatique et quasi-systÃ©matique de chaque modification du code sur
   l'environnement de production. Les mises en production sont rÃ©guliÃ¨res
   et ne sont plus une source de stresse, et l'environnement de production
   est ainsi toujours Ã  jour. En pratique, c'est un objectif trÃ¨s
   compliquÃ© Ã  atteindre, et pas toujours adaptÃ©. (Petite parenthÃ¨seâ€¦
   Lire la suite

   Agile

Dâ€™Ã©tudiant Ã  mentor : rencontre avec notre Octo Thomas Le Flohic

   PostÃ© le 24/09/2019 par CÃ©line Audibert
   [agile.png]

   Thomas a fait un vÃ©ritable parcours â€œÃ  la OCTOâ€ : aprÃ¨s son Ã©cole
   dâ€™ingÃ©, il rentre en stage au sein de notre tribu VIBE (Virtual
   Immersion and Bot Experience) et rejoint dÃ©finitivement lâ€™entreprise en
   intÃ©grant le programme Skool. Un de ses profs Ã  lâ€™Ã©cole Ã©tait un Octo,
   Fabien. Câ€™est ce qui lui a donnÃ© envie de venir frapper Ã  notre porte.
   Comme lui, Thomas a voulu garder un lien avec lâ€™Ã©cole et transmettre
   son savoir. Câ€™est ainsi quâ€™il sâ€™est lancÃ© dans lâ€™accompagnement dâ€™un
   projet deâ€¦
   Lire la suite

   Archi & techno

Interview CÃ©line Gilet â€“ Â« Le Tech Lead nâ€™est pas un super hÃ©ros ! Â»

   PostÃ© le 23/09/2019 par CÃ©line Audibert
   [archi.png]

   Depuis plus de 4 ans chez OCTO, CÃ©line, membre de la tribu CRAFT, est
   devenue une rÃ©fÃ©rence parmi nos Tech Lead. DÃ©couvrez sa vision de ce
   rÃ´le Ã  part. Pour toi, quel est le rÃ´le du Tech Lead ?  Pour moi, câ€™est
   faire en sorte que lâ€™Ã©quipe au sens large (DÃ©veloppeurs, Ops,
   Fonctionnels, Product Owner) arrive Ã  dÃ©livrer rÃ©guliÃ¨rement de la
   valeur. ConcrÃ¨tement, il sâ€™agit de jongler et prioriser en permanence
   entre plusieurs casquettes : expertise, accompagnement, coaching et
   formation.
   Lire la suite

   MÃ©thode innovation

Injonctions paradoxales : un MVP â€¦ mais pour tous !

   PostÃ© le 20/09/2019 par Dominique Lequepeys, Sylvain Fagnent
   un MVP pour tous

   Un MVP ... mais pour tout le monde ! Et si vous vouliez lâ€™entendre
   cette injonction ? Mise en scÃ¨ne, Ã©coutez la. Les racines du paradoxe
   D'un cÃ´tÃ©, les managers sont sous la pression du timing : ils sont
   sÃ©duits par le concept de MVP, Minimum Viable Product, prÃ©sentÃ© comme
   un moyen d'accÃ©lÃ©rer la mise sur le marchÃ©. D'un autre, ils sont sous
   la pression du chiffre : ils ont du mal Ã  accepter qu'on se prive d'une
   partie du marchÃ© potentiel. En outre, ilsâ€¦
   Lire la suite
   1234>
   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #alternate OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires
   OCTO Talks ! Â» Le chemin vers lâ€™omnicanal Flux des commentaires Le
   demi-cercle (Ã©pisode 48 â€” Plaques tournantes) Lâ€™optimisation bayÃ©sienne
   par lâ€™exemple : Ã  quoi Ã§a sert et comment Ã§a marche ? alternate
   alternate

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

Le chemin vers lâ€™omnicanal

   PostÃ© le 01/08/2018 par Julien Kirch
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Si votre systÃ¨me dâ€™information nâ€™est pas tombÃ© dedans quand il Ã©tait
   petit, faire de lâ€™omnicanal est souvent un parcours semÃ© dâ€™embÃ»ches, et
   de promesses dâ€™Ã©diteurs.

   Cet article se propose de parler des sujets de fond liÃ©s Ã  ce type de
   transformations.

   Il est aussi lâ€™occasion dâ€™aborder lâ€™histoire des SI pour comprendre
   comment on est arrivÃ© Ã  la situation actuelle.

Câ€™est quoi lâ€™omnicanal ?

   Un canal est un point dâ€™accÃ¨s spÃ©cifique Ã  un systÃ¨me. Un SI peut par
   exemple avoir un canal web client, un canal application mobile client,
   un backoffice de gestion, des accÃ¨s pour les partenairesâ€¦

   Un SI omnicanal est un SI qui permet aux diffÃ©rentes personnes qui
   lâ€™utilisent de passer de maniÃ¨re fluide dâ€™un canal de distribution Ã  un
   autre.

   Lâ€™exemple type est de commencer Ã  faire une demande de prÃªt immobilier
   sur son smartphone, de la continuer sur son ordinateur portable une
   fois chez soi, puis Ã©ventuellement de terminer le dossier en se rendant
   en agence. Cela ne signifie pas utiliser le mÃªme outil dans les trois
   cas, mais bien dâ€™avoir des outils spÃ©cifiques dont lâ€™ergonomie est
   adaptÃ©e Ã  chaque utilisation, et de pouvoir passer de lâ€™un Ã  lâ€™autre
   Â« sans couture Â» (seamless), câ€™est-Ã -dire sans avoir Ã  refaire une
   opÃ©ration dÃ©jÃ  faite comme une saisie de donnÃ©es.

   En plus des avantages pour les utilisateurÂ·riceÂ·s, nous allons voir que
   lâ€™omnicanalitÃ© a Ã©galement des avantages pour lâ€™IT.

   Ã€ lâ€™inverse, un SI multicanal fournit les mÃªmes fonctionnalitÃ©s sur
   plusieurs canaux mais de maniÃ¨re silotÃ©e, et la bascule dâ€™un canal Ã 
   lâ€™autre est donc visible de la part des personnes ou des systÃ¨mes qui
   lâ€™utilisent.

   Dans ce cas une personne qui commence une demande de prÃªt immobilier
   chez elle et qui se rend en agence devra reprendre le dossier depuis le
   dÃ©but car le backoffice de lâ€™agence nâ€™a pas accÃ¨s Ã  la demande faite
   sur le canal web client.

Pourquoi câ€™est compliquÃ© ?

   Le chantier de transformation omnicanal comporte plusieurs axes, liÃ©s
   aux diffÃ©rentes contraintes des systÃ¨mes actuels.

   Pour comprendre la situation, le mieux est de revenir en arriÃ¨re et de
   dÃ©rouler lâ€™historique du SI.

   Nous allons prendre ici un exemple typique du domaine bancaire tel
   quâ€™on le retrouve chez de nombreux acteurs historiques.

Les annÃ©es 80 : au commencement Ã©taient le mainframe et le backoffice

   Les premiÃ¨res briques du SI se sont construites dans les annÃ©es 80 sur
   mainframe, dÃ©veloppÃ©es en COBOL ou Ã©quivalent. Ces systÃ¨mes historiques
   peuvent Ãªtre des dÃ©veloppements Â« maison Â», des progiciels, ou un
   mÃ©lange des deux.

   Les Ã©crans de backoffice permettant dâ€™y accÃ©der sont conÃ§us pour les
   employÃ©Â·eÂ·s de lâ€™entreprise et leurs sont rÃ©servÃ©s.

   Les workflows de traitement et les fonctionnalitÃ©s exposÃ©es sont
   directement calquÃ©s sur les Ã©crans et chaque Ã©tape du process est
   stockÃ©e dans la base de donnÃ©es dâ€™une maniÃ¨re structurÃ©e. Il ne sâ€™agit
   pas dâ€™un modÃ¨le MVC : les dÃ©finitions des Ã©crans sont imbriquÃ©es avec
   les traitements mÃ©tiers.

   Les bureaux Ã©tant fermÃ©s la nuit et le week-end, les appels interactifs
   sont dÃ©sactivÃ©s pendant ces pÃ©riodes, ce qui permet dâ€™exÃ©cuter des
   traitements de masse ou batch. Ces traitements bÃ©nÃ©ficient ainsi de
   lâ€™intÃ©gralitÃ© de la puissance de calcul, et le fait dâ€™Ãªtre les seuls Ã 
   sâ€™exÃ©cuter leur permet de simplifier leur design car ils peuvent ainsi
   monopoliser des ressources comme des tables de bases de donnÃ©es sans se
   soucier du reste du monde.

   Cela permet aussi de simplifier les rÃ¨gles mÃ©tier, par exemple les
   calculs comptables sont beaucoup plus simples lorsquâ€™aucune autre
   opÃ©ration nâ€™est effectuÃ©e pendant quâ€™ils sâ€™exÃ©cutent.

Les annÃ©es 2000 : lâ€™arrivÃ©e du web, le bicanal

   Avec lâ€™arrivÃ©e du web, il est temps dâ€™ouvrir un site de banque en
   ligne.

   Cela signifie donner accÃ¨s Ã  des fonctionnalitÃ©s du mainframe, mais
   dâ€™une maniÃ¨re diffÃ©rente de celle du backoffice :
     * les Ã©crans doivent Ãªtre adaptÃ©s pour Ãªtre utilisables par des
       non-employÃ©Â·eÂ·s, certains workflows comportent donc plus dâ€™Ã©tapes ;
     * certaines options nÃ©cessitant la validation dâ€™unÂ·e employÃ©Â·e
       empÃªcheront dâ€™aller jusquâ€™au bout du traitement Ã  partir du site,
       cela nÃ©cessitera des opÃ©rations de backoffice spÃ©cifiques.

   Le systÃ¨me mainframe historique est vital pour lâ€™entreprise et la
   maÃ®trise quâ€™ell en a nâ€™est pas toujours satisfaisante : ce patrimoine
   commence Ã  dater et la connaissance sâ€™est donc perdue, il comporte
   rarement des test automatisÃ©s et avec une documentation souvent
   lacunaire.

   La stratÃ©gie choisie est donc souvent de limiter au maximum lâ€™ampleur
   des modifications sur cette partie du systÃ¨me pour limiter les risques.

   Lâ€™approche choisie alors consiste Ã  exposer les workflows existant
   autant que possible â€“ câ€™est-Ã -dire ceux du backoffice â€“ principalement
   sous formes dâ€™API synchrones, et Ã  dÃ©velopper le site web au-dessus de
   ces API, alors mÃªme que les workflows ne sont pas les mÃªmes.

   Les contrats de ces APIs sont donc assez proches des Ã©crans mainframe
   pour limiter lâ€™effort Ã  fournir. Il ne sâ€™agit bien entendu pas dâ€™API
   REST, mais gÃ©nÃ©ralement de messages MQ ou dâ€™appels CTG.

   Lorsque les deux workflows ne correspondent pas, on aboutit Ã  ce type
   de situation :

   Il est dans ce cas impossible de stocker les rÃ©sultats des Ã©tapes 1A ou
   2A dans le mainframe. Ils seront donc stockÃ©s dans le backend du site
   web dans une base de donnÃ©es sÃ©parÃ©e. Cela signifie aussi quâ€™il faudra
   dupliquer les contrÃ´les de saisie de ces Ã©tapes dans la partie web,
   pour Ã©viter dâ€™avoir Ã  revenir en arriÃ¨re dans les Ã©crans du site web.

   Suivant les Ã©tapes, les donnÃ©es sont donc stockÃ©es soit dans le systÃ¨me
   cÅ“ur, soit de maniÃ¨re intermÃ©diaire dans le sous-systÃ¨me du site web.

   En fonction des situations, les points de Â« rencontre Â» des workflows
   sont plus ou moins nombreux. Le cas extrÃªme est celui oÃ¹ il existe un
   seul point de synchronisation : la derniÃ¨re Ã©tape du workflow. Dans
   cette situation, le site web doit stocker toutes les donnÃ©es
   intermÃ©diaires, et recoder tous les contrÃ´les de saisie.

   Dans ce cas, les donnÃ©es dans la base du site web qui nâ€™ont pas Ã©tÃ©
   dÃ©versÃ©es dans la base du mainframe ne sont ni visibles depuis le
   backoffice ni des autres systÃ¨mes qui exploitent cette base.

   Par exemple, si vous commencez Ã  souscrire un prÃªt immobilier sur le
   site web sans terminer la procÃ©dure et que vous vous rendez dans votre
   agence bancaire, il faudra refaire tout ou partie des opÃ©rations.

   Par ailleurs, les opÃ©rations de backoffice spÃ©cifiques au site web
   ainsi que les besoins de support client nÃ©cessitent de dÃ©velopper des
   Ã©crans spÃ©cifiques branchÃ©s sur le mÃªme backend.

   Lâ€™inaccessibilitÃ© du cÅ“ur systÃ¨me historique pendant la nuit pose aussi
   problÃ¨me : il est inconcevable de faire de mÃªme pour un site web
   destinÃ© au grand public.

   Il existe de nombreuses maniÃ¨res dâ€™amÃ©liorer cette situation,
   lâ€™approche souvent rencontrÃ©e consiste Ã  :
    1. effectuer une copie de certaines donnÃ©es avant de couper le systÃ¨me
       mainframe, et sâ€™en servir comme dâ€™un cache en lecture seule
       accessible pendant la nuit, le cache sera dÃ©sactivÃ© lorsque les
       traitements de masse sont terminÃ©s ;
    2. ne pas exÃ©cuter les opÃ©rations qui nÃ©cessitent des Ã©critures mais
       les enregistrer sous forme de demandes dâ€™exÃ©cutions dans le backend
       du site web, et rÃ©aliser rÃ©ellement les traitements le jour suivant
       Ã  lâ€™ouverture du mainframe.

   Cela rend le SI plus difficile Ã  observer car les donnÃ©es sont
   distribuÃ©es entre les deux sous-systÃ¨mes.

   Bien entendu, mÃªme si la rÃ©utilisation de fonctionnalitÃ©s existantes
   est privilÃ©giÃ©e, certains besoins du site web nÃ©cessitent de dÃ©velopper
   des APIs spÃ©cifiques dans le cÅ“ur mÃ©tier.

Aujourdâ€™hui : le mobile et les partenaires

   Lâ€™arrivÃ©e du mobile pourrait signifier la mise en place dâ€™une
   tricanalitÃ©. Mais les besoins mobiles sont souvent suffisamment proches
   des besoins web pour quâ€™ils sâ€™appuient sur les mÃªmes systÃ¨mes. Dans
   quelques situations, il peut Ãªtre nÃ©cessaire de stocker des donnÃ©es
   intermÃ©diaires sur les terminaux, mais il ne sâ€™agit pas dâ€™un vrai
   troisiÃ¨me canal.

   Les Ã©crans de backoffice ont souvent Ã©tÃ© remplacÃ©s par des technologies
   web. Mais pour limiter les impacts sur le mainframe, on conservera
   souvent les mÃªmes workflows, le nouveau backoffice nâ€™aura donc pas Ã 
   stocker de donnÃ©es.

   De mÃªme, le site web public a pu Ãªtre refondu, mais toujours en
   subissant les contraintes de lâ€™existant.

   En revanche, la banque a nouÃ© des partenariats. Ces partenaires peuvent
   par exemple vendre des prÃªts de la banque en marque blanche quand vous
   achetez un de leur produits.

   Les process nÃ©cessaires aux partenaires sont aussi diffÃ©rents du
   process historique que du process web, le systÃ¨me devient donc souvent
   tricanal. Prenons le cas oÃ¹ lâ€™intÃ©gration se fait via un backend
   spÃ©cifique.

   Pour rester lisible, le schÃ©ma ne contient pas les backoffice dÃ©diÃ©s
   aux canaux web et partenaires mais ils existent bel et bien, une
   personne du support peut donc avoir Ã  jongler avec trois backoffices
   diffÃ©rents.

   Le canal partenaire ne pose pas le mÃªme problÃ¨me que le canal web. En
   effet, un client qui commence Ã  souscrire un prÃªt en marque blanche en
   achetant un bien voudra rarement conclure la transaction dans votre
   agence. En revanche, la multiplication des canaux rend la maintenance
   du systÃ¨me plus complexe quand on veut modifier un des workflows
   centraux qui sont exposÃ©s aux autres canaux ou changer une des rÃ¨gles
   de gestion dupliquÃ©e Ã  plusieurs endroits.

   Certains besoins des partenaires se rapprochent de ceux du site web
   client, il arrive donc quâ€™une partie du code soit partagÃ©e entre les
   deux. Cela Ã©vite de dÃ©velopper plusieurs fois les mÃªmes choses mais
   rend le systÃ¨me encore plus difficile Ã  observer.

En rÃ©sumÃ© : les problÃ¨mes du multicanal

   Le multicanal pose donc les problÃ¨mes suivants :
     * mauvaise expÃ©rience utilisateurÂ·riceÂ·s lors du passage dâ€™un canal Ã 
       lâ€™autre ;
     * duplication de code entre les canaux ;
     * donnÃ©es partiellement dupliquÃ©es entre les canaux ;
     * limites dans la capacitÃ© Ã  crÃ©er des parcours trÃ¨s diffÃ©rents du
       parcours historique ;
     * difficultÃ© de mettre en Å“uvre des Ã©volutions cross-canaux du fait
       de la duplication ;
     * systÃ¨me difficile Ã  observer.

Que faut-il pour avoir un SI omnicanal ?

   Les problÃ¨mes causÃ©s par le multicanal et les limites des SI
   correspondants nous donnent les informations nÃ©cessaires pour dresser
   le plan dâ€™un SI omnicanal.

   Avant de rentrer dans le dÃ©tail, il faut prÃ©ciser quâ€™un systÃ¨me
   omnicanal ne signifie pas un systÃ¨me unique de haut en bas pour tous
   les canaux mais un systÃ¨me cÅ“ur permettant de rÃ©pondre aux besoins de
   lâ€™omnicanalitÃ© sur lequel viendront se brancher les diffÃ©rents canaux.

   La diffÃ©rence avec un systÃ¨me multicanal est la capacitÃ© de passer dâ€™un
   canal Ã  lâ€™autre, pas le fait dâ€™avoir un systÃ¨me unique.

   Ainsi vous nâ€™exposerez pas forcÃ©ment les mÃªmes services ou les mÃªmes
   technologies pour votre application mobiles et pour vos partenaires.
   Vous aurez un systÃ¨me cÅ“ur sur lequel viendront se greffer votre canal
   backoffice, votre canal public, votre canal partenaireâ€¦

Des processus mÃ©tier indÃ©pendants des canaux

   Les workflows Ã©tant diffÃ©rent dâ€™un canal Ã  lâ€™autre, lâ€™omnicanalitÃ©
   nÃ©cessite de concevoir des processus mÃ©tier qui soient adaptables aux
   diffÃ©rents canaux.

   Cela signifie quâ€™il ne faut pas penser son processus en termes dâ€™Ã©tapes
   qui ont la granularitÃ© dâ€™un Ã©cran mais en termes de macro-Ã©tapes avec
   une taille plus importante, ce qui donnera Ã  chaque canal les marges de
   manÅ“uvres dont il a besoin.

   Par exemple, souscrire un crÃ©dit peut, en le simplifiant Ã  lâ€™extrÃªme,
   se dÃ©composer en trois macro-Ã©tapes :
     * renseigner des informations personnelles et faire des simulations
       de crÃ©dit jusquâ€™Ã  obtenir une offre satisfaisante ;
     * valider une demande de crÃ©dit en saisissant des informations
       supplÃ©mentaires ;
     * traiter la demande dans le backoffice pour la valider ou la
       rejeter.

   Il sâ€™agit dâ€™un travail de conception mÃ©tier. Câ€™est souvent la partie la
   plus difficile du chantier car il sâ€™agit dâ€™un exercice dont on a peu
   lâ€™habitude, et câ€™est donc une bonne premiÃ¨re Ã©tape.

Un systÃ¨me de stockage

   Les donnÃ©es doivent Ãªtre stockÃ©es dans un systÃ¨me indÃ©pendant des
   canaux.

   Comme les saisies dâ€™informations peuvent se faire dans des ordres
   diffÃ©rents dâ€™un canal Ã  lâ€™autre, on peut moins souvent sâ€™appuyer sur
   des contraintes dâ€™intÃ©gritÃ© que dans un systÃ¨me monocanal.

   Par exemple unÂ·e clientÂ·e pourra peut-Ãªtre crÃ©er un compte sans fournir
   immÃ©diatement son nom ou son adresse.

Des rÃ¨gles mÃ©tier de validation

   Dans un systÃ¨me historique, les services mÃ©tier Ã©tant adossÃ©s aux
   Ã©crans, chacun comportait les rÃ¨gles mÃ©tiers correspondantes permettant
   de valider les informations saisies dans le formulaire.

   Dans un systÃ¨me omnicanal, ce nâ€™est plus possible car chaque canal peut
   concevoir son parcours.

   Cela signifie que les rÃ¨gles de validation seront sous deux formes :
    1. dans le systÃ¨me central, des rÃ¨gles de validation seront placÃ©es au
       niveau de chaque macro-Ã©tape ;
    2. les canaux doivent implÃ©menter ces mÃªmes rÃ¨gles au niveau de chaque
       Ã©cran ou de chaque service exposÃ© avec la granularitÃ© la plus fine
       possible pour Ãªtre en mesure de remonter des erreurs au plus prÃ¨s
       de la saisie des donnÃ©es.

   Cela nÃ©cessite de bien documenter les rÃ¨gles.

Des services facilement utilisables et composables

   Ce sont les services synchrones et asynchrones sur lesquels seront
   construits les canaux.

   En effet, composer des services pour de lâ€™omnicanal signifie de bien
   maÃ®triser les dÃ©pendances entre les diffÃ©rents services pour donner des
   libertÃ©s aux diffÃ©rents canaux.

   Ces services doivent aussi, autant que possible, Ãªtre accessibles 24
   heures sur 24. Cela va nÃ©cessiter, du point de vue de lâ€™extÃ©rieur, que
   les traitements ensemblistes Â« de nuit Â» ne rendent plus le systÃ¨me
   inaccessible. Cela peut demander de rÃ©utiliser le mÃªme type de
   comportements que ceux qui Ã©taient utilisÃ©s par les canaux, comme le
   fait dâ€™enregistrer des demandes dâ€™exÃ©cutions Ã  traiter plus tard. La
   diffÃ©rence est que le comportement sera cohÃ©rent entre les diffÃ©rents
   canaux car rÃ©alisÃ© dans la partie commune.

Les canaux

   Câ€™est la partie spÃ©cifique Ã  chaque canal qui dÃ©finit le workflow de ce
   canal et lâ€™expose de la maniÃ¨re appropriÃ©e par des Ã©crans ou des
   services.

   Lâ€™objectif est que cette partie du SI ne stocke pas dâ€™information. En
   effet, comme nous lâ€™avons vu plus haut, toute information stockÃ©e au
   niveau dâ€™un canal va crÃ©er un silotage. Ils ne font que sâ€™appuyer sur
   les services de la couche cÅ“ur.

   Lâ€™omnicanalitÃ© rend la conception des canaux plus difficiles car ils
   doivent prendre en compte le fait quâ€™un processus peut avoir Ã©tÃ©
   dÃ©marrÃ© dans un autre canal ayant un workflow diffÃ©rent.

   Par exemple, certains des champs de saisie auront peut-Ãªtre dÃ©jÃ  Ãªtre
   remplis et pas dâ€™autres.

   Il faut quâ€™il puisse dÃ©terminer comment effectuer la reprise du
   traitement dans de bonnes conditions.

   Cela demande une conception rigoureuse ainsi quâ€™une bonne couverture de
   tests.

Faire vivre le systÃ¨me

   La derniÃ¨re pierre de lâ€™omnicanal est la capacitÃ© Ã  le faire vivre.

   En effet, les canaux sont fortement couplÃ©s au systÃ¨me cÅ“ur, ils
   devront donc Ãªtre modifiÃ©s de maniÃ¨re coordonnÃ©e.

   Ce couplage est un effet direct de lâ€™omnicanalitÃ© : câ€™est elle qui
   permet de passer dâ€™un canal Ã  lâ€™autre. Le modÃ¨le de canaux dÃ©couplÃ©s
   est celui du multicanal.

   Votre organisation doit donc Ãªtre adaptÃ©e Ã  cette contrainte.

Comment y aller ?

   Maintenant que nous savons en quoi devrait consister un systÃ¨me
   omnicanal, reste Ã  Ã©tudier les trajectoires pour lâ€™atteindre.

   Nous allons commencer par un point sur la situation de dÃ©part puis
   donner quatre exemples de stratÃ©gie possibles. Il existe de multiples
   approches, celles qui sont mentionnÃ©es ici ont Ã©tÃ© choisies car elles
   mettent en lumiÃ¨res les contraintes qui sâ€™appliquent.

Situation de dÃ©part

   Le systÃ¨me multicanal comporte deux Ã©lÃ©ments qui ont de la valeur et
   sur lesquels il faut sâ€™appuyer en le faisant Ã©voluer vers lâ€™omnicanal,
   et deux limites quâ€™il faudra supprimer :

   Ã€ conserver :
     * les rÃ¨gles de traitement mÃ©tier ;
     * les rÃ¨gles de validation de donnÃ©es.

   Les deux reprÃ©sentent de la valeur mÃªme si elles sont adhÃ©rentes au
   Ã©tapes du workflow historique (par exemple les diffÃ©rents Ã©crans du
   process de souscription originel).

   Ã€ supprimer :
     * le workflow unique formant lâ€™assise du systÃ¨me historique
     * les rÃ¨gles dâ€™intÃ©gritÃ© des donnÃ©es alignÃ©es avec le process
       historique

StratÃ©gie 1 : commencer par acheter un BPM

   Câ€™est la solution que prÃ©conisent certains Ã©diteurs.

   Les BPM sont des outils permettant de dÃ©finir des workflow mÃ©tiers sous
   forme low-code, câ€™est-Ã -dire via de la configuration et/ou des
   designers graphiques. Ils permettent Ã©galement de stocker lâ€™Ã©tat
   courant des diffÃ©rents workflows.

   Câ€™est une solution tentante car elle fournit un socle prÃªt Ã  lâ€™emploi
   pour une partie des besoins.

   Deux points dâ€™attention pour cette approche :
     * comme avec tout progiciel, attention Ã  ne pas oublier les bonnes
       pratiques de dÃ©veloppement comme les tests automatisÃ©s : votre BPM
       embarquera du code, et qui dit code dit tests ;
     * ne pensez pas quâ€™avoir choisi un BPM signifie que vous avez gagnÃ©,
       en effet nous avons vu que la partie la plus difficile du chantier
       est la conception des services sur lesquels va sâ€™appuyer le BPM.

   Il sâ€™agit dâ€™une utilisation trÃ¨s spÃ©cifique des outils de BPM, loin de
   la gestion des processus mÃ©tiers qui est leur utilisation normale.

StratÃ©gie 2 : repartir sur un nouveau systÃ¨me

   Câ€™est la solution la plus risquÃ©e, mais qui est parfois la moins
   mauvaise. Par exemple quand vous avez perdu la maÃ®trise de votre
   systÃ¨me historique, ou quâ€™il sâ€™agit dâ€™un progiciel qui nâ€™est pas
   compatible avec lâ€™omnicanal.

   La solution nâ€™est pas forcÃ©ment de partir de zÃ©ro : il est possible de
   partir sur un progiciel plus rÃ©cent, ou de racheter une entreprise
   disposant dâ€™une solution dÃ©jÃ  fonctionnelle.

StratÃ©gie 3 : rendre le cÅ“ur mÃ©tier historique omnicanal

   Il sâ€™agit dâ€™attaquer le problÃ¨me par le bas, câ€™est-Ã -dire par le cÅ“ur
   mÃ©tier.

   Cela peut Ãªtre Ã  lâ€™occasion de lâ€™ajout dâ€™un nouveau canal, en profitant
   dâ€™avoir des nouveaux besoins factuels, et un budget.

   Il va sâ€™agir de transformer le cÅ“ur, puis de faire maigrir les canaux
   existants en redescendant ce qui ne devrait pas sâ€™y trouver, comme le
   stockage de donnÃ©es.

   La situation de dÃ©part


   En cours de migration : les canaux diminuent et le cÅ“ur sâ€™enrichit


   Cible : les canaux nâ€™ont plus de base de donnÃ©es

   Câ€™est probablement la meilleure solution si vous avez la maÃ®trise de
   votre existant et que vous souhaitez capitaliser dessus.

   Deux points dâ€™attention :
     * faire Ã©voluer de maniÃ¨re significative un outil demande un niveau
       de maÃ®trise plus important que le fait de le maintenir, la facilitÃ©
       Ã  corriger des erreurs sur le cÅ“ur nâ€™est pas un bon indicateur de
       votre capacitÃ© Ã  le transformer ;
     * ne pas introduire de rÃ©gressions, par exemple en supprimant des
       comportements non documentÃ©s mais sur lesquels le code sâ€™appuie.

StratÃ©gie 4 : ajouter une couche dâ€™omnicanal au-dessus du cÅ“ur

   Il sâ€™agit de la voie intermÃ©diaire : on sâ€™appuie sur lâ€™existant le
   temps de bÃ¢tir un remplacement.

   Il sâ€™agit de bÃ¢tir une surcouche omnicanale au-dessus du cÅ“ur. PlutÃ´t
   que de partir de zÃ©ro, il est possible de partir dâ€™un des canaux
   existants en le sÃ©parant entre une partie souche qui servira de base Ã 
   la partie omnicanal et la partie exposition qui deviendra la nouvelle
   couche canal.

   En enrichissant peu Ã  peu de nouveau types de donnÃ©es en les remontant
   depuis le cÅ“ur historique et des fonctionnalitÃ©s associÃ©es. Cette
   couche devra exposer les services rÃ©utilisables qui serviront de base
   aux diffÃ©rents canaux.

   Pendant la construction, vous continuerez de subir les limitations du
   cÅ“ur existant, mais commencerez Ã  bÃ©nÃ©ficier de certains avantages de
   lâ€™omnicanalitÃ©, comme la transition plus facile dâ€™un canal Ã  lâ€™autre.

   Lâ€™Ã©tape suivante consistera Ã  dÃ©gonfler le systÃ¨me historique pour
   sâ€™appuyer de plus en plus sur la nouvelle couche.

   Cela va probablement demander des Ã©volutions du systÃ¨me cÅ“ur. Cependant
   elles ne demanderont pas de transformations profondes, au contraire de
   la stratÃ©gie prÃ©cÃ©dente.

   En cible on pourra dÃ©comissionner totalement le systÃ¨me historique, ou
   conserver certains Ã©lÃ©ments comme les parties rÃ©glementaires pour
   lesquels la migration ne se justifie pas et qui nâ€™imposent pas de
   contraintes sur le nouveau systÃ¨me.

   Une des difficultÃ©s de cette stratÃ©gie est de bien choisir lâ€™ordre dans
   lequel remonter les fonctionnalitÃ©s pour bÃ©nÃ©ficier au plus vite des
   premiers avantages tout en limitant les risques.

   La situation de dÃ©part

   En cours de migration, la zone du milieu prend de lâ€™importance

   Cible : le cÅ“ur historique nâ€™est plus le centre du systÃ¨me

Pour terminer

   Lâ€™omnicanalisation dâ€™un SI est un chantier risquÃ© et de longue haleine.
   Mal conÃ§u ou mal pilotÃ©, il peut Ãªtre un enfer de plusieurs annÃ©es qui
   aboutira Ã  ajouter de nouvelles briques Ã  votre systÃ¨me, sans atteindre
   aucun des buts fixÃ©s.

   Il est autant liÃ© Ã  la DSI quâ€™au mÃ©tier : il demande du travail Ã  tous
   les deux, mais apportera aussi des avantages Ã  chacun. Si lâ€™un des deux
   acteurs veut se lancer sans la pleine coopÃ©ration de lâ€™autre, câ€™est
   lâ€™Ã©chec presque assurÃ©.

   MÃªme si ce changement peut permettre de rÃ©duire la dÃ©pendance aux
   systÃ¨mes historiques, y arriver va demander de comprendre comment ces
   systÃ¨mes fonctionnent, et de les modifier. Moins bien vous maÃ®trisez
   votre mainframe, plus il sera difficile de vous en passer.

   Si un tel projet vous semble long et coÃ»teux aujourdâ€™hui, gardez Ã 
   lâ€™esprit que plus le temps passe et plus la situation va empirer.

   Bonne chance Ã  vous.
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Cet article a Ã©tÃ© postÃ© dans Archi & techno, StratÃ©gie SI et tagguÃ©
   Architecture SI, omnicanal.

Articles rÃ©cents

     * Comment conserver les mots de passe de ses utilisateurs en 2019 ?
     * AmÃ©lioration continue : Comment rester dynamique Ã  mesure que
       lâ€™Ã©quipe sâ€™agrandit ?
     * Culture Innovâ€™ : Quel ROI attendu ?
     * Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes
     * Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos
       valeurs et le garant de la vision technique dâ€™OCTO.â€

Un commentaire sur â€œLe chemin vers lâ€™omnicanalâ€

     Anas
   02/08/2018 Ã  16:20
   Une stratÃ©gie qui n'a pas Ã©tÃ© Ã©voquÃ©e et qui mÃ©rite de l'Ãªtre, il
   s'agit de la solution CEP couplÃ©e Ã  une solution de suivi de parcours.
   La solution BPM n'est pas trÃ¨s adaptÃ©e Ã  des parcours impliquant des
   millions d'utilisateurs car il faut pouvoirs stocker et gÃ©rer autant
   d'instances de processus que de parcours utilisateurs en cours. Pour
   peu que le parcours dure quelques jours voir quelques semaines (ce qui
   est le cas dans le domaine bancaire), on atteint trÃ¨s vite des volumes
   difficilement supportables par les solutions BPM du marchÃ©.

Laisser un commentaire Annuler la rÃ©ponse

   Votre adresse de messagerie ne sera pas publiÃ©e. Les champs
   obligatoires sont indiquÃ©s avec *

   Commentaire
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   [ ] Me notifier par mail en cas de nouveaux commentaires

   Nom * ______________________________

   Adresse de messagerie * ______________________________

   Site web ______________________________
   (BUTTON) Laisser un commentaire
   Ce formulaire est protÃ©gÃ© par Google Recaptcha

   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #alternate OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires
   OCTO Talks ! Â» Le demi-cercle (Ã©pisode 49 â€” Cocktail) Flux des
   commentaires Lâ€™optimisation bayÃ©sienne par lâ€™exemple : Ã  quoi Ã§a sert
   et comment Ã§a marche ? GraphQL: Et pour quoi faire ? alternate
   alternate

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

Le demi-cercle (Ã©pisode 49 â€” Cocktail)

   PostÃ© le 03/08/2018 par Christophe Thibaut
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   The world is not interested in the storms you encountered, but did you
   bring in the ship?
   William McFee

   Sept heure moins dix. Tu entres dans la Grande Salle de la Direction
   GÃ©nÃ©rale. Toutes les lumiÃ¨res sont allumÃ©es bien que le jour soit
   encore clair. On a pliÃ© toutes les tables sauf une, et repoussÃ© les
   chaises dans un coin.

   Pop !

   Victor sert le champagne dans des flÃ»tes. Tu te demandes si elles ont
   Ã©tÃ© louÃ©es pour lâ€™occasion, ou si dÃ©cidÃ©ment cette maison regorge de
   trÃ©sors cachÃ©s. Il y a du monde, au moins 40 personnes. Audrey et
   JÃ©rÃ©mie sont en train de discuter avec un homme en costume trois piÃ¨ces
   et une jeune femme dâ€™apparence assez chic malgrÃ© une chevelure hirsute.
   Certainement des clients de chez Juniper. Tu tâ€™approches. Audrey dit :
   â€“ En tout cas, câ€™est une bonne chose que vous ayez pu rencontrer
   Victor. Jâ€™Ã©tais loin de maÃ®triser mon sujet sur Parady !
   La jeune femme dit :
   â€“ Vous vous en Ãªtes trÃ¨s bien sortis. Une prÃ©sentation trÃ¨s
   professionnelle, vraiment.
   JÃ©rÃ©mie sourit dâ€™un sourire que tu ne lui connais pas, et rÃ©pond :
   â€“ Merci. Beaucoup.
   Lâ€™homme en costume dit :
   â€“ Et surtout, Ã§a nous a permis de mieux faire connaissance avec votre
   produit. Ce quâ€™on ne vous a pas dit, câ€™est que ces features que vous
   nous avez prÃ©sentÃ©es, on les cherche depuis deux ans sur le marchÃ© !
   Une chance que Victor se soit plantÃ© en scooter.
   Mais non, quâ€™est-ce que tu racontes.
   Il aurait pris tout lâ€™espace et le client nâ€™aurait pas vu la dÃ©mo
   dâ€™Audrey et JÃ©rÃ©mie, et il ne nous aurait pas achetÃ© la gamme complÃ¨te.
   La mÃ©disanceâ€¦

   Farid et Hugo sont arrivÃ©s. Ils serrent des mains. Prennent une flÃ»te.

   Tintement de verre. Les conversations sâ€™estompent.

   Le PrÃ©sident Directeur GÃ©nÃ©ral, GÃ©rard Beaufret, lÃ¨ve son verre un
   instant, le pose sur la table derriÃ¨re lui, et dÃ©clare :
   â€“ Je voudrais remercier dâ€™abord nos clients, anciens et nouveaux (il
   adresse un sourire au couple venu de Juniper), merci, pour la confiance
   que vous nous faites, et qui nous honore. Nous cherchons constamment Ã 
   amÃ©liorer la qualitÃ© de nos produits, et vos apprÃ©ciations â€” et bien
   entendu vos critiques â€” nous sont trÃ¨s trÃ¨s utiles.

   Bien entendu.
   Stop.

   Le PDG reprend :
   â€“ Je voudrais remercier lâ€™Ã©quipe XXLâ€¦
   Il fait un geste pour vous inviter Audrey, JÃ©rÃ©mie, Hugo, Farid et toi
   Ã  entrer dans le grand cercle. Vous avancez. Tu souris.

   Tu souris trop.
   Mais non.

   â€“ â€¦ sans qui cette Ã©popÃ©e ne serait pas possible. Chapeau ! Et sans
   oublier bien sÃ»r, notre chÃ¨re Maria, et Victor qui reprend le flambeau
   de plus belle.

   Tout le monde applaudit, y compris vous. Tu applaudis tes coÃ©quipiers.
   Maria applaudit. Victor applaudit. Jean-Bernard applaudit. Lazare lÃ¨ve
   sa flÃ»te de champagne et adresse un clin dâ€™Å“il Ã  JÃ©rÃ©mie.

   Pas facile dâ€™applaudir avec une flÃ»te Ã  la main.
   MÃªme vide.

   Une bonne demi-heure se passe. Brouhaha de discussions animÃ©es, sur
   lâ€™avenir du logiciel, la digitalisation, la vitesse, la rÃ©activitÃ©.
   JÃ©rÃ©mie, Farid et toi, vous parlez dâ€™architecture. Victor, accompagnÃ©
   dâ€™un collÃ¨gue de la Direction des Ventes, sâ€™immisce dans le groupe et
   le prÃ©sente :
   â€“ Vous connaissez Daniel Derby ? Product Manager de la gamme Parady.
   JÃ©rÃ©mie dit : salut Daniel.

   Bon sang JÃ©rÃ©mie connaÃ®t tout le monde dans cette boÃ®te.

   Vous vous saluez. La conversation fait comme une pause, puis reprend :

   Daniel : Alors JÃ©rÃ©mie, dis nous, câ€™est quoi votre secret de
   fabrication, chez XXL ?
   JÃ©rÃ©mie : Ah ah. Le secretâ€¦ Mais il nâ€™y a pas de secret.
   Daniel : Sans blague. Regardez le chemin parcouru en 10 mois. Vous avez
   forcÃ©ment un truc. Comment faites-vous pour aller si vite ?
   Farid : Oui, tiens câ€™est vrai, câ€™est quoi notre secret ?
   JÃ©rÃ©mie : Pffff. Non, je ne vois pas.
   Victor (sâ€™esclaffant) : Il faut continuer Ã  le faire boire si tu veux
   dÃ©couvrir le truc. Je vais chercher du champagne.
   Daniel : Si tu y rÃ©flÃ©chis, lÃ  comme Ã§a ? Quâ€™est-ce que vous avez de
   diffÃ©rent ?
   Toi : On a un bureau qui donne sur le sud ? Non, je plaisante.

   Victor revient avec du champagne et sâ€™avance pour remplir vos flÃ»tes.
   JÃ©rÃ©mie, Farid et toi, dÃ©clinez poliment.

   JÃ©rÃ©mie (tend son verre) : Oh, remarque aprÃ¨s tout. Merci.

   JÃ©rÃ©mie te regarde une seconde, dÃ©guste son champagne et reprend :
   JÃ©rÃ©mie : Notre secret, câ€™est la qualitÃ© des conversations.
   Farid (claque des doigts) : VoilÃ . Exactement !
   Daniel : La qualitÃ© de vos conversations ? Câ€™est une blague ?
   JÃ©rÃ©mie : Mais non, pourquoi ? Quâ€™est-ce qui te fait rire lÃ -dedans ?
   Victor : Remarque quâ€™il nâ€™a pas tort. Au dÃ©but Ã§a mâ€™a surpris, mais en
   fait il a un peu raison.
   Daniel : Mais, vous nâ€™Ãªtes pas lÃ  pour avoir de jolies conversations de
   salon ! Vous Ãªtes lÃ  pour faire votre travail.
   JÃ©rÃ©mie : Bien sÃ»r. Moi-mÃªme, je nâ€™aime pas les conversations de salon
   comme tu dis. Non, je te parle des conversations au travail. Celles qui
   permettent dâ€™obtenir des informations et de prendre nos dÃ©cisions.
   Daniel : Ha ! Vous prenez des dÃ©cisions ! Et combien de dÃ©cisions vous
   prenez de cette maniÃ¨re ?
   JÃ©rÃ©mie : Je dirais plusieurs dizaines par jour. Câ€™est principalement
   ce en quoi consiste notre travail dâ€™ailleurs.
   Farid : Une longue sÃ©rie de dÃ©cisionsâ€¦
   Toi : Plus ou moins funestesâ€¦
   Farid (souriant) : Tu vois le verre Ã  moitiÃ© videâ€¦
   Daniel (vide sa flÃ»te, croise les bras) : Tout de mÃªme. Je suis curieux
   de savoir quel type de conversations vous tenez, et Ã  propos de quoi ?
   JÃ©rÃ©mie : Ã‡a dÃ©pend pas mal de ce que lâ€™on est en train de faire, note.
   Daniel : Ah oui ?
   JÃ©rÃ©mie : Mais si on voulait les catÃ©goriser par contenu, je pense
   quâ€™on trouverait cinq catÃ©gories distinctes :
   (JÃ©rÃ©mie compte sur ses doigts) Les conversations avec le code. Les
   conversations Ã  propos du code. Les conversations Ã  propos du problÃ¨me
   que nous voulons rÃ©soudre grÃ¢ce au code. Les conversations Ã  propos de
   notre faÃ§on de rÃ©soudre le problÃ¨me
   Toi : Ã‡a fait quatre.
   JÃ©rÃ©mie (souriant) : Je sais encore compter. Et puis les conversations
   Ã  propos de toutes ces conversations.
   Daniel : Attends, jâ€™ai perdu le fil. Quâ€™est-ce que tu appelles une
   conversation avec le code ?
   JÃ©rÃ©mie : Tu lis un morceau de code, tu ne le comprends pas bien;
   disons que sa forme est difficile Ã  comprendre. Tu Ã©cris un test sur ce
   code, qui te rÃ©vÃ¨le une nouvelle information, ou bien qui confirme une
   hypothÃ¨se. Câ€™est comme si tu posais une question. Quand tu as
   suffisamment de tests, tu peux changer la forme du code, ce qui le rend
   plus facile Ã  comprendre. Et tu relances tes tests. Câ€™est ce que
   jâ€™appelle une sorte de conversation. Si on veut.
   Daniel : Ã‡a me rappelle mes Ã©tudes. Câ€™est ce quâ€™on faisait avec
   Smalltalk. Sauf quâ€™on ne faisait pas de tests comme vous, on utilisait
   un dÃ©bogueur intÃ©grÃ©.
   JÃ©rÃ©mie : Je ne connais pas Smalltalk, mais je dirais quâ€™on peut faire
   Ã§a avec nâ€™importe quel langage, du moment quâ€™on a un outil de test et
   un dÃ©bogueur.
   Daniel : Bon. Admettons. Et les autres conversations ?
   JÃ©rÃ©mie : Les conversations Ã  propos du code, sont celles que nous
   avons trÃ¨s souvent entre dÃ©veloppeurs. Est-ce que le code fait ce quâ€™il
   est supposÃ© faire ? Est-ce que le code est facile Ã  comprendre ?
   Quâ€™est-ce quâ€™il faut changer dans ce code ? Ce genre de questions.
   Daniel : Je vois. Et ensuite ?
   JÃ©rÃ©mie : Les conversations Ã  propos du problÃ¨me, sont celles que nous
   avons avec Maria, CharlÃ¨ne, Victor et dâ€™autres personnes, et ces
   conversations tournent autour des utilisateurs, des clients et de ce
   quâ€™ils essayent dâ€™obtenir au moyen dâ€™XXL, et comment ils lâ€™obtiennent.
   Daniel : OK. Câ€™est la partie fonctionnelle.
   JÃ©rÃ©mie : Si tu veux.
   Daniel : Mais Ã§a, Ã§a ne devrait pas faire lâ€™objet de conversation
   justement : Ã§a devrait Ãªtre dans la spÃ©cification.
   JÃ©rÃ©mie : Ah bon ?
   Daniel : Bien sÃ»r. Pour Ã©crire un programme qui fait correctement ce
   qui est attendu fonctionnellement, il faut des spÃ©cifications.
   JÃ©rÃ©mie : OK. Je ne dis pas non. Dans ce cas, cette catÃ©gorie de
   conversation inclura probablement les conversations Ã  propos de la
   spÃ©cification.
   Daniel : Eh bien non, pas du tout. La spÃ©cification est justement lÃ 
   pour Ã©viter dâ€™avoir Ã  revenir sur le sujet.
   JÃ©rÃ©mie : Pour que ce que tu dis soit exact, Ã  savoir, quâ€™on aie pas
   besoin de revenir sur le sujet, il faudrait que la spÃ©cification soit
   complÃ¨te.
   Victor : Ah Ã§aâ€¦
   JÃ©rÃ©mie : Note que si la spÃ©cification Ã©tait complÃ¨te, on pourrait
   probablement la transformer automatiquement en logiciel. On nâ€™aurait
   plus besoin de la traduire en code.
   Daniel : Ha ! Câ€™est Ã§a qui serait pratique !
   Victor : Mais alors les dÃ©veloppeurs nâ€™auraient plus de travailâ€¦ Et
   alors tu ferais quoi, comme mÃ©tier, JÃ©rÃ©mie ?
   JÃ©rÃ©mie : Probablement un mÃ©tier qui tourne autour de la crÃ©ation de
   spÃ©cifications.
   Daniel : Bon. Dâ€™accord. Ensuite, tu as parlÃ© des conversations Ã  propos
   de notre faÃ§on de rÃ©soudre le problÃ¨meâ€¦
   JÃ©rÃ©mie : Oui, câ€™est tout ce qui concerne le process, lâ€™organisation.
   La mÃ©thodologie si tu prÃ©fÃ¨res.
   Victor : Et la derniÃ¨re catÃ©gorie ?
   JÃ©rÃ©mie : Les conversations Ã  propos de toutes ces conversations.
   Daniel : Oui, en quoi Ã§a consiste ?
   JÃ©rÃ©mie : Eh bien, par exemple, Ã  essayer de comprendre pourquoi une
   conversation qui aurait dÃ» Ãªtre plus efficace par exemple, ne lâ€™a pas
   Ã©tÃ©, et ce quâ€™on peut faire pour quâ€™elle le devienne.
   Daniel : Et donc, comme Ã§a, vous savez, Ã  tout moment, quel type de
   conversation vous Ãªtes en train dâ€™avoir ? Câ€™est hilarant.
   JÃ©rÃ©mie : Mais non, pas du tout.
   Daniel : Alors pourquoi tu me parles de toutes ces catÃ©gories JÃ©rÃ©mie ?
   JÃ©rÃ©mie : Tu mâ€™as demandÃ© quels types de conversation on tient. Jâ€™ai
   essayÃ© de rÃ©pondre Ã  cette question.
   Daniel : Ha ! Tu es trop sÃ©rieux, JÃ©rÃ©mie. Tiens bois encore un peu de
   champagne.
   Toi : Il se fait tard. Je rentre. A demain !

   (Ã  suivre)
   Episodes PrÃ©cÃ©dents :
   1 â€” Si le code pouvait parler
   2 â€” Voir / Avancer
   3 â€” Communication Breakdown
   4 â€” Driver / Navigator
   5 â€” Brown Bag Lunch
   6 â€” Conseils Ã  emporter
   7 â€” Crise / OpportunitÃ©
   8 â€” Le CinquiÃ¨me Ã‰tage
   9 â€” Que faire ?
   10 â€” Soitâ€¦ Soitâ€¦
   11 â€” BoÃ®tes et FlÃªches
   12 â€” Le prochain Copil
   13 â€” La Faille
   14 â€” PoussiÃ¨re
   15 â€” Lâ€™hypothÃ¨se et la RÃ¨gle
   16 â€“ DÃ©placements
   17 â€” Jouer et ranger
   18 â€” Arrangements
   19 â€” Mise au point
   20 â€” ExpÃ©rimentation
   21 â€” Ã‰chantillons
   22 â€” Non-conclusions
   23 â€” Non-dÃ©cisions
   24 â€” Ã‰pisode neigeux
   25 â€” Fusions et confusions
   26 â€” DÃ©barquement
   27 â€” TempÃªte
   28 â€” EmbardÃ©e
   29 â€” AmÃ©nagement
   30 â€” Interruptions
   31 â€” Normalisation
   32 â€” Outsiders
   33 â€” Fabrication
   34 â€” Observation
   35 â€” Perturbations
   36 â€” Conclusions
   37 â€” Nouvelle Donne
   38 â€” Transaction
   39 â€” Mutation
   40 â€” Exclusion Mutuelle
   41 â€” PrÃ©emption
   42 â€” DÃ©monstration
   43 â€” Conversation
   44 â€” Exception
   45 â€” Explications
   46 â€” TÃ©lescopage
   47 â€” NÃ©gociations
   48 â€” Plaques tournantes
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Cet article a Ã©tÃ© postÃ© dans Software Craftsmanship.

Articles rÃ©cents

     * Comment conserver les mots de passe de ses utilisateurs en 2019 ?
     * AmÃ©lioration continue : Comment rester dynamique Ã  mesure que
       lâ€™Ã©quipe sâ€™agrandit ?
     * Culture Innovâ€™ : Quel ROI attendu ?
     * Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes
     * Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos
       valeurs et le garant de la vision technique dâ€™OCTO.â€

Laisser un commentaire Annuler la rÃ©ponse

   Votre adresse de messagerie ne sera pas publiÃ©e. Les champs
   obligatoires sont indiquÃ©s avec *

   Commentaire
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   [ ] Me notifier par mail en cas de nouveaux commentaires

   Nom * ______________________________

   Adresse de messagerie * ______________________________

   Site web ______________________________
   (BUTTON) Laisser un commentaire
   Ce formulaire est protÃ©gÃ© par Google Recaptcha
   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

   SÃ©curitÃ©

Comment conserver les mots de passe de ses utilisateurs en 2019 ?

   PostÃ© le 02/10/2019 par Fabien Leite
   Mot de passe

   Lorsque vous concevez une application, vous vous posez forcÃ©ment la
   question de lâ€™authentification et du contrÃ´le dâ€™accÃ¨s. Pour Ã§a,
   plusieurs mÃ©thodes sont disponibles et la premiÃ¨re qui vient
   gÃ©nÃ©ralement Ã  lâ€™esprit est lâ€™utilisation dâ€™un couple identifiant / mot
   de passe. Dans la mesure du possible, on prÃ©fÃ¨rera utiliser une
   solution dÃ©diÃ©e Ã  lâ€™authentification et au contrÃ´le dâ€™accÃ¨s : en bref,
   utiliser une solution dâ€™IAM pour gÃ©rer ces aspects Ã  votre place. Câ€™est
   gÃ©nÃ©ralement plus simple Ã  maintenir et câ€™est surtout souvent meilleur
   pour lâ€™expÃ©rience utilisateur. â€¦
   Lire la suite

   MÃ©thode

AmÃ©lioration continue : Comment rester dynamique Ã  mesure que lâ€™Ã©quipe
sâ€™agrandit ?

   PostÃ© le 01/10/2019 par Etienne Girot

   DiffÃ©rentes Ã©tudes1 soutiennent quâ€™une Ã©quipe performante est une
   Ã©quipe qui est capable de remettre frÃ©quemment en question ses modes de
   fonctionnement afin dâ€™apprendre et sâ€™amÃ©liorer en continu. Pour y
   arriver, elle : favorise l'Ã©mergence de nouvelles idÃ©es a moyen de
   valider ou dâ€™invalider efficacement la pertinence de ces nouvelles
   idÃ©es est en mesure dâ€™aligner ses membres derriÃ¨re les idÃ©es retenues
   comme Ã©tant pertinentes Or, plus une Ã©quipe grandit (aussi bien en
   nombre de membres quâ€™en temps passÃ© Ã  travailler ensemble) plus elle
   est sujette Ã â€¦
   Lire la suite

   MÃ©thode innovation

Culture Innovâ€™ : Quel ROI attendu ?

   PostÃ© le 01/10/2019 par Sylvain Fagnent, Matthieu VETTER
   [school.png]

   AprÃ¨s des annÃ©es et des millions investis sous la menace de la
   disruption, les Directions reviennent Ã  une logique plus ROIste. Ce
   mouvement est sain pour optimiser les ressources rares et donner du
   sens au travail des innovateurs. Le risque est cependant de tuer dans
   lâ€™oeuf des pÃ©pites potentielles en pilotant lâ€™innovation comme un
   business opÃ©rationnel. En fonction des objectifs, les retours sur
   investissement (ROI) dâ€™une dÃ©marche dâ€™innovation seront diffÃ©rents. Et
   dans un monde de plus en plus focalisÃ© sur la rentabilitÃ© Ã  court
   terme,â€¦
   Lire la suite

   Data Science

Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes

   PostÃ© le 30/09/2019 par Annabelle Blangero
   [school.png]

   Lâ€™usage des algorithmes de traitement de donnÃ©es â€“ de la simple requÃªte
   SQL aux puissants algorithmes de recommandation et de personnalisation
   des gÃ©ants de la Tech â€“ sâ€™est popularisÃ© ces derniÃ¨res annÃ©es,
   notamment pour des utilisateurs traditionnellement hors du domaine IT.
   Cet usage se retrouve dans tous les secteurs (industrie, Ã©ducation,
   santÃ©, sÃ©curitÃ©, etc.) et tend Ã  dÃ©lÃ©guer de plus en plus de dÃ©cisions
   Ã  des systÃ¨mes automatisÃ©s. Cette appropriation par le plus grand
   nombre rend les naufrages encore plus probables, et lâ€™exemple de
   Cambridgeâ€¦
   Lire la suite

   Archi & techno

Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos valeurs et le
garant de la vision technique dâ€™OCTO.â€

   PostÃ© le 27/09/2019 par Joy Boswell
   [archi.png]

   Chez OCTO depuis plus de 10 ans , Meriem fait partie des personnes
   fondatrices de lâ€™entreprise. Ancienne leadeuse de la tribu Nouvelles
   Architectures de DonnÃ©es, elle est dÃ©sormais CTO et participe Ã  la
   dÃ©finition de la vision stratÃ©gique et technique dâ€™OCTO. Qui de mieux
   pour nous parler du â€œtech leading Ã  la OCTOâ€ ?
   Lire la suite

   Data Science

Mise en application de DVC sur un projet de Machine Learning

   PostÃ© le 27/09/2019 par Nicolas TOUSSAINT, JÃ©rÃ©my Bouhi
   [school.png]

   Introduction DVC (Data Version Control) est un package Python qui
   permet de gÃ©rer plus facilement ses projets de Data science. Cet outil
   est une extension de Git pour le Machine Learning, comme lâ€™Ã©nonce son
   principal contributeur Dmitry Petrov dans cette prÃ©sentation. DVC est Ã 
   la fois comparable et complÃ©mentaire Ã  Git. Il va sâ€™occuper de
   synchroniser vos donnÃ©es et votre code. Il est donc particuliÃ¨rement
   intÃ©ressant dans le cadre dâ€™un projet de Machine Learning oÃ¹ le modÃ¨le
   et les donnÃ©es Ã©voluent au fil du dÃ©veloppement.â€¦
   Lire la suite

   Archi & techno

BD â€“ Le DÃ©ploiement Continu (CD)

   PostÃ© le 26/09/2019 par Aryana Peze
   [archi.png]

   Hello ! Lors de la BD prÃ©cÃ©dente, nous avons abordÃ© le sujet de la CI
   (IntÃ©gration Continue). Et impossible de parler de CI sans parler de CD
   (DÃ©ploiement Continu)! En thoÃ©rie, la CD implique un dÃ©ploiement
   automatique et quasi-systÃ©matique de chaque modification du code sur
   l'environnement de production. Les mises en production sont rÃ©guliÃ¨res
   et ne sont plus une source de stresse, et l'environnement de production
   est ainsi toujours Ã  jour. En pratique, c'est un objectif trÃ¨s
   compliquÃ© Ã  atteindre, et pas toujours adaptÃ©. (Petite parenthÃ¨seâ€¦
   Lire la suite

   Agile

Dâ€™Ã©tudiant Ã  mentor : rencontre avec notre Octo Thomas Le Flohic

   PostÃ© le 24/09/2019 par CÃ©line Audibert
   [agile.png]

   Thomas a fait un vÃ©ritable parcours â€œÃ  la OCTOâ€ : aprÃ¨s son Ã©cole
   dâ€™ingÃ©, il rentre en stage au sein de notre tribu VIBE (Virtual
   Immersion and Bot Experience) et rejoint dÃ©finitivement lâ€™entreprise en
   intÃ©grant le programme Skool. Un de ses profs Ã  lâ€™Ã©cole Ã©tait un Octo,
   Fabien. Câ€™est ce qui lui a donnÃ© envie de venir frapper Ã  notre porte.
   Comme lui, Thomas a voulu garder un lien avec lâ€™Ã©cole et transmettre
   son savoir. Câ€™est ainsi quâ€™il sâ€™est lancÃ© dans lâ€™accompagnement dâ€™un
   projet deâ€¦
   Lire la suite

   Archi & techno

Interview CÃ©line Gilet â€“ Â« Le Tech Lead nâ€™est pas un super hÃ©ros ! Â»

   PostÃ© le 23/09/2019 par CÃ©line Audibert
   [archi.png]

   Depuis plus de 4 ans chez OCTO, CÃ©line, membre de la tribu CRAFT, est
   devenue une rÃ©fÃ©rence parmi nos Tech Lead. DÃ©couvrez sa vision de ce
   rÃ´le Ã  part. Pour toi, quel est le rÃ´le du Tech Lead ?  Pour moi, câ€™est
   faire en sorte que lâ€™Ã©quipe au sens large (DÃ©veloppeurs, Ops,
   Fonctionnels, Product Owner) arrive Ã  dÃ©livrer rÃ©guliÃ¨rement de la
   valeur. ConcrÃ¨tement, il sâ€™agit de jongler et prioriser en permanence
   entre plusieurs casquettes : expertise, accompagnement, coaching et
   formation.
   Lire la suite

   MÃ©thode innovation

Injonctions paradoxales : un MVP â€¦ mais pour tous !

   PostÃ© le 20/09/2019 par Dominique Lequepeys, Sylvain Fagnent
   un MVP pour tous

   Un MVP ... mais pour tout le monde ! Et si vous vouliez lâ€™entendre
   cette injonction ? Mise en scÃ¨ne, Ã©coutez la. Les racines du paradoxe
   D'un cÃ´tÃ©, les managers sont sous la pression du timing : ils sont
   sÃ©duits par le concept de MVP, Minimum Viable Product, prÃ©sentÃ© comme
   un moyen d'accÃ©lÃ©rer la mise sur le marchÃ©. D'un autre, ils sont sous
   la pression du chiffre : ils ont du mal Ã  accepter qu'on se prive d'une
   partie du marchÃ© potentiel. En outre, ilsâ€¦
   Lire la suite
   1234>
   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #alternate OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires
   OCTO Talks ! Â» Lâ€™optimisation bayÃ©sienne par lâ€™exemple : Ã  quoi Ã§a sert
   et comment Ã§a marche ? Flux des commentaires Le chemin vers lâ€™omnicanal
   Le demi-cercle (Ã©pisode 49 â€” Cocktail) alternate alternate

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

Lâ€™optimisation bayÃ©sienne par lâ€™exemple : Ã  quoi Ã§a sert et comment Ã§a marche
?

   PostÃ© le 02/08/2018 par Louis Boutin, Paul De Nonancourt
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   â€œSi jâ€™ai une valeur y qui est fonction de x, comment faire pour
   dÃ©terminer la valeur de x minimisant ou maximisant la valeur de y ?â€
   tel est le problÃ¨me de base du domaine de lâ€™optimisation, qui se
   dÃ©cline Ã  de trÃ¨s nombreux cas dâ€™usage allant de â€œcomment fixer le prix
   pour maximiser un profitâ€ Ã  â€œquelle stratÃ©gie mon robot doit-il adopter
   pour rester en Ã©quilibreâ€.

   Nous vous proposons dans cet article une introduction aux stratÃ©gies
   dâ€™optimisation bayÃ©sienne, un sous-domaine regroupant des techniques
   trÃ¨s puissantes pour converger efficacement vers des valeurs optimales
   lorsquâ€™on fait face Ã  une situation oÃ¹ le nombre dâ€™observations est
   limitÃ© par des contraintes de temps ou de matÃ©riel.

   Vous souhaitez voir un cas dâ€™usage de ces algorithmes ? Comprendre
   comment ces derniers fonctionnent et comment les implÃ©menter ? Alors
   vous Ãªtes au bon endroit. Cet article prend pour exemple la
   problÃ©matique de la configuration automatique des paramÃ¨tres dâ€™une base
   de donnÃ©es pour illustrer lâ€™optimisation bayÃ©sienne. Nous prÃ©senterons
   un exemple dâ€™implÃ©mentation en Python ainsi que quelques autres cas
   dâ€™usage pour cette approche.

1 â€“ Lâ€™optimisation bayÃ©sienne au service de la performance dâ€™une base de
donnÃ©es

1.1 â€“ Un exemple concret

   Chez OCTO Technology, nous avons rÃ©cemment dÃ©cidÃ© dâ€™explorer des
   questions de configuration automatique du fonctionnement de bases de
   donnÃ©es, un domaine particuliÃ¨rement large mais avec plusieurs
   problÃ©matiques que lâ€™on peut distinguer. Lâ€™une dâ€™elles en particulier
   va nous intÃ©resser ici car elle constitue un bon exemple de situation
   oÃ¹ lâ€™optimisation bayÃ©sienne se rÃ©vÃ¨le pertinente.

   Imaginons une base de donnÃ©es, pas nÃ©cessairement complexe, avec un
   ensemble de paramÃ¨tres Ã  rÃ©gler : cache, mÃ©moires partagÃ©es, nombre de
   connexions simultanÃ©es maximum, etc. Ã‰tant donnÃ© une charge de travail,
   tel quâ€™un ensemble de requÃªtes exÃ©cutÃ©es sur cette base de donnÃ©es, on
   souhaite dÃ©terminer automatiquement les valeurs de paramÃ¨tres qui nous
   permettront dâ€™obtenir les meilleurs rÃ©sultats (par exemple, nous
   voudrions complÃ©ter lâ€™exÃ©cution de notre charge le plus rapidement
   possible). Il existe des rÃ¨gles mÃ©tier fournissant des pistes pour
   fixer ces paramÃ¨tres : le site PgTune propose par exemple des
   configurations pour Postgres en fonction du hardware (RAM, CPU). Mais
   ces rÃ¨gles ne sont pas forcÃ©ment adaptÃ©es Ã  notre charge de travail,
   sont rarement optimales et ne sâ€™appuient pas nÃ©cessairement sur des
   thÃ©ories. Pour rÃ©sumer, on souhaiterait rendre le choix dâ€™une bonne
   configuration le plus automatisÃ© et le plus efficace possible mais il
   est en rÃ©alitÃ© trÃ¨s difficile de dÃ©terminer des rÃ¨gles prÃ©cises
   rÃ©gissant ces paramÃ¨tres.

   Heureusement pour nous, il sâ€™agit finalement dâ€™un problÃ¨me classique
   dâ€™optimisation pour lequel de nombreuses solutions existent : nous
   voulons trouver rapidement une configuration (câ€™est-Ã -dire un ensemble
   de paramÃ¨tres) maximisant ou minimisant une mÃ©trique de performance.
   Pour cela, nous devons tout de mÃªme prendre en compte un certain nombre
   de contraintes :
     * Tester une configuration prend du temps car nous devons tester une
       charge dans son intÃ©gralitÃ© sur notre base de donnÃ©es, nous ne
       pouvons donc pas tester un nombre illimitÃ© de configurations pour
       dÃ©terminer la meilleure.
     * Le comportement de la performance de la base de donnÃ©es en fonction
       de la configuration est une boÃ®te noire, nous ne pouvons que donner
       une configuration en entrÃ©e et observer une performance en sortie.

   on optimise la configuration d'une une base de donnÃ©es en fonction
   d'une charge et une mÃ©trique de performance

   Le problÃ¨me de dÃ©part : comment trouver rapidement la configuration
   optimisant la performance, câ€™est-Ã -dire ici minimisant le temps
   dâ€™exÃ©cution ?

2.2 â€“ Les avantages de lâ€™optimisation bayÃ©sienne

   Compte tenu de nos contraintes, il est nÃ©cessaire de trouver une
   stratÃ©gie dâ€™optimisation pas Ã  pas efficace : nous souhaitons, en un
   minimum dâ€™observations, dÃ©terminer la meilleure configuration. En
   consultant la littÃ©rature acadÃ©mique, nous avons ainsi identifiÃ© deux
   articles explorant Ã©galement le problÃ¨me de la configuration
   automatique dâ€™une base de donnÃ©es : iTuned (2009) et Ottertune (2017).
   Les auteurs de ces deux publications proposent des solutions similaires
   basÃ©es sur lâ€™optimisation bayÃ©sienne afin de rechercher une
   configuration optimale.

   Cette approche sÃ©quentielle se trouve Ãªtre particuliÃ¨rement adaptÃ©e Ã 
   notre problÃ¨me de par son principe. Lâ€™objectif est dâ€™utiliser un petit
   nombre dâ€™observations pour estimer un comportement plus global. En
   exploitant efficacement la connaissance accumulÃ©e sur notre fonction
   boÃ®te noire, on espÃ¨re minimiser le nombre dâ€™observations et converger
   rapidement vers la configuration optimale.

   Ã‰tudions maintenant plus en dÃ©tail le fonctionnement dâ€™un algorithme
   dâ€™optimisation bayÃ©sienne avant de passer Ã  une implÃ©mentation concrÃ¨te
   pour rÃ©pondre Ã  notre problÃ¨me.

2 â€“ Sous le capot de lâ€™optimisation bayÃ©sienne

2.1 â€“ Extraire de lâ€™information Ã  partir dâ€™un nombre limitÃ© dâ€™observations

   Lâ€™optimisation bayÃ©sienne est une approche probabiliste basÃ©e sur
   lâ€™infÃ©rence bayÃ©sienne. En somme, cela veut dire quâ€™on va chercher Ã 
   exploiter ce quâ€™on connaÃ®t dÃ©jÃ , donc lâ€™ensemble des Ã©vÃ©nements
   prÃ©cÃ©demment observÃ©s, pour infÃ©rer la probabilitÃ© des Ã©vÃ©nements que
   nous nâ€™avons pas encore observÃ©s. Dans le cadre de lâ€™optimisation
   bayÃ©sienne, nous partons dâ€™un ensemble dâ€™observations dont nous
   connaissons le rÃ©sultat et nous dÃ©terminons pour chaque valeur ???? en
   dehors de cet ensemble la distribution de probabilitÃ© de lâ€™Ã©valuation
   de ???? en ce point ????.


   Dans cet exemple, on cherche Ã  minimiser une fonction quâ€™on ne connaÃ®t
   pas. Comment utiliser ces premiÃ¨res observations pour infÃ©rer les
   valeurs lorsque x varie entre -2 et 2 ?


   Mais comment calculer cette distribution de probabilitÃ© ? Parmi toutes
   les mÃ©thodes existantes, nous retiendrons ici lâ€™une des mÃ©thodes
   classiques qui consiste Ã  utiliser les processus gaussiens qui
   gÃ©nÃ©ralisent le concept de loi normale aux fonctions. Nous ne
   dÃ©velopperons pas cette mÃ©thode un peu complexe. Lâ€™important est de
   comprendre que cette approche nous permet de gÃ©nÃ©rer pour chaque point
   une distribution de probabilitÃ© caractÃ©risÃ©e par une moyenne Âµ (la
   valeur la plus probable) et un Ã©cart-type Ïƒ (la mesure de la dispersion
   probable de la valeur autour de la moyenne).

   Pour le lecteur souhaitant aller plus loin, cet excellent article de
   blog dÃ©veloppe davantage les processus gaussiens sans aller trop loin
   dans les dÃ©tails mathÃ©matiques. La publication originale est ensuite la
   source la plus exhaustive sur le sujet.

   Les processus gaussiens permettent dâ€™infÃ©rer la distribution de
   probabilitÃ© pour chaque point avec la valeur moyenne estimÃ©e Âµ en
   pointillÃ©, et lâ€™Ã©cart-type Ïƒ reprÃ©sentÃ© par la zone vert pÃ¢le.

   Il est Ã  noter quâ€™on ne pourra pas reprÃ©senter cette distribution pour
   tous les points. Nous ne considÃ©rons cette distribution que sur un
   ensemble fini de points : câ€™est notre espace de recherche. Ainsi nous
   aurons, pour chaque point de cet espace de recherche, une valeur
   centrale, la moyenne Î¼, et une certaine dispersion autour de cette
   moyenne, lâ€™Ã©cart-type Ïƒ. Ce dernier sera dâ€™autant plus faible que lâ€™on
   sera proche dâ€™un point dÃ©jÃ  observÃ©.

   Nous sommes Ã  prÃ©sent capable dâ€™infÃ©rer le comportement de notre
   fonction Ã  partir de nos Ã©valuations. Mais comment choisir quel point
   Ã©valuer : quel point a les meilleures chances dâ€™Ãªtre un minimum ?

2.2 â€“ DÃ©terminer les points Ã  plus fort potentiel avec la fonction
dâ€™acquisition

   Rappelons-nous notre objectif : minimiser ou maximiser la fonction
   observÃ©e, câ€™est-Ã -dire trouver le point pour lequel lâ€™Ã©valuation est
   minimisÃ©e ou maximisÃ©e. Le choix du point utilisÃ© pour lâ€™Ã©valuation
   suivante est donc soumis Ã  un double critÃ¨re. Nous voulons dâ€™une part
   gagner en connaissance sur le comportement de la fonction et donc
   choisir une zone de lâ€™espace de recherche oÃ¹ lâ€™inconnu est grand :
   câ€™est lâ€™exploration. Dâ€™autre part, nous souhaitons trouver le point qui
   minimise/maximise notre fonction : câ€™est lâ€™exploitation. Ces deux
   notions sont matÃ©rialisÃ©es par les indicateurs statistiques citÃ©s
   prÃ©cÃ©demment que sont lâ€™Ã©cart-type et la moyenne. Quand lâ€™Ã©cart-type
   est grand, câ€™est que la zone est mal connue et donc intÃ©ressante Ã 
   explorer. Quand la moyenne est petite/grande, câ€™est que la zone
   observÃ©e est intÃ©ressante pour trouver un minimum/maximum.

   Ce compromis entre exploration et exploitation est exprimÃ© par une
   fonction dâ€™acquisition. Cette fonction associe Ã  chaque point de
   lâ€™espace de recherche un potentiel pour Ãªtre lâ€™optimal. Il existe
   plusieurs fonctions dâ€™acquisitions, avec des variations subtiles mais
   gardant le mÃªme principe directeur : exprimer le potentiel dâ€™un point.
   fonction d'acquisition Upper Confidence Bound

   Upper Confidence Bound est un exemple de fonction dâ€™acquisition, le
   coefficient k exprime le poids donnÃ© Ã  lâ€™exploration dans le compromis
   Ã©voquÃ© prÃ©cÃ©demment Âµ : moyenne â€“ Ïƒ : Ã©cart-type


   Ã€ chaque Ã©tape de notre optimisation, le point choisi pour lâ€™Ã©valuation
   donc est celui qui maximise notre fonction dâ€™exploitation.


   En bleu, notre fonction dâ€™acquisition nous indique les points Ã  plus
   fort potentiel Ã  tester : ils reprÃ©sent le compromis entre exploitation
   (prÃ¨s du minimum) et exploration (dans des zones inconnues)

   Trouver le nouveau point Ã  Ã©valuer implique donc dâ€™Ã©valuer notre
   fonction dâ€™acquisition pour tout notre espace de recherche. Cependant
   ces Ã©valuations seront beaucoup moins coÃ»teuses en comparaison Ã 
   lâ€™Ã©valuation de la fonction observÃ©e. La fonction dâ€™acquisition Ã©tant
   simple et connue, on peut facilement lâ€™Ã©valuer en un grand nombre de
   points pour trouver le maximum. Le maximum trouvÃ© correspond au
   prochain point Ã  tester et une fois lâ€™observation rÃ©alisÃ©e, on peut
   actualiser notre optimisation avec cette nouvelle information et
   repartir depuis le dÃ©but, en rÃ©pÃ©tant jusquâ€™Ã  converger.

   Pour bien comprendre cela, reprenons notre exemple en voyant aprÃ¨s
   plusieurs itÃ©rations comment chaque boucle apporte de lâ€™information
   supplÃ©mentaire jusquâ€™Ã  atteindre un minimum. On peut comparer enfin
   lâ€™approximation obtenue Ã  la fonction originale (inconnue Ã  la base) Ã 
   minimiser et vÃ©rifier lâ€™efficacitÃ© de lâ€™algorithme.

   Le cycle dâ€™optimisation bayÃ©sienne Ã  la recherche la valeur donnant le
   rÃ©sultat minimal sur dix itÃ©rations

   Le rÃ©sultat final aprÃ¨s dix itÃ©rations avec lâ€™approximation Âµ(x) faite
   par lâ€™optimisation bayÃ©sienne comparÃ© Ã  la â€œvraieâ€ fonction Ã 
   minimiser, inconnue au dÃ©part

   Pour voir cela en pratique, passons Ã  un exemple plus concret !

3 â€“ Et en pratique, comment Ã§a se passe ?

   Maintenant que nous en savons un peu plus sur lâ€™optimisation
   bayÃ©sienne, reprenons notre problÃ¨me initial et voyons comment
   implÃ©menter en Python un algorithme rÃ©pondant Ã  ce mÃªme problÃ¨me.

   Supposons une situation oÃ¹ nous souhaitons configurer notre base de
   donnÃ©es sur laquelle nous pouvons faire varier deux paramÃ¨tres param_1
   et param_2. Le but est de dÃ©terminer quelles sont les valeurs de ces
   deux paramÃ¨tres permettant de minimiser le temps pour complÃ©ter une
   charge de travail (par exemple un ensemble de requÃªtes). Les rÃ¨gles
   mÃ©tier dont nous disposons ne nous permettent pas de dÃ©terminer les
   valeurs optimales pour ces paramÃ¨tres et nous fournissent au mieux des
   bornes dans lesquelles rechercher lâ€™optimum.

3.1 â€“ Une implÃ©mentation en Python avec scikit-optimize

   Nous allons ainsi utiliser le package Python scikit-optimize (basÃ© sur
   scikit-learn) pour mettre en place un workflow prenant en entrÃ©e un
   intervalle pour nos valeurs de paramÃ¨tres et cherchant lâ€™ensemble
   donnant les meilleurs rÃ©sultats. Tout le code du workflow et des
   visualisations est disponible sous forme de notebook Jupyter.

   CommenÃ§ons par dÃ©finir notre espace de recherche sous forme de
   dictionnaire :
search_space = {
  'param_1': (0.0, 10.0),
  'param_2': (0.0, 0.0)
}

   Il faut dÃ©sormais instancier un objet Optimizer, tirÃ© du package
   scikit-optimize, qui va se charger de la majeure partie du travail.
   Nous devons prÃ©ciser Ã  lâ€™Optimizer lâ€™espace sur lequel il va effectuer
   sa recherche. Comme expliquÃ© prÃ©cÃ©demment, nous allons utiliser un
   estimateur basÃ© sur les processus gaussiens (ou Gaussian Process,
   â€œGPâ€).

   Pour Ã©viter des effets de bord des processus gaussiens survenant
   lorsque lâ€™espace des observations est vide (ou quasi-vide), il est
   aussi prÃ©fÃ©rable de tester les premiers points de maniÃ¨re alÃ©atoire, ce
   que lâ€™on prÃ©cise par le paramÃ¨tre n_initial_points.
opt = Optimizer([search_space['param_1'], search_space['param_2']],
                "GP",
                n_initial_points=3)

   Il nâ€™y a maintenant plus quâ€™Ã  faire tourner la boucle dâ€™optimisation.
   La force de scikit-optimize se situe dans la possibilitÃ© de faire
   tourner des workflows relativement asynchrones grÃ¢ce aux fonctions ask
   et tell. Ã€ chaque Ã©tape, nous allons demander (ask) quelle est la
   configuration qui prÃ©sente le meilleur potentiel pour pouvoir la
   tester, câ€™est-Ã -dire exÃ©cuter notre charge de travail, avant dâ€™obtenir
   un rÃ©sultat que nous allons ajouter Ã  nos observations (tell). On
   boucle ensuite autant de fois que lâ€™on souhaite ou jusquâ€™Ã  ce quâ€™un
   critÃ¨re de satisfaction soit atteint.
for _ in range(20):
    # Quelle est la prochaine configuration Ã  tester ?
    next_config = opt.ask()  # Renvoie une liste

    # Ici, nous avons une dÃ©pendance extÃ©rieure puisque nous devons mettre Ã 
    # jour la configuration de la base de donnÃ©es puis tester notre charge.
    # Faisons l'hypothÃ¨se que ces interfaces ont Ã©tÃ© dÃ©finies ailleurs dans le c
ode.
    database.update_configuration(next_config)
    runtime = database.benchmark(workload)

    opt.tell(next_config, runtime)

   Si tout se passe bien, lâ€™optimiseur convergera ensuite naturellement
   vers un couple de paramÃ¨tres prÃ©sentant la meilleure performance.

   Pour se reprÃ©senter cela, supposons que le temps nÃ©cessaire pour
   complÃ©ter la charge se comporte de la maniÃ¨re suivante en fonction des
   paramÃ¨tres param_1 et param_2 :

   Ce comportement est ici hypothÃ©tique et lâ€™optimiseur ne le connaÃ®t pas.
   Voici comment Ã©volue lâ€™optimisation pour dÃ©terminer le minimum Ã  chaque
   itÃ©ration (pour rappel, le dÃ©tail est disponible dans ce notebook) :

   Lâ€™optimisation bayÃ©sienne dÃ©montre lÃ  tout son intÃ©rÃªt : en un nombre
   dâ€™observations trÃ¨s restreint (de lâ€™ordre de la dizaine), nous sommes
   en mesure de dÃ©terminer les valeurs des paramÃ¨tres pour lesquelles
   notre base de donnÃ©es a les meilleurs rÃ©sultats. Rapidement,
   lâ€™algorithme converge vers des valeurs autour de (6, 13) en gardant
   tout de mÃªme un caractÃ¨re exploratoire pour sâ€™assurer de ne pas Ãªtre
   coincÃ© sur un minimum local si le comportement de la base de donnÃ©es
   avait Ã©tÃ© plus complexe.

3.2 â€“ Gestion du bruit et de la variabilitÃ© de lâ€™environnement

   Sur un cas rÃ©el, il faut cependant se poser la question du bruit :
   lâ€™optimisation bayÃ©sienne est-elle rÃ©siliente lorsque les observations
   sont bruitÃ©es (dans notre cas, on peut par exemple avoir un temps qui
   varie Ã  cause de perturbations rÃ©seaux) ? La rÃ©ponse est oui, dans une
   certaine mesure. Sur un cas plus compliquÃ©, disponible sur ce notebook,
   on voit quâ€™un niveau de bruit infÃ©rieur Ã  5% peut perturber
   lâ€™algorithme sans que cela ne soit gÃªnant pour dÃ©terminer un minimum
   rapidement. Un autre exemple sur un espace Ã  une dimension dÃ©montre
   Ã©galement cela sur le repository du package scikit-optimize.

   Lorsque le bruit est plus Ã©levÃ©, il est possible de jouer sur des
   paramÃ¨tres qui peuvent prendre en compte lâ€™incertitude (câ€™est le cas du
   paramÃ¨tre alpha de lâ€™estimateur scikit-learn GaussianProcessRegressor).
   Mais lorsque cette variabilitÃ© est trop Ã©levÃ©e, lâ€™algorithme ne peut
   simplement pas fonctionner correctement. Pour cette raison, il est
   conseillÃ© avant dâ€™utiliser une stratÃ©gie dâ€™optimisation bayÃ©sienne de
   vÃ©rifier que lâ€™environnement est suffisamment stable et que les
   observations sont reproductibles. AprÃ¨s tout, on ne peut pas optimiser
   ce qui varie.

   Des observations trop bruitÃ©es ne permettent pas de converger vers un
   minimum : ici, les rÃ©sultats varient trop pour pouvoir dÃ©cider quel
   point tester ensuite

3.3 â€“ Application au tuning de modÃ¨les de machine learning

   Lâ€™exemple prÃ©cÃ©dent dâ€™application de lâ€™optimisation bayÃ©sienne est
   relativement prÃ©cis, mais la stratÃ©gie peut facilement se gÃ©nÃ©raliser Ã 
   dâ€™autres applications oÃ¹ lâ€™on cherche un ensemble de paramÃ¨tres
   maximisant la performance mais que chaque observation est coÃ»teuse.

   Câ€™est notamment le cas de la gestion des hyper-paramÃ¨tres dâ€™un modÃ¨le
   de machine learning, la librairie scikit-optimize est dâ€™ailleurs
   taillÃ©e pour ce type dâ€™utilisation. En effet, lorsquâ€™on utilise un
   modÃ¨le de machine learning, il est difficile dâ€™Ã©valuer directement la
   valeur optimale de certains paramÃ¨tres (par exemple le nombre dâ€™arbres
   et leur profondeur pour un RandomForestClassifier). Utiliser
   lâ€™optimisation bayÃ©sienne pour rÃ©soudre le problÃ¨me Ã  notre place est
   tout Ã  fait possible : lâ€™entrÃ©e de notre problÃ¨me correspond aux
   valeurs des hyper-paramÃ¨tres et la performance Ã  optimiser est une
   mÃ©trique au choix de lâ€™utilisateur (prÃ©cision, AUC, etc.).

   Comment dÃ©terminer rapidement les valeurs des hyper-paramÃ¨tres
   maximisant la mÃ©trique de performance ?


   Cette approche permet notamment de gagner en temps dâ€™optimisation en
   rÃ©duisant le nombre dâ€™observations par rapport Ã  des algorithmes type
   RandomSearch ou GridSearch qui demandent plus de tests pour arriver Ã 
   des rÃ©sultats. Câ€™est dâ€™ailleurs lâ€™approche plÃ©biscitÃ©e en 2017 par
   Google pour le tuning dâ€™hyper-paramÃ¨tres qui met mÃªme en place un
   systÃ¨me de â€œhyperparameter tuning as a serviceâ€ sur Cloud ML.

   Convaincu par lâ€™optimisation bayÃ©sienne ? Vous souhaitez optimiser
   rapidement vos modÃ¨les de machine learning ? Jetez donc un oeil aux
   solutions prÃªtes Ã  lâ€™emploi de librairies Python comme scikit-optimize
   ou bayesian-optimization qui prÃ©sentent toutes les deux des exemples
   dâ€™implÃ©mentation appliquÃ©e au tuning de modÃ¨les ici et ici.

Conclusion

   Lâ€™approche bayÃ©sienne est donc efficace pour rÃ©pondre au problÃ¨me du
   choix de paramÃ¨tres optimaux lorsque le comportement de la fonction est
   mal connue, que les observations sont coÃ»teuses et quâ€™une approche
   alÃ©atoire ou brute force nâ€™est pas envisageable. Les algorithmes
   dâ€™optimisation bayÃ©sienne se prÃªtent donc bien Ã  la configuration de
   systÃ¨mes dâ€™informations comme une base de donnÃ©es, Ã  condition de bien
   connaÃ®tre son environnement et sa variabilitÃ© !

   Enfin, on a pu rÃ©cemment voir de grandes entreprises communiquer sur
   des initiatives exploitant ces approches. Des ingÃ©nieurs de Twitter par
   exemple, dÃ©veloppent un systÃ¨me utilisant lâ€™optimisation bayÃ©sienne
   pour configurer automatiquement et en continu les paramÃ¨tres JVM de
   leurs services. En juin 2018, Facebook a prÃ©sentÃ© Spiral, une librairie
   destinÃ©e Ã  la configuration automatique et temps rÃ©el des services
   avec, en prÃ©paration, lâ€™utilisation de lâ€™optimisation bayÃ©sienne pour
   la configuration de paramÃ¨tres. Autant dâ€™approches illustrant la force
   de lâ€™optimisation bayÃ©sienne lorsquâ€™on lâ€™applique Ã  la configuration de
   systÃ¨mes informatiques.
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Cet article a Ã©tÃ© postÃ© dans Data Science.

Articles rÃ©cents

     * Comment conserver les mots de passe de ses utilisateurs en 2019 ?
     * AmÃ©lioration continue : Comment rester dynamique Ã  mesure que
       lâ€™Ã©quipe sâ€™agrandit ?
     * Culture Innovâ€™ : Quel ROI attendu ?
     * Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes
     * Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos
       valeurs et le garant de la vision technique dâ€™OCTO.â€

Laisser un commentaire Annuler la rÃ©ponse

   Votre adresse de messagerie ne sera pas publiÃ©e. Les champs
   obligatoires sont indiquÃ©s avec *

   Commentaire
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   [ ] Me notifier par mail en cas de nouveaux commentaires

   Nom * ______________________________

   Adresse de messagerie * ______________________________

   Site web ______________________________
   (BUTTON) Laisser un commentaire
   Ce formulaire est protÃ©gÃ© par Google Recaptcha
   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

   SÃ©curitÃ©

Comment conserver les mots de passe de ses utilisateurs en 2019 ?

   PostÃ© le 02/10/2019 par Fabien Leite
   Mot de passe

   Lorsque vous concevez une application, vous vous posez forcÃ©ment la
   question de lâ€™authentification et du contrÃ´le dâ€™accÃ¨s. Pour Ã§a,
   plusieurs mÃ©thodes sont disponibles et la premiÃ¨re qui vient
   gÃ©nÃ©ralement Ã  lâ€™esprit est lâ€™utilisation dâ€™un couple identifiant / mot
   de passe. Dans la mesure du possible, on prÃ©fÃ¨rera utiliser une
   solution dÃ©diÃ©e Ã  lâ€™authentification et au contrÃ´le dâ€™accÃ¨s : en bref,
   utiliser une solution dâ€™IAM pour gÃ©rer ces aspects Ã  votre place. Câ€™est
   gÃ©nÃ©ralement plus simple Ã  maintenir et câ€™est surtout souvent meilleur
   pour lâ€™expÃ©rience utilisateur. â€¦
   Lire la suite

   MÃ©thode

AmÃ©lioration continue : Comment rester dynamique Ã  mesure que lâ€™Ã©quipe
sâ€™agrandit ?

   PostÃ© le 01/10/2019 par Etienne Girot

   DiffÃ©rentes Ã©tudes1 soutiennent quâ€™une Ã©quipe performante est une
   Ã©quipe qui est capable de remettre frÃ©quemment en question ses modes de
   fonctionnement afin dâ€™apprendre et sâ€™amÃ©liorer en continu. Pour y
   arriver, elle : favorise l'Ã©mergence de nouvelles idÃ©es a moyen de
   valider ou dâ€™invalider efficacement la pertinence de ces nouvelles
   idÃ©es est en mesure dâ€™aligner ses membres derriÃ¨re les idÃ©es retenues
   comme Ã©tant pertinentes Or, plus une Ã©quipe grandit (aussi bien en
   nombre de membres quâ€™en temps passÃ© Ã  travailler ensemble) plus elle
   est sujette Ã â€¦
   Lire la suite

   MÃ©thode innovation

Culture Innovâ€™ : Quel ROI attendu ?

   PostÃ© le 01/10/2019 par Sylvain Fagnent, Matthieu VETTER
   [school.png]

   AprÃ¨s des annÃ©es et des millions investis sous la menace de la
   disruption, les Directions reviennent Ã  une logique plus ROIste. Ce
   mouvement est sain pour optimiser les ressources rares et donner du
   sens au travail des innovateurs. Le risque est cependant de tuer dans
   lâ€™oeuf des pÃ©pites potentielles en pilotant lâ€™innovation comme un
   business opÃ©rationnel. En fonction des objectifs, les retours sur
   investissement (ROI) dâ€™une dÃ©marche dâ€™innovation seront diffÃ©rents. Et
   dans un monde de plus en plus focalisÃ© sur la rentabilitÃ© Ã  court
   terme,â€¦
   Lire la suite

   Data Science

Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes

   PostÃ© le 30/09/2019 par Annabelle Blangero
   [school.png]

   Lâ€™usage des algorithmes de traitement de donnÃ©es â€“ de la simple requÃªte
   SQL aux puissants algorithmes de recommandation et de personnalisation
   des gÃ©ants de la Tech â€“ sâ€™est popularisÃ© ces derniÃ¨res annÃ©es,
   notamment pour des utilisateurs traditionnellement hors du domaine IT.
   Cet usage se retrouve dans tous les secteurs (industrie, Ã©ducation,
   santÃ©, sÃ©curitÃ©, etc.) et tend Ã  dÃ©lÃ©guer de plus en plus de dÃ©cisions
   Ã  des systÃ¨mes automatisÃ©s. Cette appropriation par le plus grand
   nombre rend les naufrages encore plus probables, et lâ€™exemple de
   Cambridgeâ€¦
   Lire la suite

   Archi & techno

Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos valeurs et le
garant de la vision technique dâ€™OCTO.â€

   PostÃ© le 27/09/2019 par Joy Boswell
   [archi.png]

   Chez OCTO depuis plus de 10 ans , Meriem fait partie des personnes
   fondatrices de lâ€™entreprise. Ancienne leadeuse de la tribu Nouvelles
   Architectures de DonnÃ©es, elle est dÃ©sormais CTO et participe Ã  la
   dÃ©finition de la vision stratÃ©gique et technique dâ€™OCTO. Qui de mieux
   pour nous parler du â€œtech leading Ã  la OCTOâ€ ?
   Lire la suite

   Data Science

Mise en application de DVC sur un projet de Machine Learning

   PostÃ© le 27/09/2019 par Nicolas TOUSSAINT, JÃ©rÃ©my Bouhi
   [school.png]

   Introduction DVC (Data Version Control) est un package Python qui
   permet de gÃ©rer plus facilement ses projets de Data science. Cet outil
   est une extension de Git pour le Machine Learning, comme lâ€™Ã©nonce son
   principal contributeur Dmitry Petrov dans cette prÃ©sentation. DVC est Ã 
   la fois comparable et complÃ©mentaire Ã  Git. Il va sâ€™occuper de
   synchroniser vos donnÃ©es et votre code. Il est donc particuliÃ¨rement
   intÃ©ressant dans le cadre dâ€™un projet de Machine Learning oÃ¹ le modÃ¨le
   et les donnÃ©es Ã©voluent au fil du dÃ©veloppement.â€¦
   Lire la suite

   Archi & techno

BD â€“ Le DÃ©ploiement Continu (CD)

   PostÃ© le 26/09/2019 par Aryana Peze
   [archi.png]

   Hello ! Lors de la BD prÃ©cÃ©dente, nous avons abordÃ© le sujet de la CI
   (IntÃ©gration Continue). Et impossible de parler de CI sans parler de CD
   (DÃ©ploiement Continu)! En thoÃ©rie, la CD implique un dÃ©ploiement
   automatique et quasi-systÃ©matique de chaque modification du code sur
   l'environnement de production. Les mises en production sont rÃ©guliÃ¨res
   et ne sont plus une source de stresse, et l'environnement de production
   est ainsi toujours Ã  jour. En pratique, c'est un objectif trÃ¨s
   compliquÃ© Ã  atteindre, et pas toujours adaptÃ©. (Petite parenthÃ¨seâ€¦
   Lire la suite

   Agile

Dâ€™Ã©tudiant Ã  mentor : rencontre avec notre Octo Thomas Le Flohic

   PostÃ© le 24/09/2019 par CÃ©line Audibert
   [agile.png]

   Thomas a fait un vÃ©ritable parcours â€œÃ  la OCTOâ€ : aprÃ¨s son Ã©cole
   dâ€™ingÃ©, il rentre en stage au sein de notre tribu VIBE (Virtual
   Immersion and Bot Experience) et rejoint dÃ©finitivement lâ€™entreprise en
   intÃ©grant le programme Skool. Un de ses profs Ã  lâ€™Ã©cole Ã©tait un Octo,
   Fabien. Câ€™est ce qui lui a donnÃ© envie de venir frapper Ã  notre porte.
   Comme lui, Thomas a voulu garder un lien avec lâ€™Ã©cole et transmettre
   son savoir. Câ€™est ainsi quâ€™il sâ€™est lancÃ© dans lâ€™accompagnement dâ€™un
   projet deâ€¦
   Lire la suite

   Archi & techno

Interview CÃ©line Gilet â€“ Â« Le Tech Lead nâ€™est pas un super hÃ©ros ! Â»

   PostÃ© le 23/09/2019 par CÃ©line Audibert
   [archi.png]

   Depuis plus de 4 ans chez OCTO, CÃ©line, membre de la tribu CRAFT, est
   devenue une rÃ©fÃ©rence parmi nos Tech Lead. DÃ©couvrez sa vision de ce
   rÃ´le Ã  part. Pour toi, quel est le rÃ´le du Tech Lead ?  Pour moi, câ€™est
   faire en sorte que lâ€™Ã©quipe au sens large (DÃ©veloppeurs, Ops,
   Fonctionnels, Product Owner) arrive Ã  dÃ©livrer rÃ©guliÃ¨rement de la
   valeur. ConcrÃ¨tement, il sâ€™agit de jongler et prioriser en permanence
   entre plusieurs casquettes : expertise, accompagnement, coaching et
   formation.
   Lire la suite

   MÃ©thode innovation

Injonctions paradoxales : un MVP â€¦ mais pour tous !

   PostÃ© le 20/09/2019 par Dominique Lequepeys, Sylvain Fagnent
   un MVP pour tous

   Un MVP ... mais pour tout le monde ! Et si vous vouliez lâ€™entendre
   cette injonction ? Mise en scÃ¨ne, Ã©coutez la. Les racines du paradoxe
   D'un cÃ´tÃ©, les managers sont sous la pression du timing : ils sont
   sÃ©duits par le concept de MVP, Minimum Viable Product, prÃ©sentÃ© comme
   un moyen d'accÃ©lÃ©rer la mise sur le marchÃ©. D'un autre, ils sont sous
   la pression du chiffre : ils ont du mal Ã  accepter qu'on se prive d'une
   partie du marchÃ© potentiel. En outre, ilsâ€¦
   Lire la suite
   1234>
   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #alternate OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires
   OCTO Talks ! Â» Le chemin vers lâ€™omnicanal Flux des commentaires Le
   demi-cercle (Ã©pisode 48 â€” Plaques tournantes) Lâ€™optimisation bayÃ©sienne
   par lâ€™exemple : Ã  quoi Ã§a sert et comment Ã§a marche ? alternate
   alternate

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

Le chemin vers lâ€™omnicanal

   PostÃ© le 01/08/2018 par Julien Kirch
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Si votre systÃ¨me dâ€™information nâ€™est pas tombÃ© dedans quand il Ã©tait
   petit, faire de lâ€™omnicanal est souvent un parcours semÃ© dâ€™embÃ»ches, et
   de promesses dâ€™Ã©diteurs.

   Cet article se propose de parler des sujets de fond liÃ©s Ã  ce type de
   transformations.

   Il est aussi lâ€™occasion dâ€™aborder lâ€™histoire des SI pour comprendre
   comment on est arrivÃ© Ã  la situation actuelle.

Câ€™est quoi lâ€™omnicanal ?

   Un canal est un point dâ€™accÃ¨s spÃ©cifique Ã  un systÃ¨me. Un SI peut par
   exemple avoir un canal web client, un canal application mobile client,
   un backoffice de gestion, des accÃ¨s pour les partenairesâ€¦

   Un SI omnicanal est un SI qui permet aux diffÃ©rentes personnes qui
   lâ€™utilisent de passer de maniÃ¨re fluide dâ€™un canal de distribution Ã  un
   autre.

   Lâ€™exemple type est de commencer Ã  faire une demande de prÃªt immobilier
   sur son smartphone, de la continuer sur son ordinateur portable une
   fois chez soi, puis Ã©ventuellement de terminer le dossier en se rendant
   en agence. Cela ne signifie pas utiliser le mÃªme outil dans les trois
   cas, mais bien dâ€™avoir des outils spÃ©cifiques dont lâ€™ergonomie est
   adaptÃ©e Ã  chaque utilisation, et de pouvoir passer de lâ€™un Ã  lâ€™autre
   Â« sans couture Â» (seamless), câ€™est-Ã -dire sans avoir Ã  refaire une
   opÃ©ration dÃ©jÃ  faite comme une saisie de donnÃ©es.

   En plus des avantages pour les utilisateurÂ·riceÂ·s, nous allons voir que
   lâ€™omnicanalitÃ© a Ã©galement des avantages pour lâ€™IT.

   Ã€ lâ€™inverse, un SI multicanal fournit les mÃªmes fonctionnalitÃ©s sur
   plusieurs canaux mais de maniÃ¨re silotÃ©e, et la bascule dâ€™un canal Ã 
   lâ€™autre est donc visible de la part des personnes ou des systÃ¨mes qui
   lâ€™utilisent.

   Dans ce cas une personne qui commence une demande de prÃªt immobilier
   chez elle et qui se rend en agence devra reprendre le dossier depuis le
   dÃ©but car le backoffice de lâ€™agence nâ€™a pas accÃ¨s Ã  la demande faite
   sur le canal web client.

Pourquoi câ€™est compliquÃ© ?

   Le chantier de transformation omnicanal comporte plusieurs axes, liÃ©s
   aux diffÃ©rentes contraintes des systÃ¨mes actuels.

   Pour comprendre la situation, le mieux est de revenir en arriÃ¨re et de
   dÃ©rouler lâ€™historique du SI.

   Nous allons prendre ici un exemple typique du domaine bancaire tel
   quâ€™on le retrouve chez de nombreux acteurs historiques.

Les annÃ©es 80 : au commencement Ã©taient le mainframe et le backoffice

   Les premiÃ¨res briques du SI se sont construites dans les annÃ©es 80 sur
   mainframe, dÃ©veloppÃ©es en COBOL ou Ã©quivalent. Ces systÃ¨mes historiques
   peuvent Ãªtre des dÃ©veloppements Â« maison Â», des progiciels, ou un
   mÃ©lange des deux.

   Les Ã©crans de backoffice permettant dâ€™y accÃ©der sont conÃ§us pour les
   employÃ©Â·eÂ·s de lâ€™entreprise et leurs sont rÃ©servÃ©s.

   Les workflows de traitement et les fonctionnalitÃ©s exposÃ©es sont
   directement calquÃ©s sur les Ã©crans et chaque Ã©tape du process est
   stockÃ©e dans la base de donnÃ©es dâ€™une maniÃ¨re structurÃ©e. Il ne sâ€™agit
   pas dâ€™un modÃ¨le MVC : les dÃ©finitions des Ã©crans sont imbriquÃ©es avec
   les traitements mÃ©tiers.

   Les bureaux Ã©tant fermÃ©s la nuit et le week-end, les appels interactifs
   sont dÃ©sactivÃ©s pendant ces pÃ©riodes, ce qui permet dâ€™exÃ©cuter des
   traitements de masse ou batch. Ces traitements bÃ©nÃ©ficient ainsi de
   lâ€™intÃ©gralitÃ© de la puissance de calcul, et le fait dâ€™Ãªtre les seuls Ã 
   sâ€™exÃ©cuter leur permet de simplifier leur design car ils peuvent ainsi
   monopoliser des ressources comme des tables de bases de donnÃ©es sans se
   soucier du reste du monde.

   Cela permet aussi de simplifier les rÃ¨gles mÃ©tier, par exemple les
   calculs comptables sont beaucoup plus simples lorsquâ€™aucune autre
   opÃ©ration nâ€™est effectuÃ©e pendant quâ€™ils sâ€™exÃ©cutent.

Les annÃ©es 2000 : lâ€™arrivÃ©e du web, le bicanal

   Avec lâ€™arrivÃ©e du web, il est temps dâ€™ouvrir un site de banque en
   ligne.

   Cela signifie donner accÃ¨s Ã  des fonctionnalitÃ©s du mainframe, mais
   dâ€™une maniÃ¨re diffÃ©rente de celle du backoffice :
     * les Ã©crans doivent Ãªtre adaptÃ©s pour Ãªtre utilisables par des
       non-employÃ©Â·eÂ·s, certains workflows comportent donc plus dâ€™Ã©tapes ;
     * certaines options nÃ©cessitant la validation dâ€™unÂ·e employÃ©Â·e
       empÃªcheront dâ€™aller jusquâ€™au bout du traitement Ã  partir du site,
       cela nÃ©cessitera des opÃ©rations de backoffice spÃ©cifiques.

   Le systÃ¨me mainframe historique est vital pour lâ€™entreprise et la
   maÃ®trise quâ€™ell en a nâ€™est pas toujours satisfaisante : ce patrimoine
   commence Ã  dater et la connaissance sâ€™est donc perdue, il comporte
   rarement des test automatisÃ©s et avec une documentation souvent
   lacunaire.

   La stratÃ©gie choisie est donc souvent de limiter au maximum lâ€™ampleur
   des modifications sur cette partie du systÃ¨me pour limiter les risques.

   Lâ€™approche choisie alors consiste Ã  exposer les workflows existant
   autant que possible â€“ câ€™est-Ã -dire ceux du backoffice â€“ principalement
   sous formes dâ€™API synchrones, et Ã  dÃ©velopper le site web au-dessus de
   ces API, alors mÃªme que les workflows ne sont pas les mÃªmes.

   Les contrats de ces APIs sont donc assez proches des Ã©crans mainframe
   pour limiter lâ€™effort Ã  fournir. Il ne sâ€™agit bien entendu pas dâ€™API
   REST, mais gÃ©nÃ©ralement de messages MQ ou dâ€™appels CTG.

   Lorsque les deux workflows ne correspondent pas, on aboutit Ã  ce type
   de situation :

   Il est dans ce cas impossible de stocker les rÃ©sultats des Ã©tapes 1A ou
   2A dans le mainframe. Ils seront donc stockÃ©s dans le backend du site
   web dans une base de donnÃ©es sÃ©parÃ©e. Cela signifie aussi quâ€™il faudra
   dupliquer les contrÃ´les de saisie de ces Ã©tapes dans la partie web,
   pour Ã©viter dâ€™avoir Ã  revenir en arriÃ¨re dans les Ã©crans du site web.

   Suivant les Ã©tapes, les donnÃ©es sont donc stockÃ©es soit dans le systÃ¨me
   cÅ“ur, soit de maniÃ¨re intermÃ©diaire dans le sous-systÃ¨me du site web.

   En fonction des situations, les points de Â« rencontre Â» des workflows
   sont plus ou moins nombreux. Le cas extrÃªme est celui oÃ¹ il existe un
   seul point de synchronisation : la derniÃ¨re Ã©tape du workflow. Dans
   cette situation, le site web doit stocker toutes les donnÃ©es
   intermÃ©diaires, et recoder tous les contrÃ´les de saisie.

   Dans ce cas, les donnÃ©es dans la base du site web qui nâ€™ont pas Ã©tÃ©
   dÃ©versÃ©es dans la base du mainframe ne sont ni visibles depuis le
   backoffice ni des autres systÃ¨mes qui exploitent cette base.

   Par exemple, si vous commencez Ã  souscrire un prÃªt immobilier sur le
   site web sans terminer la procÃ©dure et que vous vous rendez dans votre
   agence bancaire, il faudra refaire tout ou partie des opÃ©rations.

   Par ailleurs, les opÃ©rations de backoffice spÃ©cifiques au site web
   ainsi que les besoins de support client nÃ©cessitent de dÃ©velopper des
   Ã©crans spÃ©cifiques branchÃ©s sur le mÃªme backend.

   Lâ€™inaccessibilitÃ© du cÅ“ur systÃ¨me historique pendant la nuit pose aussi
   problÃ¨me : il est inconcevable de faire de mÃªme pour un site web
   destinÃ© au grand public.

   Il existe de nombreuses maniÃ¨res dâ€™amÃ©liorer cette situation,
   lâ€™approche souvent rencontrÃ©e consiste Ã  :
    1. effectuer une copie de certaines donnÃ©es avant de couper le systÃ¨me
       mainframe, et sâ€™en servir comme dâ€™un cache en lecture seule
       accessible pendant la nuit, le cache sera dÃ©sactivÃ© lorsque les
       traitements de masse sont terminÃ©s ;
    2. ne pas exÃ©cuter les opÃ©rations qui nÃ©cessitent des Ã©critures mais
       les enregistrer sous forme de demandes dâ€™exÃ©cutions dans le backend
       du site web, et rÃ©aliser rÃ©ellement les traitements le jour suivant
       Ã  lâ€™ouverture du mainframe.

   Cela rend le SI plus difficile Ã  observer car les donnÃ©es sont
   distribuÃ©es entre les deux sous-systÃ¨mes.

   Bien entendu, mÃªme si la rÃ©utilisation de fonctionnalitÃ©s existantes
   est privilÃ©giÃ©e, certains besoins du site web nÃ©cessitent de dÃ©velopper
   des APIs spÃ©cifiques dans le cÅ“ur mÃ©tier.

Aujourdâ€™hui : le mobile et les partenaires

   Lâ€™arrivÃ©e du mobile pourrait signifier la mise en place dâ€™une
   tricanalitÃ©. Mais les besoins mobiles sont souvent suffisamment proches
   des besoins web pour quâ€™ils sâ€™appuient sur les mÃªmes systÃ¨mes. Dans
   quelques situations, il peut Ãªtre nÃ©cessaire de stocker des donnÃ©es
   intermÃ©diaires sur les terminaux, mais il ne sâ€™agit pas dâ€™un vrai
   troisiÃ¨me canal.

   Les Ã©crans de backoffice ont souvent Ã©tÃ© remplacÃ©s par des technologies
   web. Mais pour limiter les impacts sur le mainframe, on conservera
   souvent les mÃªmes workflows, le nouveau backoffice nâ€™aura donc pas Ã 
   stocker de donnÃ©es.

   De mÃªme, le site web public a pu Ãªtre refondu, mais toujours en
   subissant les contraintes de lâ€™existant.

   En revanche, la banque a nouÃ© des partenariats. Ces partenaires peuvent
   par exemple vendre des prÃªts de la banque en marque blanche quand vous
   achetez un de leur produits.

   Les process nÃ©cessaires aux partenaires sont aussi diffÃ©rents du
   process historique que du process web, le systÃ¨me devient donc souvent
   tricanal. Prenons le cas oÃ¹ lâ€™intÃ©gration se fait via un backend
   spÃ©cifique.

   Pour rester lisible, le schÃ©ma ne contient pas les backoffice dÃ©diÃ©s
   aux canaux web et partenaires mais ils existent bel et bien, une
   personne du support peut donc avoir Ã  jongler avec trois backoffices
   diffÃ©rents.

   Le canal partenaire ne pose pas le mÃªme problÃ¨me que le canal web. En
   effet, un client qui commence Ã  souscrire un prÃªt en marque blanche en
   achetant un bien voudra rarement conclure la transaction dans votre
   agence. En revanche, la multiplication des canaux rend la maintenance
   du systÃ¨me plus complexe quand on veut modifier un des workflows
   centraux qui sont exposÃ©s aux autres canaux ou changer une des rÃ¨gles
   de gestion dupliquÃ©e Ã  plusieurs endroits.

   Certains besoins des partenaires se rapprochent de ceux du site web
   client, il arrive donc quâ€™une partie du code soit partagÃ©e entre les
   deux. Cela Ã©vite de dÃ©velopper plusieurs fois les mÃªmes choses mais
   rend le systÃ¨me encore plus difficile Ã  observer.

En rÃ©sumÃ© : les problÃ¨mes du multicanal

   Le multicanal pose donc les problÃ¨mes suivants :
     * mauvaise expÃ©rience utilisateurÂ·riceÂ·s lors du passage dâ€™un canal Ã 
       lâ€™autre ;
     * duplication de code entre les canaux ;
     * donnÃ©es partiellement dupliquÃ©es entre les canaux ;
     * limites dans la capacitÃ© Ã  crÃ©er des parcours trÃ¨s diffÃ©rents du
       parcours historique ;
     * difficultÃ© de mettre en Å“uvre des Ã©volutions cross-canaux du fait
       de la duplication ;
     * systÃ¨me difficile Ã  observer.

Que faut-il pour avoir un SI omnicanal ?

   Les problÃ¨mes causÃ©s par le multicanal et les limites des SI
   correspondants nous donnent les informations nÃ©cessaires pour dresser
   le plan dâ€™un SI omnicanal.

   Avant de rentrer dans le dÃ©tail, il faut prÃ©ciser quâ€™un systÃ¨me
   omnicanal ne signifie pas un systÃ¨me unique de haut en bas pour tous
   les canaux mais un systÃ¨me cÅ“ur permettant de rÃ©pondre aux besoins de
   lâ€™omnicanalitÃ© sur lequel viendront se brancher les diffÃ©rents canaux.

   La diffÃ©rence avec un systÃ¨me multicanal est la capacitÃ© de passer dâ€™un
   canal Ã  lâ€™autre, pas le fait dâ€™avoir un systÃ¨me unique.

   Ainsi vous nâ€™exposerez pas forcÃ©ment les mÃªmes services ou les mÃªmes
   technologies pour votre application mobiles et pour vos partenaires.
   Vous aurez un systÃ¨me cÅ“ur sur lequel viendront se greffer votre canal
   backoffice, votre canal public, votre canal partenaireâ€¦

Des processus mÃ©tier indÃ©pendants des canaux

   Les workflows Ã©tant diffÃ©rent dâ€™un canal Ã  lâ€™autre, lâ€™omnicanalitÃ©
   nÃ©cessite de concevoir des processus mÃ©tier qui soient adaptables aux
   diffÃ©rents canaux.

   Cela signifie quâ€™il ne faut pas penser son processus en termes dâ€™Ã©tapes
   qui ont la granularitÃ© dâ€™un Ã©cran mais en termes de macro-Ã©tapes avec
   une taille plus importante, ce qui donnera Ã  chaque canal les marges de
   manÅ“uvres dont il a besoin.

   Par exemple, souscrire un crÃ©dit peut, en le simplifiant Ã  lâ€™extrÃªme,
   se dÃ©composer en trois macro-Ã©tapes :
     * renseigner des informations personnelles et faire des simulations
       de crÃ©dit jusquâ€™Ã  obtenir une offre satisfaisante ;
     * valider une demande de crÃ©dit en saisissant des informations
       supplÃ©mentaires ;
     * traiter la demande dans le backoffice pour la valider ou la
       rejeter.

   Il sâ€™agit dâ€™un travail de conception mÃ©tier. Câ€™est souvent la partie la
   plus difficile du chantier car il sâ€™agit dâ€™un exercice dont on a peu
   lâ€™habitude, et câ€™est donc une bonne premiÃ¨re Ã©tape.

Un systÃ¨me de stockage

   Les donnÃ©es doivent Ãªtre stockÃ©es dans un systÃ¨me indÃ©pendant des
   canaux.

   Comme les saisies dâ€™informations peuvent se faire dans des ordres
   diffÃ©rents dâ€™un canal Ã  lâ€™autre, on peut moins souvent sâ€™appuyer sur
   des contraintes dâ€™intÃ©gritÃ© que dans un systÃ¨me monocanal.

   Par exemple unÂ·e clientÂ·e pourra peut-Ãªtre crÃ©er un compte sans fournir
   immÃ©diatement son nom ou son adresse.

Des rÃ¨gles mÃ©tier de validation

   Dans un systÃ¨me historique, les services mÃ©tier Ã©tant adossÃ©s aux
   Ã©crans, chacun comportait les rÃ¨gles mÃ©tiers correspondantes permettant
   de valider les informations saisies dans le formulaire.

   Dans un systÃ¨me omnicanal, ce nâ€™est plus possible car chaque canal peut
   concevoir son parcours.

   Cela signifie que les rÃ¨gles de validation seront sous deux formes :
    1. dans le systÃ¨me central, des rÃ¨gles de validation seront placÃ©es au
       niveau de chaque macro-Ã©tape ;
    2. les canaux doivent implÃ©menter ces mÃªmes rÃ¨gles au niveau de chaque
       Ã©cran ou de chaque service exposÃ© avec la granularitÃ© la plus fine
       possible pour Ãªtre en mesure de remonter des erreurs au plus prÃ¨s
       de la saisie des donnÃ©es.

   Cela nÃ©cessite de bien documenter les rÃ¨gles.

Des services facilement utilisables et composables

   Ce sont les services synchrones et asynchrones sur lesquels seront
   construits les canaux.

   En effet, composer des services pour de lâ€™omnicanal signifie de bien
   maÃ®triser les dÃ©pendances entre les diffÃ©rents services pour donner des
   libertÃ©s aux diffÃ©rents canaux.

   Ces services doivent aussi, autant que possible, Ãªtre accessibles 24
   heures sur 24. Cela va nÃ©cessiter, du point de vue de lâ€™extÃ©rieur, que
   les traitements ensemblistes Â« de nuit Â» ne rendent plus le systÃ¨me
   inaccessible. Cela peut demander de rÃ©utiliser le mÃªme type de
   comportements que ceux qui Ã©taient utilisÃ©s par les canaux, comme le
   fait dâ€™enregistrer des demandes dâ€™exÃ©cutions Ã  traiter plus tard. La
   diffÃ©rence est que le comportement sera cohÃ©rent entre les diffÃ©rents
   canaux car rÃ©alisÃ© dans la partie commune.

Les canaux

   Câ€™est la partie spÃ©cifique Ã  chaque canal qui dÃ©finit le workflow de ce
   canal et lâ€™expose de la maniÃ¨re appropriÃ©e par des Ã©crans ou des
   services.

   Lâ€™objectif est que cette partie du SI ne stocke pas dâ€™information. En
   effet, comme nous lâ€™avons vu plus haut, toute information stockÃ©e au
   niveau dâ€™un canal va crÃ©er un silotage. Ils ne font que sâ€™appuyer sur
   les services de la couche cÅ“ur.

   Lâ€™omnicanalitÃ© rend la conception des canaux plus difficiles car ils
   doivent prendre en compte le fait quâ€™un processus peut avoir Ã©tÃ©
   dÃ©marrÃ© dans un autre canal ayant un workflow diffÃ©rent.

   Par exemple, certains des champs de saisie auront peut-Ãªtre dÃ©jÃ  Ãªtre
   remplis et pas dâ€™autres.

   Il faut quâ€™il puisse dÃ©terminer comment effectuer la reprise du
   traitement dans de bonnes conditions.

   Cela demande une conception rigoureuse ainsi quâ€™une bonne couverture de
   tests.

Faire vivre le systÃ¨me

   La derniÃ¨re pierre de lâ€™omnicanal est la capacitÃ© Ã  le faire vivre.

   En effet, les canaux sont fortement couplÃ©s au systÃ¨me cÅ“ur, ils
   devront donc Ãªtre modifiÃ©s de maniÃ¨re coordonnÃ©e.

   Ce couplage est un effet direct de lâ€™omnicanalitÃ© : câ€™est elle qui
   permet de passer dâ€™un canal Ã  lâ€™autre. Le modÃ¨le de canaux dÃ©couplÃ©s
   est celui du multicanal.

   Votre organisation doit donc Ãªtre adaptÃ©e Ã  cette contrainte.

Comment y aller ?

   Maintenant que nous savons en quoi devrait consister un systÃ¨me
   omnicanal, reste Ã  Ã©tudier les trajectoires pour lâ€™atteindre.

   Nous allons commencer par un point sur la situation de dÃ©part puis
   donner quatre exemples de stratÃ©gie possibles. Il existe de multiples
   approches, celles qui sont mentionnÃ©es ici ont Ã©tÃ© choisies car elles
   mettent en lumiÃ¨res les contraintes qui sâ€™appliquent.

Situation de dÃ©part

   Le systÃ¨me multicanal comporte deux Ã©lÃ©ments qui ont de la valeur et
   sur lesquels il faut sâ€™appuyer en le faisant Ã©voluer vers lâ€™omnicanal,
   et deux limites quâ€™il faudra supprimer :

   Ã€ conserver :
     * les rÃ¨gles de traitement mÃ©tier ;
     * les rÃ¨gles de validation de donnÃ©es.

   Les deux reprÃ©sentent de la valeur mÃªme si elles sont adhÃ©rentes au
   Ã©tapes du workflow historique (par exemple les diffÃ©rents Ã©crans du
   process de souscription originel).

   Ã€ supprimer :
     * le workflow unique formant lâ€™assise du systÃ¨me historique
     * les rÃ¨gles dâ€™intÃ©gritÃ© des donnÃ©es alignÃ©es avec le process
       historique

StratÃ©gie 1 : commencer par acheter un BPM

   Câ€™est la solution que prÃ©conisent certains Ã©diteurs.

   Les BPM sont des outils permettant de dÃ©finir des workflow mÃ©tiers sous
   forme low-code, câ€™est-Ã -dire via de la configuration et/ou des
   designers graphiques. Ils permettent Ã©galement de stocker lâ€™Ã©tat
   courant des diffÃ©rents workflows.

   Câ€™est une solution tentante car elle fournit un socle prÃªt Ã  lâ€™emploi
   pour une partie des besoins.

   Deux points dâ€™attention pour cette approche :
     * comme avec tout progiciel, attention Ã  ne pas oublier les bonnes
       pratiques de dÃ©veloppement comme les tests automatisÃ©s : votre BPM
       embarquera du code, et qui dit code dit tests ;
     * ne pensez pas quâ€™avoir choisi un BPM signifie que vous avez gagnÃ©,
       en effet nous avons vu que la partie la plus difficile du chantier
       est la conception des services sur lesquels va sâ€™appuyer le BPM.

   Il sâ€™agit dâ€™une utilisation trÃ¨s spÃ©cifique des outils de BPM, loin de
   la gestion des processus mÃ©tiers qui est leur utilisation normale.

StratÃ©gie 2 : repartir sur un nouveau systÃ¨me

   Câ€™est la solution la plus risquÃ©e, mais qui est parfois la moins
   mauvaise. Par exemple quand vous avez perdu la maÃ®trise de votre
   systÃ¨me historique, ou quâ€™il sâ€™agit dâ€™un progiciel qui nâ€™est pas
   compatible avec lâ€™omnicanal.

   La solution nâ€™est pas forcÃ©ment de partir de zÃ©ro : il est possible de
   partir sur un progiciel plus rÃ©cent, ou de racheter une entreprise
   disposant dâ€™une solution dÃ©jÃ  fonctionnelle.

StratÃ©gie 3 : rendre le cÅ“ur mÃ©tier historique omnicanal

   Il sâ€™agit dâ€™attaquer le problÃ¨me par le bas, câ€™est-Ã -dire par le cÅ“ur
   mÃ©tier.

   Cela peut Ãªtre Ã  lâ€™occasion de lâ€™ajout dâ€™un nouveau canal, en profitant
   dâ€™avoir des nouveaux besoins factuels, et un budget.

   Il va sâ€™agir de transformer le cÅ“ur, puis de faire maigrir les canaux
   existants en redescendant ce qui ne devrait pas sâ€™y trouver, comme le
   stockage de donnÃ©es.

   La situation de dÃ©part


   En cours de migration : les canaux diminuent et le cÅ“ur sâ€™enrichit


   Cible : les canaux nâ€™ont plus de base de donnÃ©es

   Câ€™est probablement la meilleure solution si vous avez la maÃ®trise de
   votre existant et que vous souhaitez capitaliser dessus.

   Deux points dâ€™attention :
     * faire Ã©voluer de maniÃ¨re significative un outil demande un niveau
       de maÃ®trise plus important que le fait de le maintenir, la facilitÃ©
       Ã  corriger des erreurs sur le cÅ“ur nâ€™est pas un bon indicateur de
       votre capacitÃ© Ã  le transformer ;
     * ne pas introduire de rÃ©gressions, par exemple en supprimant des
       comportements non documentÃ©s mais sur lesquels le code sâ€™appuie.

StratÃ©gie 4 : ajouter une couche dâ€™omnicanal au-dessus du cÅ“ur

   Il sâ€™agit de la voie intermÃ©diaire : on sâ€™appuie sur lâ€™existant le
   temps de bÃ¢tir un remplacement.

   Il sâ€™agit de bÃ¢tir une surcouche omnicanale au-dessus du cÅ“ur. PlutÃ´t
   que de partir de zÃ©ro, il est possible de partir dâ€™un des canaux
   existants en le sÃ©parant entre une partie souche qui servira de base Ã 
   la partie omnicanal et la partie exposition qui deviendra la nouvelle
   couche canal.

   En enrichissant peu Ã  peu de nouveau types de donnÃ©es en les remontant
   depuis le cÅ“ur historique et des fonctionnalitÃ©s associÃ©es. Cette
   couche devra exposer les services rÃ©utilisables qui serviront de base
   aux diffÃ©rents canaux.

   Pendant la construction, vous continuerez de subir les limitations du
   cÅ“ur existant, mais commencerez Ã  bÃ©nÃ©ficier de certains avantages de
   lâ€™omnicanalitÃ©, comme la transition plus facile dâ€™un canal Ã  lâ€™autre.

   Lâ€™Ã©tape suivante consistera Ã  dÃ©gonfler le systÃ¨me historique pour
   sâ€™appuyer de plus en plus sur la nouvelle couche.

   Cela va probablement demander des Ã©volutions du systÃ¨me cÅ“ur. Cependant
   elles ne demanderont pas de transformations profondes, au contraire de
   la stratÃ©gie prÃ©cÃ©dente.

   En cible on pourra dÃ©comissionner totalement le systÃ¨me historique, ou
   conserver certains Ã©lÃ©ments comme les parties rÃ©glementaires pour
   lesquels la migration ne se justifie pas et qui nâ€™imposent pas de
   contraintes sur le nouveau systÃ¨me.

   Une des difficultÃ©s de cette stratÃ©gie est de bien choisir lâ€™ordre dans
   lequel remonter les fonctionnalitÃ©s pour bÃ©nÃ©ficier au plus vite des
   premiers avantages tout en limitant les risques.

   La situation de dÃ©part

   En cours de migration, la zone du milieu prend de lâ€™importance

   Cible : le cÅ“ur historique nâ€™est plus le centre du systÃ¨me

Pour terminer

   Lâ€™omnicanalisation dâ€™un SI est un chantier risquÃ© et de longue haleine.
   Mal conÃ§u ou mal pilotÃ©, il peut Ãªtre un enfer de plusieurs annÃ©es qui
   aboutira Ã  ajouter de nouvelles briques Ã  votre systÃ¨me, sans atteindre
   aucun des buts fixÃ©s.

   Il est autant liÃ© Ã  la DSI quâ€™au mÃ©tier : il demande du travail Ã  tous
   les deux, mais apportera aussi des avantages Ã  chacun. Si lâ€™un des deux
   acteurs veut se lancer sans la pleine coopÃ©ration de lâ€™autre, câ€™est
   lâ€™Ã©chec presque assurÃ©.

   MÃªme si ce changement peut permettre de rÃ©duire la dÃ©pendance aux
   systÃ¨mes historiques, y arriver va demander de comprendre comment ces
   systÃ¨mes fonctionnent, et de les modifier. Moins bien vous maÃ®trisez
   votre mainframe, plus il sera difficile de vous en passer.

   Si un tel projet vous semble long et coÃ»teux aujourdâ€™hui, gardez Ã 
   lâ€™esprit que plus le temps passe et plus la situation va empirer.

   Bonne chance Ã  vous.
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Cet article a Ã©tÃ© postÃ© dans Archi & techno, StratÃ©gie SI et tagguÃ©
   Architecture SI, omnicanal.

Articles rÃ©cents

     * Comment conserver les mots de passe de ses utilisateurs en 2019 ?
     * AmÃ©lioration continue : Comment rester dynamique Ã  mesure que
       lâ€™Ã©quipe sâ€™agrandit ?
     * Culture Innovâ€™ : Quel ROI attendu ?
     * Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes
     * Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos
       valeurs et le garant de la vision technique dâ€™OCTO.â€

Un commentaire sur â€œLe chemin vers lâ€™omnicanalâ€

     Anas
   02/08/2018 Ã  16:20
   Une stratÃ©gie qui n'a pas Ã©tÃ© Ã©voquÃ©e et qui mÃ©rite de l'Ãªtre, il
   s'agit de la solution CEP couplÃ©e Ã  une solution de suivi de parcours.
   La solution BPM n'est pas trÃ¨s adaptÃ©e Ã  des parcours impliquant des
   millions d'utilisateurs car il faut pouvoirs stocker et gÃ©rer autant
   d'instances de processus que de parcours utilisateurs en cours. Pour
   peu que le parcours dure quelques jours voir quelques semaines (ce qui
   est le cas dans le domaine bancaire), on atteint trÃ¨s vite des volumes
   difficilement supportables par les solutions BPM du marchÃ©.

Laisser un commentaire Annuler la rÃ©ponse

   Votre adresse de messagerie ne sera pas publiÃ©e. Les champs
   obligatoires sont indiquÃ©s avec *

   Commentaire
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   [ ] Me notifier par mail en cas de nouveaux commentaires

   Nom * ______________________________

   Adresse de messagerie * ______________________________

   Site web ______________________________
   (BUTTON) Laisser un commentaire
   Ce formulaire est protÃ©gÃ© par Google Recaptcha

   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #alternate OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires
   OCTO Talks ! Â» Le demi-cercle (Ã©pisode 49 â€” Cocktail) Flux des
   commentaires Lâ€™optimisation bayÃ©sienne par lâ€™exemple : Ã  quoi Ã§a sert
   et comment Ã§a marche ? GraphQL: Et pour quoi faire ? alternate
   alternate

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

Le demi-cercle (Ã©pisode 49 â€” Cocktail)

   PostÃ© le 03/08/2018 par Christophe Thibaut
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   The world is not interested in the storms you encountered, but did you
   bring in the ship?
   William McFee

   Sept heure moins dix. Tu entres dans la Grande Salle de la Direction
   GÃ©nÃ©rale. Toutes les lumiÃ¨res sont allumÃ©es bien que le jour soit
   encore clair. On a pliÃ© toutes les tables sauf une, et repoussÃ© les
   chaises dans un coin.

   Pop !

   Victor sert le champagne dans des flÃ»tes. Tu te demandes si elles ont
   Ã©tÃ© louÃ©es pour lâ€™occasion, ou si dÃ©cidÃ©ment cette maison regorge de
   trÃ©sors cachÃ©s. Il y a du monde, au moins 40 personnes. Audrey et
   JÃ©rÃ©mie sont en train de discuter avec un homme en costume trois piÃ¨ces
   et une jeune femme dâ€™apparence assez chic malgrÃ© une chevelure hirsute.
   Certainement des clients de chez Juniper. Tu tâ€™approches. Audrey dit :
   â€“ En tout cas, câ€™est une bonne chose que vous ayez pu rencontrer
   Victor. Jâ€™Ã©tais loin de maÃ®triser mon sujet sur Parady !
   La jeune femme dit :
   â€“ Vous vous en Ãªtes trÃ¨s bien sortis. Une prÃ©sentation trÃ¨s
   professionnelle, vraiment.
   JÃ©rÃ©mie sourit dâ€™un sourire que tu ne lui connais pas, et rÃ©pond :
   â€“ Merci. Beaucoup.
   Lâ€™homme en costume dit :
   â€“ Et surtout, Ã§a nous a permis de mieux faire connaissance avec votre
   produit. Ce quâ€™on ne vous a pas dit, câ€™est que ces features que vous
   nous avez prÃ©sentÃ©es, on les cherche depuis deux ans sur le marchÃ© !
   Une chance que Victor se soit plantÃ© en scooter.
   Mais non, quâ€™est-ce que tu racontes.
   Il aurait pris tout lâ€™espace et le client nâ€™aurait pas vu la dÃ©mo
   dâ€™Audrey et JÃ©rÃ©mie, et il ne nous aurait pas achetÃ© la gamme complÃ¨te.
   La mÃ©disanceâ€¦

   Farid et Hugo sont arrivÃ©s. Ils serrent des mains. Prennent une flÃ»te.

   Tintement de verre. Les conversations sâ€™estompent.

   Le PrÃ©sident Directeur GÃ©nÃ©ral, GÃ©rard Beaufret, lÃ¨ve son verre un
   instant, le pose sur la table derriÃ¨re lui, et dÃ©clare :
   â€“ Je voudrais remercier dâ€™abord nos clients, anciens et nouveaux (il
   adresse un sourire au couple venu de Juniper), merci, pour la confiance
   que vous nous faites, et qui nous honore. Nous cherchons constamment Ã 
   amÃ©liorer la qualitÃ© de nos produits, et vos apprÃ©ciations â€” et bien
   entendu vos critiques â€” nous sont trÃ¨s trÃ¨s utiles.

   Bien entendu.
   Stop.

   Le PDG reprend :
   â€“ Je voudrais remercier lâ€™Ã©quipe XXLâ€¦
   Il fait un geste pour vous inviter Audrey, JÃ©rÃ©mie, Hugo, Farid et toi
   Ã  entrer dans le grand cercle. Vous avancez. Tu souris.

   Tu souris trop.
   Mais non.

   â€“ â€¦ sans qui cette Ã©popÃ©e ne serait pas possible. Chapeau ! Et sans
   oublier bien sÃ»r, notre chÃ¨re Maria, et Victor qui reprend le flambeau
   de plus belle.

   Tout le monde applaudit, y compris vous. Tu applaudis tes coÃ©quipiers.
   Maria applaudit. Victor applaudit. Jean-Bernard applaudit. Lazare lÃ¨ve
   sa flÃ»te de champagne et adresse un clin dâ€™Å“il Ã  JÃ©rÃ©mie.

   Pas facile dâ€™applaudir avec une flÃ»te Ã  la main.
   MÃªme vide.

   Une bonne demi-heure se passe. Brouhaha de discussions animÃ©es, sur
   lâ€™avenir du logiciel, la digitalisation, la vitesse, la rÃ©activitÃ©.
   JÃ©rÃ©mie, Farid et toi, vous parlez dâ€™architecture. Victor, accompagnÃ©
   dâ€™un collÃ¨gue de la Direction des Ventes, sâ€™immisce dans le groupe et
   le prÃ©sente :
   â€“ Vous connaissez Daniel Derby ? Product Manager de la gamme Parady.
   JÃ©rÃ©mie dit : salut Daniel.

   Bon sang JÃ©rÃ©mie connaÃ®t tout le monde dans cette boÃ®te.

   Vous vous saluez. La conversation fait comme une pause, puis reprend :

   Daniel : Alors JÃ©rÃ©mie, dis nous, câ€™est quoi votre secret de
   fabrication, chez XXL ?
   JÃ©rÃ©mie : Ah ah. Le secretâ€¦ Mais il nâ€™y a pas de secret.
   Daniel : Sans blague. Regardez le chemin parcouru en 10 mois. Vous avez
   forcÃ©ment un truc. Comment faites-vous pour aller si vite ?
   Farid : Oui, tiens câ€™est vrai, câ€™est quoi notre secret ?
   JÃ©rÃ©mie : Pffff. Non, je ne vois pas.
   Victor (sâ€™esclaffant) : Il faut continuer Ã  le faire boire si tu veux
   dÃ©couvrir le truc. Je vais chercher du champagne.
   Daniel : Si tu y rÃ©flÃ©chis, lÃ  comme Ã§a ? Quâ€™est-ce que vous avez de
   diffÃ©rent ?
   Toi : On a un bureau qui donne sur le sud ? Non, je plaisante.

   Victor revient avec du champagne et sâ€™avance pour remplir vos flÃ»tes.
   JÃ©rÃ©mie, Farid et toi, dÃ©clinez poliment.

   JÃ©rÃ©mie (tend son verre) : Oh, remarque aprÃ¨s tout. Merci.

   JÃ©rÃ©mie te regarde une seconde, dÃ©guste son champagne et reprend :
   JÃ©rÃ©mie : Notre secret, câ€™est la qualitÃ© des conversations.
   Farid (claque des doigts) : VoilÃ . Exactement !
   Daniel : La qualitÃ© de vos conversations ? Câ€™est une blague ?
   JÃ©rÃ©mie : Mais non, pourquoi ? Quâ€™est-ce qui te fait rire lÃ -dedans ?
   Victor : Remarque quâ€™il nâ€™a pas tort. Au dÃ©but Ã§a mâ€™a surpris, mais en
   fait il a un peu raison.
   Daniel : Mais, vous nâ€™Ãªtes pas lÃ  pour avoir de jolies conversations de
   salon ! Vous Ãªtes lÃ  pour faire votre travail.
   JÃ©rÃ©mie : Bien sÃ»r. Moi-mÃªme, je nâ€™aime pas les conversations de salon
   comme tu dis. Non, je te parle des conversations au travail. Celles qui
   permettent dâ€™obtenir des informations et de prendre nos dÃ©cisions.
   Daniel : Ha ! Vous prenez des dÃ©cisions ! Et combien de dÃ©cisions vous
   prenez de cette maniÃ¨re ?
   JÃ©rÃ©mie : Je dirais plusieurs dizaines par jour. Câ€™est principalement
   ce en quoi consiste notre travail dâ€™ailleurs.
   Farid : Une longue sÃ©rie de dÃ©cisionsâ€¦
   Toi : Plus ou moins funestesâ€¦
   Farid (souriant) : Tu vois le verre Ã  moitiÃ© videâ€¦
   Daniel (vide sa flÃ»te, croise les bras) : Tout de mÃªme. Je suis curieux
   de savoir quel type de conversations vous tenez, et Ã  propos de quoi ?
   JÃ©rÃ©mie : Ã‡a dÃ©pend pas mal de ce que lâ€™on est en train de faire, note.
   Daniel : Ah oui ?
   JÃ©rÃ©mie : Mais si on voulait les catÃ©goriser par contenu, je pense
   quâ€™on trouverait cinq catÃ©gories distinctes :
   (JÃ©rÃ©mie compte sur ses doigts) Les conversations avec le code. Les
   conversations Ã  propos du code. Les conversations Ã  propos du problÃ¨me
   que nous voulons rÃ©soudre grÃ¢ce au code. Les conversations Ã  propos de
   notre faÃ§on de rÃ©soudre le problÃ¨me
   Toi : Ã‡a fait quatre.
   JÃ©rÃ©mie (souriant) : Je sais encore compter. Et puis les conversations
   Ã  propos de toutes ces conversations.
   Daniel : Attends, jâ€™ai perdu le fil. Quâ€™est-ce que tu appelles une
   conversation avec le code ?
   JÃ©rÃ©mie : Tu lis un morceau de code, tu ne le comprends pas bien;
   disons que sa forme est difficile Ã  comprendre. Tu Ã©cris un test sur ce
   code, qui te rÃ©vÃ¨le une nouvelle information, ou bien qui confirme une
   hypothÃ¨se. Câ€™est comme si tu posais une question. Quand tu as
   suffisamment de tests, tu peux changer la forme du code, ce qui le rend
   plus facile Ã  comprendre. Et tu relances tes tests. Câ€™est ce que
   jâ€™appelle une sorte de conversation. Si on veut.
   Daniel : Ã‡a me rappelle mes Ã©tudes. Câ€™est ce quâ€™on faisait avec
   Smalltalk. Sauf quâ€™on ne faisait pas de tests comme vous, on utilisait
   un dÃ©bogueur intÃ©grÃ©.
   JÃ©rÃ©mie : Je ne connais pas Smalltalk, mais je dirais quâ€™on peut faire
   Ã§a avec nâ€™importe quel langage, du moment quâ€™on a un outil de test et
   un dÃ©bogueur.
   Daniel : Bon. Admettons. Et les autres conversations ?
   JÃ©rÃ©mie : Les conversations Ã  propos du code, sont celles que nous
   avons trÃ¨s souvent entre dÃ©veloppeurs. Est-ce que le code fait ce quâ€™il
   est supposÃ© faire ? Est-ce que le code est facile Ã  comprendre ?
   Quâ€™est-ce quâ€™il faut changer dans ce code ? Ce genre de questions.
   Daniel : Je vois. Et ensuite ?
   JÃ©rÃ©mie : Les conversations Ã  propos du problÃ¨me, sont celles que nous
   avons avec Maria, CharlÃ¨ne, Victor et dâ€™autres personnes, et ces
   conversations tournent autour des utilisateurs, des clients et de ce
   quâ€™ils essayent dâ€™obtenir au moyen dâ€™XXL, et comment ils lâ€™obtiennent.
   Daniel : OK. Câ€™est la partie fonctionnelle.
   JÃ©rÃ©mie : Si tu veux.
   Daniel : Mais Ã§a, Ã§a ne devrait pas faire lâ€™objet de conversation
   justement : Ã§a devrait Ãªtre dans la spÃ©cification.
   JÃ©rÃ©mie : Ah bon ?
   Daniel : Bien sÃ»r. Pour Ã©crire un programme qui fait correctement ce
   qui est attendu fonctionnellement, il faut des spÃ©cifications.
   JÃ©rÃ©mie : OK. Je ne dis pas non. Dans ce cas, cette catÃ©gorie de
   conversation inclura probablement les conversations Ã  propos de la
   spÃ©cification.
   Daniel : Eh bien non, pas du tout. La spÃ©cification est justement lÃ 
   pour Ã©viter dâ€™avoir Ã  revenir sur le sujet.
   JÃ©rÃ©mie : Pour que ce que tu dis soit exact, Ã  savoir, quâ€™on aie pas
   besoin de revenir sur le sujet, il faudrait que la spÃ©cification soit
   complÃ¨te.
   Victor : Ah Ã§aâ€¦
   JÃ©rÃ©mie : Note que si la spÃ©cification Ã©tait complÃ¨te, on pourrait
   probablement la transformer automatiquement en logiciel. On nâ€™aurait
   plus besoin de la traduire en code.
   Daniel : Ha ! Câ€™est Ã§a qui serait pratique !
   Victor : Mais alors les dÃ©veloppeurs nâ€™auraient plus de travailâ€¦ Et
   alors tu ferais quoi, comme mÃ©tier, JÃ©rÃ©mie ?
   JÃ©rÃ©mie : Probablement un mÃ©tier qui tourne autour de la crÃ©ation de
   spÃ©cifications.
   Daniel : Bon. Dâ€™accord. Ensuite, tu as parlÃ© des conversations Ã  propos
   de notre faÃ§on de rÃ©soudre le problÃ¨meâ€¦
   JÃ©rÃ©mie : Oui, câ€™est tout ce qui concerne le process, lâ€™organisation.
   La mÃ©thodologie si tu prÃ©fÃ¨res.
   Victor : Et la derniÃ¨re catÃ©gorie ?
   JÃ©rÃ©mie : Les conversations Ã  propos de toutes ces conversations.
   Daniel : Oui, en quoi Ã§a consiste ?
   JÃ©rÃ©mie : Eh bien, par exemple, Ã  essayer de comprendre pourquoi une
   conversation qui aurait dÃ» Ãªtre plus efficace par exemple, ne lâ€™a pas
   Ã©tÃ©, et ce quâ€™on peut faire pour quâ€™elle le devienne.
   Daniel : Et donc, comme Ã§a, vous savez, Ã  tout moment, quel type de
   conversation vous Ãªtes en train dâ€™avoir ? Câ€™est hilarant.
   JÃ©rÃ©mie : Mais non, pas du tout.
   Daniel : Alors pourquoi tu me parles de toutes ces catÃ©gories JÃ©rÃ©mie ?
   JÃ©rÃ©mie : Tu mâ€™as demandÃ© quels types de conversation on tient. Jâ€™ai
   essayÃ© de rÃ©pondre Ã  cette question.
   Daniel : Ha ! Tu es trop sÃ©rieux, JÃ©rÃ©mie. Tiens bois encore un peu de
   champagne.
   Toi : Il se fait tard. Je rentre. A demain !

   (Ã  suivre)
   Episodes PrÃ©cÃ©dents :
   1 â€” Si le code pouvait parler
   2 â€” Voir / Avancer
   3 â€” Communication Breakdown
   4 â€” Driver / Navigator
   5 â€” Brown Bag Lunch
   6 â€” Conseils Ã  emporter
   7 â€” Crise / OpportunitÃ©
   8 â€” Le CinquiÃ¨me Ã‰tage
   9 â€” Que faire ?
   10 â€” Soitâ€¦ Soitâ€¦
   11 â€” BoÃ®tes et FlÃªches
   12 â€” Le prochain Copil
   13 â€” La Faille
   14 â€” PoussiÃ¨re
   15 â€” Lâ€™hypothÃ¨se et la RÃ¨gle
   16 â€“ DÃ©placements
   17 â€” Jouer et ranger
   18 â€” Arrangements
   19 â€” Mise au point
   20 â€” ExpÃ©rimentation
   21 â€” Ã‰chantillons
   22 â€” Non-conclusions
   23 â€” Non-dÃ©cisions
   24 â€” Ã‰pisode neigeux
   25 â€” Fusions et confusions
   26 â€” DÃ©barquement
   27 â€” TempÃªte
   28 â€” EmbardÃ©e
   29 â€” AmÃ©nagement
   30 â€” Interruptions
   31 â€” Normalisation
   32 â€” Outsiders
   33 â€” Fabrication
   34 â€” Observation
   35 â€” Perturbations
   36 â€” Conclusions
   37 â€” Nouvelle Donne
   38 â€” Transaction
   39 â€” Mutation
   40 â€” Exclusion Mutuelle
   41 â€” PrÃ©emption
   42 â€” DÃ©monstration
   43 â€” Conversation
   44 â€” Exception
   45 â€” Explications
   46 â€” TÃ©lescopage
   47 â€” NÃ©gociations
   48 â€” Plaques tournantes
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Cet article a Ã©tÃ© postÃ© dans Software Craftsmanship.

Articles rÃ©cents

     * Comment conserver les mots de passe de ses utilisateurs en 2019 ?
     * AmÃ©lioration continue : Comment rester dynamique Ã  mesure que
       lâ€™Ã©quipe sâ€™agrandit ?
     * Culture Innovâ€™ : Quel ROI attendu ?
     * Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes
     * Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos
       valeurs et le garant de la vision technique dâ€™OCTO.â€

Laisser un commentaire Annuler la rÃ©ponse

   Votre adresse de messagerie ne sera pas publiÃ©e. Les champs
   obligatoires sont indiquÃ©s avec *

   Commentaire
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   [ ] Me notifier par mail en cas de nouveaux commentaires

   Nom * ______________________________

   Adresse de messagerie * ______________________________

   Site web ______________________________
   (BUTTON) Laisser un commentaire
   Ce formulaire est protÃ©gÃ© par Google Recaptcha
   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

   SÃ©curitÃ©

Comment conserver les mots de passe de ses utilisateurs en 2019 ?

   PostÃ© le 02/10/2019 par Fabien Leite
   Mot de passe

   Lorsque vous concevez une application, vous vous posez forcÃ©ment la
   question de lâ€™authentification et du contrÃ´le dâ€™accÃ¨s. Pour Ã§a,
   plusieurs mÃ©thodes sont disponibles et la premiÃ¨re qui vient
   gÃ©nÃ©ralement Ã  lâ€™esprit est lâ€™utilisation dâ€™un couple identifiant / mot
   de passe. Dans la mesure du possible, on prÃ©fÃ¨rera utiliser une
   solution dÃ©diÃ©e Ã  lâ€™authentification et au contrÃ´le dâ€™accÃ¨s : en bref,
   utiliser une solution dâ€™IAM pour gÃ©rer ces aspects Ã  votre place. Câ€™est
   gÃ©nÃ©ralement plus simple Ã  maintenir et câ€™est surtout souvent meilleur
   pour lâ€™expÃ©rience utilisateur. â€¦
   Lire la suite

   MÃ©thode

AmÃ©lioration continue : Comment rester dynamique Ã  mesure que lâ€™Ã©quipe
sâ€™agrandit ?

   PostÃ© le 01/10/2019 par Etienne Girot

   DiffÃ©rentes Ã©tudes1 soutiennent quâ€™une Ã©quipe performante est une
   Ã©quipe qui est capable de remettre frÃ©quemment en question ses modes de
   fonctionnement afin dâ€™apprendre et sâ€™amÃ©liorer en continu. Pour y
   arriver, elle : favorise l'Ã©mergence de nouvelles idÃ©es a moyen de
   valider ou dâ€™invalider efficacement la pertinence de ces nouvelles
   idÃ©es est en mesure dâ€™aligner ses membres derriÃ¨re les idÃ©es retenues
   comme Ã©tant pertinentes Or, plus une Ã©quipe grandit (aussi bien en
   nombre de membres quâ€™en temps passÃ© Ã  travailler ensemble) plus elle
   est sujette Ã â€¦
   Lire la suite

   MÃ©thode innovation

Culture Innovâ€™ : Quel ROI attendu ?

   PostÃ© le 01/10/2019 par Sylvain Fagnent, Matthieu VETTER
   [school.png]

   AprÃ¨s des annÃ©es et des millions investis sous la menace de la
   disruption, les Directions reviennent Ã  une logique plus ROIste. Ce
   mouvement est sain pour optimiser les ressources rares et donner du
   sens au travail des innovateurs. Le risque est cependant de tuer dans
   lâ€™oeuf des pÃ©pites potentielles en pilotant lâ€™innovation comme un
   business opÃ©rationnel. En fonction des objectifs, les retours sur
   investissement (ROI) dâ€™une dÃ©marche dâ€™innovation seront diffÃ©rents. Et
   dans un monde de plus en plus focalisÃ© sur la rentabilitÃ© Ã  court
   terme,â€¦
   Lire la suite

   Data Science

Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes

   PostÃ© le 30/09/2019 par Annabelle Blangero
   [school.png]

   Lâ€™usage des algorithmes de traitement de donnÃ©es â€“ de la simple requÃªte
   SQL aux puissants algorithmes de recommandation et de personnalisation
   des gÃ©ants de la Tech â€“ sâ€™est popularisÃ© ces derniÃ¨res annÃ©es,
   notamment pour des utilisateurs traditionnellement hors du domaine IT.
   Cet usage se retrouve dans tous les secteurs (industrie, Ã©ducation,
   santÃ©, sÃ©curitÃ©, etc.) et tend Ã  dÃ©lÃ©guer de plus en plus de dÃ©cisions
   Ã  des systÃ¨mes automatisÃ©s. Cette appropriation par le plus grand
   nombre rend les naufrages encore plus probables, et lâ€™exemple de
   Cambridgeâ€¦
   Lire la suite

   Archi & techno

Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos valeurs et le
garant de la vision technique dâ€™OCTO.â€

   PostÃ© le 27/09/2019 par Joy Boswell
   [archi.png]

   Chez OCTO depuis plus de 10 ans , Meriem fait partie des personnes
   fondatrices de lâ€™entreprise. Ancienne leadeuse de la tribu Nouvelles
   Architectures de DonnÃ©es, elle est dÃ©sormais CTO et participe Ã  la
   dÃ©finition de la vision stratÃ©gique et technique dâ€™OCTO. Qui de mieux
   pour nous parler du â€œtech leading Ã  la OCTOâ€ ?
   Lire la suite

   Data Science

Mise en application de DVC sur un projet de Machine Learning

   PostÃ© le 27/09/2019 par Nicolas TOUSSAINT, JÃ©rÃ©my Bouhi
   [school.png]

   Introduction DVC (Data Version Control) est un package Python qui
   permet de gÃ©rer plus facilement ses projets de Data science. Cet outil
   est une extension de Git pour le Machine Learning, comme lâ€™Ã©nonce son
   principal contributeur Dmitry Petrov dans cette prÃ©sentation. DVC est Ã 
   la fois comparable et complÃ©mentaire Ã  Git. Il va sâ€™occuper de
   synchroniser vos donnÃ©es et votre code. Il est donc particuliÃ¨rement
   intÃ©ressant dans le cadre dâ€™un projet de Machine Learning oÃ¹ le modÃ¨le
   et les donnÃ©es Ã©voluent au fil du dÃ©veloppement.â€¦
   Lire la suite

   Archi & techno

BD â€“ Le DÃ©ploiement Continu (CD)

   PostÃ© le 26/09/2019 par Aryana Peze
   [archi.png]

   Hello ! Lors de la BD prÃ©cÃ©dente, nous avons abordÃ© le sujet de la CI
   (IntÃ©gration Continue). Et impossible de parler de CI sans parler de CD
   (DÃ©ploiement Continu)! En thoÃ©rie, la CD implique un dÃ©ploiement
   automatique et quasi-systÃ©matique de chaque modification du code sur
   l'environnement de production. Les mises en production sont rÃ©guliÃ¨res
   et ne sont plus une source de stresse, et l'environnement de production
   est ainsi toujours Ã  jour. En pratique, c'est un objectif trÃ¨s
   compliquÃ© Ã  atteindre, et pas toujours adaptÃ©. (Petite parenthÃ¨seâ€¦
   Lire la suite

   Agile

Dâ€™Ã©tudiant Ã  mentor : rencontre avec notre Octo Thomas Le Flohic

   PostÃ© le 24/09/2019 par CÃ©line Audibert
   [agile.png]

   Thomas a fait un vÃ©ritable parcours â€œÃ  la OCTOâ€ : aprÃ¨s son Ã©cole
   dâ€™ingÃ©, il rentre en stage au sein de notre tribu VIBE (Virtual
   Immersion and Bot Experience) et rejoint dÃ©finitivement lâ€™entreprise en
   intÃ©grant le programme Skool. Un de ses profs Ã  lâ€™Ã©cole Ã©tait un Octo,
   Fabien. Câ€™est ce qui lui a donnÃ© envie de venir frapper Ã  notre porte.
   Comme lui, Thomas a voulu garder un lien avec lâ€™Ã©cole et transmettre
   son savoir. Câ€™est ainsi quâ€™il sâ€™est lancÃ© dans lâ€™accompagnement dâ€™un
   projet deâ€¦
   Lire la suite

   Archi & techno

Interview CÃ©line Gilet â€“ Â« Le Tech Lead nâ€™est pas un super hÃ©ros ! Â»

   PostÃ© le 23/09/2019 par CÃ©line Audibert
   [archi.png]

   Depuis plus de 4 ans chez OCTO, CÃ©line, membre de la tribu CRAFT, est
   devenue une rÃ©fÃ©rence parmi nos Tech Lead. DÃ©couvrez sa vision de ce
   rÃ´le Ã  part. Pour toi, quel est le rÃ´le du Tech Lead ?  Pour moi, câ€™est
   faire en sorte que lâ€™Ã©quipe au sens large (DÃ©veloppeurs, Ops,
   Fonctionnels, Product Owner) arrive Ã  dÃ©livrer rÃ©guliÃ¨rement de la
   valeur. ConcrÃ¨tement, il sâ€™agit de jongler et prioriser en permanence
   entre plusieurs casquettes : expertise, accompagnement, coaching et
   formation.
   Lire la suite

   MÃ©thode innovation

Injonctions paradoxales : un MVP â€¦ mais pour tous !

   PostÃ© le 20/09/2019 par Dominique Lequepeys, Sylvain Fagnent
   un MVP pour tous

   Un MVP ... mais pour tout le monde ! Et si vous vouliez lâ€™entendre
   cette injonction ? Mise en scÃ¨ne, Ã©coutez la. Les racines du paradoxe
   D'un cÃ´tÃ©, les managers sont sous la pression du timing : ils sont
   sÃ©duits par le concept de MVP, Minimum Viable Product, prÃ©sentÃ© comme
   un moyen d'accÃ©lÃ©rer la mise sur le marchÃ©. D'un autre, ils sont sous
   la pression du chiffre : ils ont du mal Ã  accepter qu'on se prive d'une
   partie du marchÃ© potentiel. En outre, ilsâ€¦
   Lire la suite
   1234>
   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #alternate OCTO Talks ! Â» Feed OCTO Talks ! Â» Comments Feed OCTO Talks
   ! Â» A chat with Doug Cutting about Hadoop Comments Feed Geo localizing
   Medline citations Serverless real-time architecture on AWS: there is a
   way ! alternate alternate

     * fr
     * pt-br

   OCTO Talks !

   Go to content
     * Archi & Techno
     * Methodology
     * Big Data
     * News

A chat with Doug Cutting about Hadoop

   Publication date 14/01/2016 by Nelly Grellier
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   We had the chance to interview Doug Cutting during the Cloudera
   Sessions in Paris, October 2014. Doug is the creator behind Hadoop and
   Clouderaâ€™s Chief Architect. Here is our exchange below:

   DougBWSquare

A question is: how does it feel to see that Hadoop is actually becoming the
must have, the default way of storing and computing over data in large
enterprise companies?

   Rationally it feels very good. Itâ€™s a technology thatâ€™s supposed to do
   that. Emotionally itâ€™s very satisfying, but also I must say I must be
   very lucky. I was in the right place at the right time and happened to
   be the person. Someone else would have done this had I not, by now.


   Download our white paper â€œHadoop Roadmapâ€

Itâ€™s funny because yesterday you were mentioning how Google released that
paper about GFS and then about MapReduce, and you seemed surprised that no
one else has gone and implemented the paper. How would you describe this,
because it was a very big, big task that some people were daunted by taking
on orâ€¦?

   I think, again, I have the right experience from having put some work
   in open source. I worked on search engines and I could see the value in
   the technology, I understood the problem, and that combination. And I
   think Iâ€™ve also been in the software business long enough so thatâ€™s why
   I knew what itâ€™d take to build a project that would be useful, that
   would be used. And I think no one else was positioned ready enough in
   the competition with that combination of properties. Iâ€™ve been able to
   take advantage of these papers and implement them as open source, and
   get them out to people. My guess, I donâ€™t know. It wasnâ€™t my plan.

Were you expecting that it would get take such a big, big impact?

   No, not at all.

OK, now I guess itâ€™ll be more of a technical question: you mentioned
yesterday (I was there yesterday and today) that you know there are all these
tools that are coming out, like, building on top of Hadoop and bringing a new
technology and a new usage of data â€“ how do you see Hadoop changing,
architecturally speaking, to be able to provide even more capabilities in the
future?

   Itâ€™s a very general architecture. Itâ€™s in many ways, much like I said,
   an operating system. An operating system, Iâ€™ve been showing, has
   storage, has a scheduler, has security mechanisms. Already the
   challenge is to support all kinds of different applications. So I think
   that the design it has right now is more or less sufficient to permit a
   very wide range.

Just like operating systems havenâ€™t changed since Windows.

   Yeah, not fundamentally. Since the 60â€™s. Those basic capabilities give
   you a platform you can develop lots of different applications on that
   can share the hardware, in a sense. Itâ€™s reallyâ€¦ Well, a Java OS is
   sort of â€œget out of the wayâ€ and let applications share the hardware.

Provide abstractions as Jim Baum said.

   Exactly.

To deal with complexity.

   And so I think thatâ€™s a role that Hadoop is filling more and more.

   I know it needs a radical re-architecture to do that. Whether people
   will implement alternate file systemsâ€¦That might happen, weâ€™ll see.

OK. Thank you so much. And do you see, all these tools, like, you see Kafka
for log aggregation across DC, and we see Storm for stream processing, and
all these things. Do you see new usages that havenâ€™t come out yet for data?
You can search on it, you can index it, you can stream it and process it in
real timeâ€¦

   We think there are lots of opportunities for more vertical applications
   in different industries that are very specific. Things that can process
   images, tools that can process dataâ€¦ There are lots of different areas
   where there arenâ€™t tools today. Not to mention verticals like insurance
   and banking and so on. Some people see commercial offerings and some
   people see open source offerings. I think right now what people are
   seeing are more the lower-level tools that can be plugged. I think more
   and more, higher and higher upper stack will see open-source
   implementations commoditizing the value of the stack. Thatâ€™s an ongoing
   process.

   WP_Hadoop_carto_3D


   Want to know more about Hadoop and the Hadoop ecosystem? Have a look at
   our Hadoop map (English version)!

   Our Hadoop White Paper and Roadmap are also available for free download
   (French only).
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   This entry was posted in Big Data, News.

Recent Posts

     * Seven shades of Git
     * Accelerating NiFi flows delivery: Part 1
     * Cache me if you can â€“ 2
     * Android Material Components: Exploring MaterialShapeDrawable
     * Comic â€“ Infrastructure as Code (IaC)

Un commentaire sur â€œA chat with Doug Cutting about Hadoopâ€

     Nick
   08/01/2018 Ã  09:59
   Link to Hadoop map is broken :(

Leave a Reply Cancel reply

   Your email address will not be published. Required fields are marked *

   Comment
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   [ ] Me notifier par mail en cas de nouveaux commentaires

   Name * ______________________________

   Email * ______________________________

   Website ______________________________
   (BUTTON) Leave a comment
   This form is protected by Google Recaptcha

   ____________________ (BUTTON)

   Search

   Incubated startups at OCTO
   Appaloosa, your company App Store

   Appaloosa, your company App Store
   www.laduckconf.com www.laduckconf.com

   Our white papers :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Who we are
          + Who we are
          + Locations
          + Our products
          + Partners
          + Investors
     * What we do
          + What we do
          + How we do it
          + Publications
          + Events
          + OCTO Academy
     * Join us
          + OCTO is hiring!
          + Inside OCTO
          + Our tribes
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * Headquarters:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Legal mentions

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #alternate OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires
   OCTO Talks ! Â» Browser 2.0 : un nouveau browser pour des interactions
   plus riches Flux des commentaires Maven Community news â€“ AoÃ»t 2007 WWDC
   2007 alternate alternate

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

Browser 2.0 : un nouveau browser pour des interactions plus riches

   PostÃ© le 04/09/2007 par Andre Nedelcoux
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Lorsque lâ€™on cherche Ã  classifier les applications et que lâ€™on
   sâ€™intÃ©resse aux technologies dâ€™interface homme-machine, nous avons
   dÃ©sormais pris lâ€™habitude de distinguer deux filiÃ¨res principales : la
   filiÃ¨re RIA,  Â» Rich Internet Applications  Â» et la filiÃ¨re RDA,  Â»
   Rich Desktop Applications Â« . Est-il possible de tirer partie des
   avantages respectifs de ces deux technologies? Un petit dÃ©lire sur une
   solution mixteâ€¦

   Dans le premier cas (RIA), le navigateur web est utilisÃ© comme
   environnement dâ€™exÃ©cution des applications, câ€™est-Ã -dire comme
   conteneur pour le code dÃ©veloppÃ© en HTML, Javascript et autre CSS.
   GrÃ¢ce Ã  des efforts importants de communautÃ©s open source et dâ€™Ã©diteur,
   le niveau dâ€™interaction (de  Â» richesse Â« ) proposÃ© par ce type
   dâ€™applications est en augmentation constante, avec des efforts
   importants pour se rapprocher du niveau dâ€™ergonomie des applications
   natives. On peut citer Ã  titre dâ€™exemple le framework ajax  Â» page bus
    Â» de Tibco qui a vocation Ã  proposer une approche Ã©vÃ©nementielle pour
   les dÃ©veloppements Javascript.
   Dans le second cas (RDA), le navigateur web est utilisÃ© comme moyen
   dâ€™accÃ¨s Ã  lâ€™application : un lien sur une page permet de lancer un
   plugin cÃ´tÃ© client qui, via le browser, rÃ©cupÃ¨re les composants de
   lâ€™application. Une fois tÃ©lÃ©chargÃ©e, lâ€™application sâ€™exÃ©cute de maniÃ¨re
   autonome, le browser nâ€™Ã©tant plus utilisÃ©. Comme exemple concret, il
   est possible de citer la technologie Java Web Start de Sun qui joue le
   rÃ´le de lanceur et dâ€™updateur depuis le serveur (si une nouvelle
   version de lâ€™application est disponible). Dans le monde Eclipse, le
   browser est mÃªme totalement contournÃ© : câ€™est la plate-forme Eclipse
   qui se charge de rÃ©cupÃ©rer les nouvelles versions de lâ€™application et
   qui agit comme un  Â» browser dâ€™applications RDA Â« . Il y a ici peu de
   limites dans le niveau dâ€™ergonomie atteignable, sans les limites
   imposÃ©es par le browser (sÃ©curitÃ©, accÃ¨s au file system, accÃ¨s Ã  des
   pÃ©riphÃ©riquesâ€¦).
   Il peut Ãªtre intÃ©ressant de rÃ©flÃ©chir aux moyens de marier le meilleur
   de ces deux mondes. Ainsi, on peut imaginer un browser web capable
   dâ€™offrir une vraie  Â» infrastructure  Â» desktop, contenant des
   applications web qui pourraient dÃ©sormais interagir fortement avec ce
   browser, en le modifiant (par exemple par ajout de fenÃªtre, dâ€™entrÃ©es
   de menus du browserâ€¦) ou en communiquant avec lui (par exemple par
   dÃ©clenchement dâ€™un Ã©vÃ©nement qui serait propagÃ© Ã  lâ€™OS ou Ã  une autre
   application Ã©galement hÃ©bergÃ©e dans le browser). Le browser deviendrait
   un pont entre lâ€™application web et les fonctions offertes par lâ€™OS,
   puis dans un second temps avec toutes les applications du poste ; il
   serait capable de gÃ©rer le multi-fenÃªtrage associÃ© Ã  plusieurs
   applications ouvertes en parallÃ¨le, avec toutes les fonctionnalitÃ©s
   associÃ©es (sauvegarde de lâ€™Ã©tat du browser et des prÃ©fÃ©rences
   utilisateur, habilitationsâ€¦).
   Que gagnerait-on avec ce browser hybride ? Il serait possible de lever
   des limites des deux filiÃ¨res classiques puisque lâ€™on aurait une
   infrastructure totalement ouverte vers le poste local, qui permettrait
   aussi une ouverture sur le web. Il serait possible de proposer le mÃªme
   niveau dâ€™interactivitÃ© que les applications locales sans avoir besoin
   de rÃ©inventer toute une ergonomie dans le cadre contraint du browser
   habituel. Dâ€™un point de vue performances et fluiditÃ© des applications,
   un gain substantiel pourrait Ãªtre envisagÃ© puisque le browser
   permettrait dâ€™utiliser des composants performants de lâ€™OS, dont
   lâ€™imitation en RIA donne parfois lieu Ã  des implÃ©mentations poussives.
   Fermez les yeux deux secondes et imaginez un peu :
     * Lâ€™utilisateur lance son browser  Â» new generation  Â» et saisit
       lâ€™URL dâ€™une application
     * Lors de son lancement, lâ€™application  Â» dÃ©clare  Â» au browser
       quâ€™elle a besoin des 3 onglets supplÃ©mentaires (positionnÃ©s en haut
       Ã  gauche pour 2 dâ€™entre eux et en bas pour le dernier afin de
       constituer une barre de messages pour lâ€™utilisateur) ainsi que dâ€™un
       composant  Â» browser  Â» chargÃ© de piloter MS Word
     * Durant lâ€™exÃ©cution, lâ€™application va pousser des informations dans
       chacun des 3 onglets, lancer MS Word pour lui injecter un document
       type rempli de donnÃ©es issues de lâ€™application, que lâ€™utilisateur
       modifie (dans MS Word !) et re-soumet Ã  lâ€™application
     * Parce quâ€™il a besoin de faire une recherche sur le web,
       lâ€™utilisateur lance Google : il lui suffit de lancer la page web
       dans un onglet. Pour une application web classique, la plate-forme
       est un simple browser 1.0 et il hÃ©berge lâ€™application de maniÃ¨re
       transparente.

   Dans une utilisation  Â» totale Â« , le browser deviendrait une
   plate-forme RDA capable dâ€™hÃ©berger des applications web. Dans une
   utilisation  Â» basique Â« , on aurait un simple browser web. Lâ€™avantage
   estâ€¦ quâ€™il est possible de faire les deux au sein dâ€™une mÃªme
   plate-forme, selon le type dâ€™application ! Par ailleurs, lâ€™accÃ¨s aux
   ressources et aux composants IHM natifs de lâ€™OS serait possible via ce
   browser.
   Alors, vous Ãªtes partants ? Comment pourrait-on implÃ©menter avec les
   technologies dâ€™aujourdâ€™hui cette nouvelle filiÃ¨re de browser ?
   PremiÃ¨re solution : en sâ€™appuyant sur un browser qui offre dÃ©jÃ  un
   modÃ¨le de framework de programmation dâ€™IHM, Ã  savoir FireFox avec son
   framework XUL. Notre application web pourrait Ãªtre dÃ©veloppÃ©e de
   maniÃ¨re  Â» classique  Â» (Javascript + HTML + CSS + tiers serveur en
   langage de votre choix) et envoyer des instructions XUL au browser
   (avec un mÃ©canisme Ã  trouver J) pour que celui-ci se dÃ©forme et ajoute
   des morceaux dâ€™IHM  Â» rÃ©ellement riches  Â» (= en technologie de lâ€™OS).
   DeuxiÃ¨me solution : en sâ€™appuyant sur une solution RDA capable de
   piloter un browser, Ã  savoir Eclipse RCP par exemple. Dans ce modÃ¨le,
   lâ€™application web classique remonte des instructions Ã  la plate-forme
   qui se dÃ©forme Ã©galement ; ce mÃ©canisme est ici possible du fait de la
   capacitÃ© dâ€™Eclipse RCP Ã  intÃ©grer (via un composant ActiveX) un browser
   web et Ã  communiquer avec lui via ce  Â» pont  Â» ActiveX. Autre avantage
   : il est Ã©galement possible de dÃ©ployer dans ce browser de vraies
   applications RDA, dÃ©veloppÃ©es dans la technologie Eclipse.
   De nombreux enjeux restent Ã  adresser pour parvenir Ã  dÃ©velopper ce
   type dâ€™applications :
     * Comment dÃ©velopper une application  Â» cross browser  Â» ? Pour
       lâ€™Ãªtre vraiment, elles nâ€™exploiteraient pas les nouvelles
       fonctionnalitÃ©s offertes par ce browser de nouvelle gÃ©nÃ©ration et
       seraient alors de  Â» simples applications internet riches Â« â€¦
     * Faut-il introduire une nouvelle technologie, câ€™est-Ã -dire encore un
       autre browser en plus du nombre dÃ©jÃ  important ? Comment
       capitaliser sur le trÃ¨s large parc installÃ© dâ€™IE?
     * Quel langage de programmation pour lâ€™API du browser ? Quel
       protocole derriÃ¨re cette API, câ€™est-Ã -dire quelle structure de
       message et dâ€™Ã©change de message entre les applications et le
       browser hybride ?
     * Comment gÃ©rer les problÃ©matiques de sÃ©curitÃ© de ce nouveau browser
       qui permet Ã  une application web dâ€™interagir fortement avec lâ€™OS ?
     * Enfin, la complexitÃ© introduite en vaut-elle la chandelle ? On peut
       imaginer que dÃ©velopper une telle application pour un dÃ©veloppeur
       peu expÃ©rimentÃ© risque dâ€™Ãªtre assez complexe, vu le mÃ©lange de
       technologies.

   â€¦ mais on peut toujours rÃªver :o). Il y a quelques annÃ©es, on avait des
   Ã©crans noirs et verts en 32/70.
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Cet article a Ã©tÃ© postÃ© dans BrÃ¨ves de consultants et tagguÃ© RIA.

Articles rÃ©cents

     * Comment conserver les mots de passe de ses utilisateurs en 2019 ?
     * AmÃ©lioration continue : Comment rester dynamique Ã  mesure que
       lâ€™Ã©quipe sâ€™agrandit ?
     * Culture Innovâ€™ : Quel ROI attendu ?
     * Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes
     * Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos
       valeurs et le garant de la vision technique dâ€™OCTO.â€

3 commentaires sur â€œBrowser 2.0 : un nouveau browser pour des interactions
plus richesâ€

     ben
   04/09/2007 Ã  21:24

   Que pense tu de XAML?
   www.xaml.fr/

     tvi
   08/09/2007 Ã  21:42

   La 2Ã¨me solution prÃ©sente l'inconvÃ©nient d'utiliser un truc trÃ¨s trÃ¨s
   propriÃ©taire (ActiveX) entre 2 morceaux trÃ¨s ouverts (java avec Eclipse
   RCP et HTML/CSS), et rend le conteneur dÃ©pendant du browser puisqu'il
   n'y a pas d'interface COM unique (qu'implÃ©menteraient IE, Mozilla,
   etc.).
   Ca va bien pour des applis intranet en entreprise (j'ai un exemple en
   tÃªte ;-) mais au-delÃ ... couic.

     Dominique De Vito
   22/09/2007 Ã  18:06

   D'aprÃ¨s ce que j'ai compris de la voie suivie par Adobe, le navigateur
   Air (ex-Apollo) est le navigateur hybride envisagÃ© ici, ou en tout cas,
   en est trÃ¨s proche de part sa capacitÃ© Ã  se comporter comme un
   navigateur normal et sa facilitÃ© Ã  pouvoir, par ex, accÃ©der aux
   ressources de la machine locale. Ce navigateur d'Adobe serait plutÃ´t du
   premier type dÃ©taillÃ© plus haut.

Laisser un commentaire Annuler la rÃ©ponse

   Votre adresse de messagerie ne sera pas publiÃ©e. Les champs
   obligatoires sont indiquÃ©s avec *

   Commentaire
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   [ ] Me notifier par mail en cas de nouveaux commentaires

   Nom * ______________________________

   Adresse de messagerie * ______________________________

   Site web ______________________________
   (BUTTON) Laisser un commentaire
   Ce formulaire est protÃ©gÃ© par Google Recaptcha

   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #alternate OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux des commentaires
   OCTO Talks ! Â» RÃ¨gles de qualitÃ© de code Flux des commentaires
   alternate alternate

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

RÃ¨gles de qualitÃ© de code

   PostÃ© le 21/06/2011 par Maxime ARNSTAMM
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   RÃ¨gles de qualitÃ© de code Sonar .NET
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Cet article a Ã©tÃ© postÃ© dans .

Articles rÃ©cents

     * Comment conserver les mots de passe de ses utilisateurs en 2019 ?
     * AmÃ©lioration continue : Comment rester dynamique Ã  mesure que
       lâ€™Ã©quipe sâ€™agrandit ?
     * Culture Innovâ€™ : Quel ROI attendu ?
     * Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes
     * Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos
       valeurs et le garant de la vision technique dâ€™OCTO.â€

Laisser un commentaire Annuler la rÃ©ponse

   Votre adresse de messagerie ne sera pas publiÃ©e. Les champs
   obligatoires sont indiquÃ©s avec *

   Commentaire
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   [ ] Me notifier par mail en cas de nouveaux commentaires

   Nom * ______________________________

   Adresse de messagerie * ______________________________

   Site web ______________________________
   (BUTTON) Laisser un commentaire
   Ce formulaire est protÃ©gÃ© par Google Recaptcha
   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
   #alternate alternate alternate OCTO Talks ! Â» Flux OCTO Talks ! Â» Flux
   des commentaires OCTO Talks ! Â» query Flux des commentaires alternate
   alternate

     * en
     * pt-br

   OCTO Talks !

   Aller au contenu de la page
     * StratÃ©gie SI
     * archi & techno
     * MÃ©thode
     * Digitalisation
     * Big Data
     * Ã‰vÃ¨nement

query

   PostÃ© le 20/02/2019 par Joy Boswell
     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

     * Tweet
     * Share 0
     * +1
     * LinkedIn 0

   Cet article a Ã©tÃ© postÃ© dans .

Articles rÃ©cents

     * Comment conserver les mots de passe de ses utilisateurs en 2019 ?
     * AmÃ©lioration continue : Comment rester dynamique Ã  mesure que
       lâ€™Ã©quipe sâ€™agrandit ?
     * Culture Innovâ€™ : Quel ROI attendu ?
     * Ouvrir la boÃ®te noire et comprendre les dÃ©cisions des algorithmes
     * Meriem Berkane, CTO : â€œLe Tech Lead est lâ€™incarnation de nos
       valeurs et le garant de la vision technique dâ€™OCTO.â€

Laisser un commentaire Annuler la rÃ©ponse

   Votre adresse de messagerie ne sera pas publiÃ©e. Les champs
   obligatoires sont indiquÃ©s avec *

   Commentaire
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________
   _____________________________________________

   [ ] Me notifier par mail en cas de nouveaux commentaires

   Nom * ______________________________

   Adresse de messagerie * ______________________________

   Site web ______________________________
   (BUTTON) Laisser un commentaire
   Ce formulaire est protÃ©gÃ© par Google Recaptcha
   ____________________ (BUTTON)

   Chercher

   Les start-ups incubÃ©es chez OCTO :
   Appaloosa, App Store dâ€™entreprise

   Les prochaines formations :
    1. [R]Ã©volution Blockchain
    2. ThÃ©orie U
    3. AWS : Notions techniques Amazon Web Services de base
    4. Administrer la plateforme Hadoop 2.X Hortonworks : fondamentaux
    5. QualitÃ© des dÃ©veloppements avec Test Driven Development

   Appaloosa, App Store dâ€™entreprise

   Suivez lâ€™aventure sur leur blog
   www.laduckconf.com www.laduckconf.com

   Nos livres blancs :
   Culture DevOps 2 Culture DevOps 2 Guide de survie dans la jungle
   technologique Culture Code Culture Code Software Craftsmanship : Better
   places with better code Roadmap Produit Roadmap Produit Et si elle
   devenait une direction plutÃ´t quâ€™un plan Ã©tabli ?

     * Nous connaÃ®tre
          + Pourquoi OCTO ?
          + OÃ¹ trouver OCTO ?
          + Nos produits
          + Nos partenaires
          + Investisseurs
     * Notre mission
          + Ce que nous faisons
          + Comment nous le faisons
          + Publications
          + Ã‰vÃ¨nements
          + OCTO Academy
     * Nous rejoindre
          + OCTO Recrute !
          + DÃ©couvrez OCTO de l'intÃ©rieur
          + Nos tribus
     * International
          + Paris
          + Rabat
          + Lausanne
          + Sydney

   OCTO Technology
   Part of Accenture Digital
     * Paris
     * Rabat
     * Lausanne
     * Sydney


     * SiÃ¨ge:
     * 34 avenue de l'OpÃ©ra,
     * 75002 Paris,
     * France
     * +33 (0)1 58 56 10 00

     * Contact
     * Mentions legales

   En navigant sur ce site, vous acceptez lâ€™utilisation de cookies ou
   autres traceurs vous permettant une utilisation optimale du site
   (partages sur les rÃ©seaux sociaux, statistiques de visite,
   etc.)J'accepte
